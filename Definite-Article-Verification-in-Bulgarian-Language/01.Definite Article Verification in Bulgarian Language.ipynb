{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ba6dbb-7300-4aa4-be29-9428e6935672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "from ufal.udpipe import Model, Pipeline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import spacy_stanza\n",
    "import stanza\n",
    "import time\n",
    "import urllib.request\n",
    "import warnings\n",
    "\n",
    "# pip install ufal.udpipe\n",
    "# pip install spacy-stanza\n",
    "# pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c20c6e-a84f-4573-8ee9-862665a570fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30debef-d1a9-4421-897e-eefc36abc031",
   "metadata": {},
   "source": [
    "# Linguistic Rule-Based System for Definite Article Verification in Bulgarian Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd48eb-5d47-44b9-9400-097061575bfd",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff55729-4e8c-4633-ad4f-4bd3b3aeac41",
   "metadata": {},
   "source": [
    "In everyday writing, it's crucial for people to use grammatical rules correctly, especially when it comes to the definite article in Bulgarian, which can appear in either a full or short form. Misusing these forms can cause confusion and change the meaning of a sentence.\n",
    "\n",
    "In this article, we explore the challenge of determining the correctness of full and short definite articles in Bulgarian, a task necessitating sophisticated NLP techniques. Rather than being a tool for NLP models, this program aims to assist users in verifying whether they are using the full or short form of the definite article correctly. It could eventually be developed into an online grammar checker to support everyday writing.\n",
    "\n",
    "To achieve this goal, the program leverages several key tools and technologies:\n",
    "\n",
    "- **Python**: A versatile programming language widely used in data science and NLP due to its rich ecosystem of libraries and ease of use.\n",
    "- **SpaCy**: An open-source NLP library in Python.\n",
    "- **Stanza and UDPipe**: Given that SpaCy does not have native support for Bulgarian, this project integrates two other libraries - UDPipe and Stanza - to handle Bulgarian text processing.\n",
    "\n",
    "SpaCy, together with Stanza and UDPipe, provides features such as Part-of-Speech (POS) tagging, which assigns word types like nouns, verbs, and adjectives; morphological tagging (TAG), which identifies grammatical features such as tense, number, and gender; and syntactic dependency parsing (DEP), which reveals the grammatical structure of sentences by showing how words relate to each other. These features are crucial for understanding the nuances of Bulgarian grammar and ensuring the correct usage of definite articles.\n",
    "\n",
    "This article walks the reader through the process of developing the program, from understanding the linguistic problem to choosing the right tools, implementing the solution, and evaluating its effectiveness. It starts with a discussion of the problem and the tools used, followed by in-depth sections on implementing grammatical rules, testing, and potential future improvements. By the end of the article, readers will have a solid grasp of both the challenges and solutions involved in building an NLP tool tailored for the Bulgarian language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb006e-3f05-4dd6-ab70-aeb8f42bc865",
   "metadata": {},
   "source": [
    "### Proposed approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ba57f-a2eb-4c14-aba6-9348b37a743b",
   "metadata": {},
   "source": [
    "- Begin by exploring the grammar that forms the foundation of our work.\n",
    "- Then create a proof of concept (PoC) to test our initial ideas.\n",
    "- Experiment with Stanza and UDPipe in order to identify the most effective one for our purposes.\n",
    "- With the selected library, build functions to process data and establish a generic testing function to ensure consistent result evaluation.\n",
    "- Then expand the basic functionality introduced by the PoC by incrementally adding rules.\n",
    "- After implementing each rule, test and validate the results, examine any failures, and plan the next steps. Continue the iterative process for each rule.\n",
    "- After implementing all the rules, test again with a longer dataset with real scraped data.\n",
    "- Finally, conclude with a summary of the insights gained throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c220ee1-37ee-40cb-8660-f1f54f9a48b1",
   "metadata": {},
   "source": [
    "## Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb34e0-6742-4e8e-991a-62190fc94703",
   "metadata": {},
   "source": [
    "### Rules for full/short form of the definite article in Bulgarian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acacf37-1f23-45bf-80b4-b9522536ac38",
   "metadata": {},
   "source": [
    "**Rule1:** The long definite article should be used when the noun takes the role of the subject.   <a href=\"#ref1\">[1]</a>, <a href=\"#ref2\">[2]</a>\n",
    "  * Exceptions are made only for nicknames, aliases, or geographical names like _Апостола_, _Щастливеца_, _Хисарлъка_, etc., which, even if they are the subject in the sentence, are still used with a short definite article.\n",
    "\n",
    "Examples:\n",
    "\n",
    "  * _Ключът е на масата._\n",
    "  * _Царят пие вино._\n",
    "  * _Ученикът е умен и трудолюбив._\n",
    "  * _Приятелят ми е в чужбина._\n",
    "  * _Гостът пристигна._\n",
    "  * _Готвачът приготви обяда._\n",
    "  * _Влакът спря на гара София._\n",
    "  * _Учителят говореше за Стефан Стамболов._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329406f-b044-4c3e-84ca-8644bf1ed218",
   "metadata": {},
   "source": [
    "**Rule2**: The short form of the definite article is used in grammatical positions, such as:\n",
    "  * a) When the noun takes the role of the object. <a href=\"#ref1\">[1]</a>, <a href=\"#ref2\">[2]</a>\n",
    "  * b) The noun is after a preposition <a href=\"#ref1\">[1]</a>, <a href=\"#ref2\">[2]</a>\n",
    "  * c) the object of a verb <a href=\"#ref6\">[6]</a>\n",
    "  * d) the object of a preposition <a href=\"#ref6\">[6]</a>\n",
    "  * e) (or in apposition to such objects).<a href=\"#ref6\">[6]</a>\n",
    "\n",
    "\n",
    "  Examples:\n",
    "\n",
    "  \n",
    "  * Object of Verb: _Таня търси лекаря._\n",
    "  * Object of Preposition: _Говорим за лекаря._\n",
    "  * Apposition to Object of Verb: _Таня търси Ангел Иванчев, лекаря._\n",
    "  * Apposition to Object of Preposition: _Говорим за Ангел Иванчев, лекаря._\n",
    "  * Object: _Той ми даде ключа от къщата._\n",
    "  * Object: _Кралицата говори с царя._\n",
    "  * Object: _Аз помагам на ученика._\n",
    "  * Object: _Много пътници слязоха от влака._\n",
    "  * Object: _Слушахме с интерес учителя._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e58bf-229f-4ce0-ac33-bc3c911fb133",
   "metadata": {},
   "source": [
    "**Rule3**: Adjectives, numerals, participles and possessive pronouns take the same article as the noun they agree with. Or in other words, In adjective-noun phrases, only the adjective takes a definite article ending. <a href=\"#ref3\">[3]</a>, <a href=\"#ref7\">[7]</a>\n",
    "  * Exception: when the noun phrase does not already show its definiteness through the presence of a demonstrative pronoun such as _този_ (\"this\") or _онзи_ (\"that\") <a href=\"#ref6\">[6]</a>\n",
    "    \n",
    "Examples:\n",
    "\n",
    "  * _Дългоочакваният гост дойде._\n",
    "  * _Иван, гостът от Сопот, дойде._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111be730-3eae-4e86-94ba-def908803222",
   "metadata": {},
   "source": [
    "**Rule4**: The full definite article should be used when a noun is after verbs like _съм_, _бъда_, _оказвам се_, _изглеждам_, etc. <a href=\"#ref3\">[3]</a>\n",
    " \n",
    "  Examples:  \n",
    "  * _Х. е съученикът ми | успелият | добрият._\n",
    "  * _У. се оказа най-верният му приятел |дарителят на училището._\n",
    "  * _Ученикът на първия чин изглежда най-доволният от всички._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02ef4b-d445-4bbf-9968-bebb96f42294",
   "metadata": {},
   "source": [
    "**Rule5**: When there are two or more adjectives in front of the noun the definite article is added only to the _first_ adjective. <a href=\"#ref4\">[4]</a>, <a href=\"#ref5\">[5]</a>\n",
    "\n",
    "Example:\n",
    "\n",
    "  * _Той е най-високият и хубав в стаята._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f801c4-37ee-46cc-afc5-25ab6bff86ff",
   "metadata": {},
   "source": [
    "**Rule_6**: If we are addressing someone using a nickname, it must take the full definite article. (Note that this is not the same as Rule1b.) <a href=\"#ref3\">[3]</a>\n",
    "\n",
    "Example:\n",
    "  * Малкият, заповядай едно бонбонче!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f679a-de56-493a-9998-1a4d2efae185",
   "metadata": {},
   "source": [
    "**Rule_7**:\n",
    "  * The long forms are used when the noun is the subject of a clause (already covered by Rule1), a predicate connected to a subject by a verb of “being”, or an apposition to one of these. <a href=\"#ref6\">[6]</a>\n",
    "\n",
    "Examples:\n",
    "  * Predicate: Приятелят ни е лекарят.\n",
    "  * Apposition to Subject: Ангел Иванчев, лекарят, живее тука.\n",
    "  * Apposition to Predicate: Приятелят ни е Ангел Иванчев, лекарят."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c3182-4bfe-4be5-aa2b-b7cb220a208b",
   "metadata": {},
   "source": [
    "**Additionally**, in **the passive voice** (especially if the subject is an inanimate noun), as well as in cases of **inverted word order** in the sentence, the subject may not be correctly recognized, which can lead to incorrect use of the short form of the definite article instead of the full form. Therefore, special care should be taken in examples like the following:\n",
    "  * _Телевизорът е поправен от новия техник._\n",
    "  * _Ученика, а не учителя извика при себе си директорът._\n",
    "  * _Заекът видя сокола._\n",
    "  * _Заека видя соколът._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1835489a-8dc6-4a5b-8a70-328c0ca6b36d",
   "metadata": {},
   "source": [
    "### Linguistic tagging in NLP\n",
    "\n",
    "In the realm of Natural Language Processing (NLP), part-of-Speech (POS) tagging, morphological tagging (TAG), and dependency parsing (DEP) are foundational techniques that enable machines to comprehend linguistic nuances. \n",
    "\n",
    "In order to be able to analyze a sententece, we need to understand the linguistic annotations that are generated by an NLP model. \n",
    "Here is an example output from Stanza:\n",
    "\n",
    "<img src=\"images/stanza_example_output.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3ea9db-1e68-4d1e-b12d-27841f7683af",
   "metadata": {},
   "source": [
    "#### POS tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de63c0a-8008-4031-8948-3cebe6b783a1",
   "metadata": {},
   "source": [
    "POS tagging involves identifying the grammatical category of each word, such as nouns, verbs, and adjectives, providing a basic syntactic framework. \n",
    "The POS annotations related to Bulgarian can be found [here](https://universaldependencies.org/bg/pos/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e259e-049e-47a5-b347-4f8fccda586d",
   "metadata": {},
   "source": [
    "- **NOUN**: Noun - A word representing a person, place, thing, or idea.\n",
    "- **AUX**: Auxiliary - A verb used to form tenses, moods, or voices of other verbs.\n",
    "- **ADJ**: Adjective - A word that describes or modifies a noun.\n",
    "- **PUNCT**: Punctuation - A symbol used to separate sentences and clarify meaning.\n",
    "- **VERB**: Verb - A word that describes an action, occurrence, or state.\n",
    "- **ADV**: Adverb - A word that modifies a verb, adjective, or other adverbs.\n",
    "- **PRON**: Pronoun - A word that takes the place of a noun.\n",
    "- **DET**: Determiner - A word that introduces a noun (e.g., 'the', 'a').\n",
    "- **ADP**: Adposition - A word governing a noun or pronoun (prepositions/postpositions).\n",
    "- **CONJ**: Conjunction - A word used to connect clauses or sentences.\n",
    "- **NUM**: Numeral - A word that expresses numbers.\n",
    "- **PART**: Particle - A word that has a grammatical function but does not fit into other categories.\n",
    "- **INTJ**: Interjection - An abrupt remark, often an exclamation.\n",
    "- **PROPN**: Proper Noun - A specific name for a person, place, or thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32a5d5-c3fe-4cdc-82df-baf35ef8425b",
   "metadata": {},
   "source": [
    "#### TAG annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0db37-3127-4420-9451-6c81678328d0",
   "metadata": {},
   "source": [
    "TAG delves deeper by analyzing the morphological aspects of words, revealing tense, number, and case, which enriches the linguistic context. This is a non-exhaustive list, there are other annotations like verb tense, but they are not related to definite article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fa722-95ef-48a9-824d-a91020b0c5e2",
   "metadata": {},
   "source": [
    "- **A**: Adjective\n",
    "- **C**: Cardinal number\n",
    "- **D**: Determiner\n",
    "- **I**: Interjection\n",
    "- **M**: Masculine agreement\n",
    "- **N**: Noun\n",
    "- **P**: Pronoun\n",
    "- **Q**: Clitic\n",
    "- **R**: Adverb\n",
    "- **S**: Preposition or postposition\n",
    "- **T**: Particle\n",
    "- **V**: Verb\n",
    "- **X**: Other (unknown)\n",
    "- **c**: Common noun\n",
    "- **d**: Definite article\n",
    "- **f**: Feminine gender\n",
    "- **h**: Definite article, short form\n",
    "- **i**: Indefinite article\n",
    "- **m**: Masculine gender\n",
    "- **n**: Neuter gender\n",
    "- **p**: Plural number\n",
    "- **p**: Proper noun\n",
    "- **s**: Singular number\n",
    "- **t**: Third person\n",
    "- **x**: Auxiliary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcdf952-4fdb-471d-b3e2-9e71cd228756",
   "metadata": {},
   "source": [
    "#### DEP tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f8bd77-cc3d-4857-9322-99ab7cd976e5",
   "metadata": {},
   "source": [
    "DEP focuses on the syntactic relationships between words, mapping out how they depend on one another to form coherent sentences. Dependencies, specific to Bulgarian are defined [here](https://universaldependencies.org/bg/dep/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ab571-273f-4f05-aa61-1d63384deb6b",
   "metadata": {},
   "source": [
    "- **acl**: Clausal modifier of a noun (adjectival clause)\n",
    "- **advcl**: Adverbial clause modifier\n",
    "- **advmod**: Adverbial modifier\n",
    "- **amod**: Adjectival modifier\n",
    "- **appos**: Appositional modifier\n",
    "- **aux**: Auxiliary (non-main) verb\n",
    "- **case**: Case marking (prepositions and postpositions)\n",
    "- **cc**: Coordinating conjunction\n",
    "- **ccomp**: Clausal complement (with a subject)\n",
    "- **clf**: Classifier\n",
    "- **compound**: Compound noun or other compound\n",
    "- **conj**: Conjunct (member of a conjunction)\n",
    "- **cop**: Copula (Linking verb)\n",
    "- **csubj**: Clausal subject\n",
    "- **dep**: Unspecified dependency (generic)\n",
    "- **det**: Determiner\n",
    "- **discourse**: Discourse element\n",
    "- **dislocated**: Dislocated elements\n",
    "- **expl**: Expletive (like 'there' in 'there is')\n",
    "- **fixed**: Fixed multiword expression\n",
    "- **flat**: Flat multiword expression (e.g., proper names)\n",
    "- **goeswith**: Goes with (used for broken-up words)\n",
    "- **iobj**: Indirect object\n",
    "- **list**: List (for chains of items)\n",
    "- **mark**: Marker (e.g., subordinating conjunction)\n",
    "- **nmod**: Nominal modifier\n",
    "- **nsubj**: Nominal subject\n",
    "- **nummod**: Numeric modifier\n",
    "- **obj**: Direct object\n",
    "- **obl**: Oblique nominal (usually adverbials)\n",
    "- **orphan**: Orphan (used for incomplete constructions)\n",
    "- **parataxis**: Parataxis (side-by-side clauses)\n",
    "- **punct**: Punctuation\n",
    "- **reparandum**: Reparandum (used in speech for corrections)\n",
    "- **root**: Root of the sentence\n",
    "- **vocative**: Vocative (direct address)\n",
    "- **xcomp**: Open clausal complement (without a subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4992f6d-bfa2-44e9-8c58-8ba891bde1e0",
   "metadata": {},
   "source": [
    "## Experiments with Stanza and UDPipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5dc22e-c6f1-4706-9b2f-e771890bcf45",
   "metadata": {},
   "source": [
    "Stanza and UDPipe provide similar functionalities in terms of NLP features. However, two differences are important. Stanza is based on neural networks whereas UDPipe is rule-based. Furthermore, UDPipe produces output in a different format that needs to be converted to what SpaCy understands. \n",
    "\n",
    "Since no information is available on which of them is more suitable specifically for Bulgarian, we need to perform some experiments and decide ourselves.\n",
    "\n",
    "We will experiment with three properties:\n",
    "\n",
    "* supported features\n",
    "* splitting into sentences\n",
    "* performance with large amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db3f3a8-f662-4859-a172-c7487ada73a1",
   "metadata": {},
   "source": [
    "### Download and initialize Bulgarian models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e47b4ec9-8167-49c8-bba6-294fb4af2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Stanza\n",
    "if not os.path.isdir(\"./stanza_resources/bg\"):\n",
    "    stanza.download(\"bg\", model_dir=\"./stanza_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce83e48-74be-44de-bbb3-93bd76c8d883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bulgarian-btb-ud-2.5-191206.udpipe',\n",
       " <http.client.HTTPMessage at 0x2427b1c5ac0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the UDPipe Bulgarian model\n",
    "model_url_udpipe = \"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/bulgarian-btb-ud-2.5-191206.udpipe?sequence=6&isAllowed=y\"\n",
    "model_filename_udpipe = \"bulgarian-btb-ud-2.5-191206.udpipe\"\n",
    "urllib.request.urlretrieve(model_url_udpipe, model_filename_udpipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9805b10-8ea6-4462-a30d-503bf3b229af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 18:52:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc8c98977df4964abc5b3fde1a70d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 18:52:48 INFO: Loading these models for language: bg (Bulgarian):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | btb          |\n",
      "| pos       | btb_charlm   |\n",
      "| lemma     | btb_nocharlm |\n",
      "| depparse  | btb_charlm   |\n",
      "| ner       | bsnlp19      |\n",
      "============================\n",
      "\n",
      "2024-08-22 18:52:48 WARNING: GPU requested, but is not available!\n",
      "2024-08-22 18:52:48 INFO: Using device: cpu\n",
      "2024-08-22 18:52:48 INFO: Loading: tokenize\n",
      "2024-08-22 18:52:50 INFO: Loading: pos\n",
      "2024-08-22 18:52:50 INFO: Loading: lemma\n",
      "2024-08-22 18:52:50 INFO: Loading: depparse\n",
      "2024-08-22 18:52:50 INFO: Loading: ner\n",
      "2024-08-22 18:52:51 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spacy_stanza nlp pipeline\n",
    "nlp_spacy_stanza = spacy_stanza.load_pipeline(\"bg\", dir=\"./stanza_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c8e261-95cd-4193-b25f-40b99b7b801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UDPipe nlp pipeline\n",
    "model_udpipe = Model.load(model_filename_udpipe)\n",
    "pipeline_udpipe = Pipeline(model_udpipe, \"tokenize\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\")\n",
    "nlp_spacy_udpipe = spacy.blank(\"bg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66b855-df4c-41d0-9761-b65813309cf2",
   "metadata": {},
   "source": [
    "### Define initial functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b6ee7-285a-47e6-a5a0-9c5c6d37c0c8",
   "metadata": {},
   "source": [
    "We need some functions for creating the NLP objects for Stanza and UDPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb8d1c4-7f37-47f6-926c-88f36e66f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def udpipe_to_spacy(text, nlp):\n",
    "    \"\"\"Parses a CoNLL-U formatted string into a spaCy Doc object.\"\"\"\n",
    "    doc_str = pipeline_udpipe.process(text)\n",
    "    lines = doc_str.strip().splitlines()\n",
    "    words = []\n",
    "    lemmas = []\n",
    "    spaces = []\n",
    "    pos_tags = []\n",
    "    morph_tags = []\n",
    "    dep_heads = []\n",
    "    dep_rels = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"#\") or not line.strip():\n",
    "            continue\n",
    "\n",
    "        parts = line.split(\"\\t\")\n",
    "        index, word, lemma, pos, tag, feats, head, dep_rel, _, misc = parts\n",
    "\n",
    "        words.append(word)\n",
    "        lemmas.append(lemma)\n",
    "        pos_tags.append(pos)  # POS tag (simpler POS category)\n",
    "        morph_tags.append(tag)  # Detailed morphological tag\n",
    "        dep_heads.append(int(head) - 1)  # Convert to zero-indexed\n",
    "        dep_rels.append(dep_rel)\n",
    "\n",
    "        if \"SpaceAfter=No\" in misc:\n",
    "            spaces.append(False)\n",
    "        else:\n",
    "            spaces.append(True)\n",
    "\n",
    "    # Create the Doc object\n",
    "    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "    # Set the POS tags, morphological tags, lemmas, and dependency parsing information\n",
    "    for token, lemma, pos, morph_tag, head, dep_rel in zip(doc, lemmas, pos_tags, morph_tags, dep_heads, dep_rels):\n",
    "        token.lemma_ = lemma\n",
    "        token.pos_ = pos  # Simple POS tag\n",
    "        token.tag_ = morph_tag  # Detailed morphological tag\n",
    "        token.head = doc[head] if head >= 0 else token\n",
    "        token.dep_ = dep_rel\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9969540-33d8-4e8b-8d39-9f6ce85c5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_st(txt):\n",
    "    return nlp_spacy_stanza(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babaecc9-7543-4510-bd5c-b37b88e1b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_ud(txt):\n",
    "    return udpipe_to_spacy(txt, nlp_spacy_udpipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7dab88-0168-481c-a3ff-cd130a69dfb1",
   "metadata": {},
   "source": [
    "### Compare NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94ece13-75b0-4531-b845-f8b382992548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function for displaying useful NLP features in easy to read format\n",
    "def inspect_spacy_doc(doc):\n",
    "    for token in doc:\n",
    "        print(f\"Token: {token.text:<15} Tag: {token.tag_:<15} POS: {token.pos_:<10} Lemma: {token.lemma_:<15} Dep: {token.dep_:<10}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63283d73-0b39-49b5-8666-6e82566ece38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP features from Stanza:\n",
      "Token: Сред            Tag: R               POS: ADP        Lemma: сред            Dep: case      \n",
      "Token: гостите         Tag: Ncmpd           POS: NOUN       Lemma: гост            Dep: root      \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: официалната     Tag: Afsd            POS: ADJ        Lemma: официален       Dep: amod      \n",
      "Token: церемония       Tag: Ncfsi           POS: NOUN       Lemma: церемония       Dep: nmod      \n",
      "Token: по              Tag: R               POS: ADP        Lemma: по              Dep: case      \n",
      "Token: встъпване       Tag: Ncnsi           POS: NOUN       Lemma: встъпване       Dep: nmod      \n",
      "Token: в               Tag: R               POS: ADP        Lemma: в               Dep: case      \n",
      "Token: длъжност        Tag: Ncfsi           POS: NOUN       Lemma: длъжност        Dep: nmod      \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: новоизбрания    Tag: Amsh            POS: ADJ        Lemma: новоизбран      Dep: amod      \n",
      "Token: президент       Tag: Ncmsi           POS: NOUN       Lemma: президент       Dep: nmod      \n",
      "Token: ще              Tag: Tx              POS: AUX        Lemma: ще              Dep: aux       \n",
      "Token: бъдат           Tag: Vyptf-r3p       POS: AUX        Lemma: бъда            Dep: cop       \n",
      "Token: българският     Tag: Amsf            POS: ADJ        Lemma: български       Dep: amod      \n",
      "Token: държавен        Tag: Amsi            POS: ADJ        Lemma: държавен        Dep: amod      \n",
      "Token: глава           Tag: Ncmsi           POS: NOUN       Lemma: глава           Dep: nsubj     \n",
      "Token: Румен           Tag: Npmsi           POS: PROPN      Lemma: румен           Dep: nmod      \n",
      "Token: Радев           Tag: Hmsi            POS: PROPN      Lemma: радев           Dep: flat      \n",
      "Token: ,               Tag: punct           POS: PUNCT      Lemma: ,               Dep: punct     \n",
      "Token: президентът     Tag: Ncmsf           POS: NOUN       Lemma: президент       Dep: conj      \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: Албания         Tag: Npfsi           POS: PROPN      Lemma: албания         Dep: nmod      \n",
      "Token: Илир            Tag: Npmsi           POS: PROPN      Lemma: илир            Dep: nmod      \n",
      "Token: Мета            Tag: Hmsi            POS: PROPN      Lemma: мета            Dep: flat      \n",
      "Token: и               Tag: Cp              POS: CCONJ      Lemma: и               Dep: cc        \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: Косово          Tag: Npnsi           POS: PROPN      Lemma: косово          Dep: conj      \n",
      "Token: Хашим           Tag: Npmsi           POS: PROPN      Lemma: хашим           Dep: nmod      \n",
      "Token: Тачи            Tag: Hmsi            POS: PROPN      Lemma: тачи            Dep: flat      \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n",
      "\n",
      "NLP features from UDPipe:\n",
      "Token: Сред            Tag: R               POS: ADP        Lemma: сред            Dep: case      \n",
      "Token: гостите         Tag: Ncmpd           POS: NOUN       Lemma: гост            Dep: nmod      \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: официалната     Tag: Afsd            POS: ADJ        Lemma: официален       Dep: amod      \n",
      "Token: церемония       Tag: Ncfsi           POS: NOUN       Lemma: церемония       Dep: nmod      \n",
      "Token: по              Tag: R               POS: ADP        Lemma: по              Dep: case      \n",
      "Token: встъпване       Tag: Ncnsi           POS: NOUN       Lemma: встъпване       Dep: nmod      \n",
      "Token: в               Tag: R               POS: ADP        Lemma: в               Dep: case      \n",
      "Token: длъжност        Tag: Ncfsi           POS: NOUN       Lemma: длъжност        Dep: nmod      \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: новоизбрания    Tag: Amsh            POS: ADJ        Lemma: новоизбрам      Dep: amod      \n",
      "Token: президент       Tag: Ncmsi           POS: NOUN       Lemma: президент       Dep: nmod      \n",
      "Token: ще              Tag: Tx              POS: AUX        Lemma: ще              Dep: aux       \n",
      "Token: бъдат           Tag: Vyptf-r3p       POS: AUX        Lemma: бъда            Dep: cop       \n",
      "Token: българският     Tag: Amsf            POS: ADJ        Lemma: български       Dep: amod      \n",
      "Token: държавен        Tag: Amsi            POS: ADJ        Lemma: държавен        Dep: amod      \n",
      "Token: глава           Tag: Ncmsi           POS: NOUN       Lemma: глава           Dep: root      \n",
      "Token: Румен           Tag: Npmsi           POS: PROPN      Lemma: румен           Dep: nmod      \n",
      "Token: Радев           Tag: Hmsi            POS: PROPN      Lemma: радев           Dep: flat      \n",
      "Token: ,               Tag: punct           POS: PUNCT      Lemma: ,               Dep: punct     \n",
      "Token: президентът     Tag: Ncmsf           POS: NOUN       Lemma: президент       Dep: nsubj     \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: Албания         Tag: Npfsi           POS: PROPN      Lemma: албания         Dep: nmod      \n",
      "Token: Илир            Tag: Hfsi            POS: PROPN      Lemma: Илир            Dep: nmod      \n",
      "Token: Мета            Tag: Npfsi           POS: PROPN      Lemma: Мета            Dep: flat      \n",
      "Token: и               Tag: Cp              POS: CCONJ      Lemma: и               Dep: cc        \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: Косово          Tag: Npnsi           POS: PROPN      Lemma: косово          Dep: conj      \n",
      "Token: Хашим           Tag: Npmsi           POS: PROPN      Lemma: Хашим           Dep: flat      \n",
      "Token: Тачи            Tag: Tv              POS: PART       Lemma: Тача            Dep: discourse \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"Сред гостите на официалната церемония по встъпване в длъжност на новоизбрания президент ще бъдат българският \\\n",
    "държавен глава Румен Радев, президентът на Албания Илир Мета и на Косово Хашим Тачи.\"\"\"\n",
    "doc_st = nlp_st(sentence)\n",
    "doc_ud = nlp_ud(sentence)\n",
    "\n",
    "print(\"NLP features from Stanza:\")\n",
    "inspect_spacy_doc(doc_st)\n",
    "\n",
    "print(\"\\nNLP features from UDPipe:\")\n",
    "inspect_spacy_doc(doc_ud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67100480-b022-4d10-b067-b16992c811d1",
   "metadata": {},
   "source": [
    "It appears that Stanza is dealing a bit better with the identification of the tags and the gender. Also, one particular lemma (_новоизбрам_) was wrong by UDPipe.\n",
    "\n",
    "<img src=\"images/compare_stanza_udpipe.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd96ef-64f6-4dcf-a3aa-f479d8eceb9e",
   "metadata": {},
   "source": [
    "### Compare splitting into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37b8c6c-f093-4951-b3eb-ca3baa24aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentences = [\"Аз отивам в офиса.\", \"Иван отива в офиса.\", \"Офисът е в София.\"]\n",
    "invalid_sentences = [\"Аз отивам в офисът.\", \"Иван отива в офисът.\", \"Офиса е в София.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08065d88-e46a-4530-8d7f-72e7f1ded7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_st = nlp_st(\" \".join(valid_sentences))\n",
    "docs_ud = nlp_ud(\" \".join(valid_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9f9860-ee32-42f6-af24-84a5b42e2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into sentences using Stanza:\n",
      "\n",
      "Аз отивам в офиса.\n",
      "Иван отива в офиса.\n",
      "Офисът е в София.\n",
      "\n",
      "Split into sentences using UDPipe:\n",
      "\n",
      "Аз отивам в офиса. Иван\n",
      "отива в офиса. Офисът е в\n",
      "София.\n"
     ]
    }
   ],
   "source": [
    "print(\"Split into sentences using Stanza:\\n\")\n",
    "for sent in list(docs_st.sents):\n",
    "    print(sent)\n",
    "\n",
    "print(\"\\nSplit into sentences using UDPipe:\\n\")\n",
    "for sent in list(docs_ud.sents):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03f3d7-f412-46cd-b815-1a616182d57f",
   "metadata": {},
   "source": [
    "For some reason Stanza copes with sentence division whereas UDPipe does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48993890-ac0d-46d3-af2b-c5efc329681b",
   "metadata": {},
   "source": [
    "### Compare performance with large amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "584a0d7b-3e74-4c18-9dbc-becf2144a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with 10 rows, use same sentence for simplicity\n",
    "test_df = pd.DataFrame({\"text\": [sentence] * 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e16bfd3-ae98-4980-9ceb-18ac29eadfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_features_to_string(sent):\n",
    "    \"\"\"Converts sentence features to strings\"\"\"\n",
    "    pos = \",\".join([tk.pos_ for tk in sent])\n",
    "    tag = \",\".join([tk.tag_ for tk in sent])\n",
    "    dep = \",\".join([tk.dep_ for tk in sent])\n",
    "    morph = \",\".join([str(tk.morph) for tk in sent])\n",
    "    lemmas = \",\".join([str(tk.lemma_) for tk in sent])\n",
    "    ledge = \",\".join([str(tk.left_edge) for tk in sent])\n",
    "    redge = \",\".join([str(tk.right_edge) for tk in sent])\n",
    "    n_tokens = len(sent)\n",
    "\n",
    "    return pos, tag, dep, morph, lemmas, ledge, redge, n_tokens\n",
    "\n",
    "\n",
    "def extract_features(nlp, row, col):\n",
    "    \"\"\"Extracts linguistic features from a text column using a given NLP model\"\"\"\n",
    "    value = row[col]\n",
    "    doc = nlp(value)\n",
    "    return sent_features_to_string(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627136d-866d-436a-8796-bea32b10e32a",
   "metadata": {},
   "source": [
    "#### Extracting features using Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a489328e-bd92-41c0-a1a8-2bcc0d201f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_df[[\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_words\"]] = test_df.apply(\n",
    "    lambda r: extract_features(nlp_st, r, \"text\"), axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_st = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f483e6-4278-47b3-b550-06bfb838241d",
   "metadata": {},
   "source": [
    "#### Extracting features using UDPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c65572e8-e775-4e62-83c0-f083a622792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_df[[\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_words\"]] = test_df.apply(\n",
    "    lambda r: extract_features(nlp_ud, r, \"text\"), axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_ud = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a8804-5952-40c5-ae60-efce738a0e4b",
   "metadata": {},
   "source": [
    "#### Comparison of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ea16f7-cd38-4e0c-9993-58e2028ef2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time (stanza): 16.41700053215027 seconds\n",
      "Execution time (udpipe): 0.3071177005767822 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Execution time (stanza): {execution_time_st} seconds\")\n",
    "print(f\"Execution time (udpipe): {execution_time_ud} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37a288-3cf9-4a46-b2b8-f32eadb66e08",
   "metadata": {},
   "source": [
    "The output indicates that Stanza took much longer to execute compared to UDPipe for the same task of extracting NLP features from 10 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faccc383-ae15-4974-ac25-65ca58018232",
   "metadata": {},
   "source": [
    "#### Final verdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46863683-9bcf-4f60-bdb0-5186b744592e",
   "metadata": {},
   "source": [
    "Stanza in much better at splitting into sentences and supports more features, whereas UDPipe has significantly better performance. So the next steps will be performed mainly with Stanza in order to get more accurate results but let's be open to the possibility of using UDPipe in certain situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9f655-d5ac-44f6-869a-559ce8bef07c",
   "metadata": {},
   "source": [
    "## Proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ea0a8-81f4-41a8-a8bd-0cfbc0b18594",
   "metadata": {},
   "source": [
    "Let's create a minimal program as a proof of concept. The goal is to illustrate the idea behind text processing and determining the correctness of the definite article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048c5b4-4d8a-49a5-97f4-b57324db39b1",
   "metadata": {},
   "source": [
    "### Define one rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6dc2e2-de7b-4fcd-8561-9ca0728e0bc9",
   "metadata": {},
   "source": [
    "Define one simple rule and put it in a testing function. The rule is: if the word is a noun, is preceded by a preposition, and ends in _ът_ or _ят_, then the long form of the definite article is incorrect. Note that in reality this rule is not enough to determine the correct usage of the definite article but for the purposes of the POC it will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f305d53d-1558-4b91-a9bc-a17648f10692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_definite_article(doc):\n",
    "    \"\"\"Detects incorrect usage of the definite article based on POS tags and word endings\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        # Check if the token is a noun with a definite article (full form)\n",
    "        if token.pos_ == \"NOUN\" and token.text.endswith((\"ът\", \"ят\")):\n",
    "            # Check if the preceding token is a preposition (ADP), like \"в\"\n",
    "            if i > 0 and doc[i - 1].pos_ == \"ADP\":\n",
    "                errors.append(f\"Incorrect usage of full definite article: '{token.text}' in sentence: '{doc.text}'\")\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5876a5-24fd-458e-9863-dc29e362648b",
   "metadata": {},
   "source": [
    "### Test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72660762-a0a3-4959-8584-106f8da8aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sentences = [\"Аз отивам в офиса.\", \"Иван отива в офиса.\", \"Офисът е в София.\"]\n",
    "invalid_sentences = [\"Аз отивам в офисът.\", \"Иван отива в офисът.\", \"Офиса е в София.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0055be9d-9da9-4d72-83cf-d64e2a673171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each sentence with both libraries\n",
    "results_st = []\n",
    "results_ud = []\n",
    "for sentence in valid_sentences + invalid_sentences:\n",
    "    doc_st = nlp_st(sentence)\n",
    "    doc_ud = nlp_ud(sentence)\n",
    "\n",
    "    results_st.append(verify_definite_article(doc_st))\n",
    "    results_ud.append(verify_definite_article(doc_ud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673d0434-1d1b-45fe-ada4-354655d515d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from Stanza:\n",
      "1: []\n",
      "2: []\n",
      "3: []\n",
      "4: [\"Incorrect usage of full definite article: 'офисът' in sentence: 'Аз отивам в офисът.'\"]\n",
      "5: [\"Incorrect usage of full definite article: 'офисът' in sentence: 'Иван отива в офисът.'\"]\n",
      "6: []\n",
      "\n",
      "Results from UDPipe:\n",
      "1: []\n",
      "2: []\n",
      "3: []\n",
      "4: [\"Incorrect usage of full definite article: 'офисът' in sentence: 'Аз отивам в офисът. '\"]\n",
      "5: [\"Incorrect usage of full definite article: 'офисът' in sentence: 'Иван отива в офисът. '\"]\n",
      "6: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Results from Stanza:\")\n",
    "for i, res in enumerate(results_st):\n",
    "    print(f\"{i+1}:\", res)\n",
    "\n",
    "print(\"\\nResults from UDPipe:\")\n",
    "for i, res in enumerate(results_ud):\n",
    "    print(f\"{i+1}:\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9fc97-3036-481f-b6d0-e4665d06d35d",
   "metadata": {},
   "source": [
    "Of course we can't expect much correctness of this simple rule but we can see that it did find some incorrect usages in two out of the six cases. Not bad, actually!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf4369-b8bf-4a7c-b5bd-fc91d293836f",
   "metadata": {},
   "source": [
    "## Load and clean the testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d453a7-4c3f-48ca-878a-176923b8f758",
   "metadata": {},
   "source": [
    "This short set of sentences contains some common misuses of the definite article and also the correct usage. We will use this set for initial testing of the rules we develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d88601c9-be0a-4ba3-907c-5209c22682a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1 = pd.read_csv(\"data/test_set_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9179b26-66ba-4f32-a551-d5dad82a5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Ключа е на масата.</td>\n",
       "      <td>Ключът е на масата.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Царя пие вино.</td>\n",
       "      <td>Царят пие вино.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Ученика е умен и трудолюбив.</td>\n",
       "      <td>Ученикът е умен и трудолюбив.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Приятеля ми е в чужбина.</td>\n",
       "      <td>Приятелят ми е в чужбина.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Госта пристигна.</td>\n",
       "      <td>Гостът пристигна.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error_type                     incorrect                        correct\n",
       "0  article_misuse            Ключа е на масата.            Ключът е на масата.\n",
       "1  article_misuse                Царя пие вино.                Царят пие вино.\n",
       "2  article_misuse  Ученика е умен и трудолюбив.  Ученикът е умен и трудолюбив.\n",
       "3  article_misuse      Приятеля ми е в чужбина.      Приятелят ми е в чужбина.\n",
       "4  article_misuse              Госта пристигна.              Гостът пристигна."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075343a4-74e5-408c-8bd0-2b73d6ddf900",
   "metadata": {},
   "source": [
    "### Trim the sentences of whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bd8d67c-b9a0-4e88-9eec-1d1739fc1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1[['incorrect', 'correct']] = test_set_1[['incorrect', 'correct']].map(str.strip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396147b-97bf-49e4-98b2-b43883de89cf",
   "metadata": {},
   "source": [
    "### Add column with the differing words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65992d0c-4925-4ef4-adbc-7280f875a0e0",
   "metadata": {},
   "source": [
    "In order to perform automated tests we will need to know were exactly is the error in the sentence, if there is an error. Therefore, we'll add a new column with the expected incorrect words. Before that we need to do some cleaning like removal of punctuation. Note that this function is designed to work with Bulgarian in order to keep words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2bd8914-cd81-4f10-a4fe-f466ae6499b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence_bg(sentence):\n",
    "    \"\"\"Cleans a Bulgarian sentence by removing unwanted punctuation but preserving valid dashes.\"\"\"\n",
    "    # Remove dashes not surrounded by exactly two bg letters\n",
    "    # keep also numbers in order to preserve words like 5-годишен\n",
    "    sentence = re.sub(r\"(?<![0-9а-яА-Я])-|-(?![а-яА-Я])\", \"\", sentence)\n",
    "\n",
    "    # Remove all other punctuation except for valid dashes\n",
    "    sentence = re.sub(r\"[^\\w\\s-]\", \"\", sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "434546f4-61b6-4c09-a523-f7b0270565ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_differing_words(row):\n",
    "    \"\"\"Extracts differing words between two sentences and logs word count discrepancies.\"\"\"\n",
    "    # Clean and split the sentences into words\n",
    "    incorrect_words = clean_sentence_bg(row[\"incorrect\"]).split()\n",
    "    correct_words = clean_sentence_bg(row[\"correct\"]).split()\n",
    "\n",
    "    # Log if word count differs\n",
    "    if len(incorrect_words) != len(correct_words):\n",
    "        print(f\"Word count differs: Incorrect - {len(incorrect_words)} words, Correct - {len(correct_words)} words\")\n",
    "\n",
    "    # Get words from the correct sentence that are not in the incorrect sentence\n",
    "    differing_correct_words = [word for word in correct_words if word not in incorrect_words]\n",
    "    differing_incorrect_words = [word for word in incorrect_words if word not in correct_words]\n",
    "\n",
    "    return \",\".join(differing_incorrect_words), \",\".join(differing_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ad39063-05c2-42fd-b3fd-62b3405eb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to hold the correct and incorrect words, they will be used for automated testing\n",
    "test_set_1[[\"correct_words\", \"incorrect_words\"]] = test_set_1.apply(get_differing_words, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af0ffb9f-f844-4ed6-b28a-915929a5db25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "      <th>correct_words</th>\n",
       "      <th>incorrect_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Ключа е на масата.</td>\n",
       "      <td>Ключът е на масата.</td>\n",
       "      <td>Ключа</td>\n",
       "      <td>Ключът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Царя пие вино.</td>\n",
       "      <td>Царят пие вино.</td>\n",
       "      <td>Царя</td>\n",
       "      <td>Царят</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Ученика е умен и трудолюбив.</td>\n",
       "      <td>Ученикът е умен и трудолюбив.</td>\n",
       "      <td>Ученика</td>\n",
       "      <td>Ученикът</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error_type                     incorrect  \\\n",
       "0  article_misuse            Ключа е на масата.   \n",
       "1  article_misuse                Царя пие вино.   \n",
       "2  article_misuse  Ученика е умен и трудолюбив.   \n",
       "\n",
       "                         correct correct_words incorrect_words  \n",
       "0            Ключът е на масата.         Ключа          Ключът  \n",
       "1                Царят пие вино.          Царя           Царят  \n",
       "2  Ученикът е умен и трудолюбив.       Ученика        Ученикът  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56036cc3-4e21-4fe5-a7bf-cc589f065371",
   "metadata": {},
   "source": [
    "### Melt and sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92405dd7-be0b-4232-a6bd-30626f4866ad",
   "metadata": {},
   "source": [
    "Merge the columns _incorrect_ and _correct_ to a single column _text_. Keep each pair of incorrect and correct sentences together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c902ec4-4227-448c-a958-2350601f074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_and_sort_sentences(df):\n",
    "    \"\"\"Transforms a DataFrame to melt sentence pairs, ensuring incorrect and correct sentences are paired.\"\"\"\n",
    "\n",
    "    # Swap 'incorrect_words' and 'correct_words' columns\n",
    "    df = df.rename(columns={\"incorrect_words\": \"temp_correct_words\", \"correct_words\": \"incorrect_words\"})\n",
    "    df = df.rename(columns={\"temp_correct_words\": \"correct_words\"})\n",
    "\n",
    "    # Add an order column to keep track of the original order\n",
    "    df[\"order\"] = df.index\n",
    "\n",
    "    # Melt the DataFrame\n",
    "    df_melted = pd.melt(\n",
    "        df,\n",
    "        id_vars=[\"correct_words\", \"incorrect_words\", \"order\"],\n",
    "        value_vars=[\"incorrect\", \"correct\"],\n",
    "        var_name=\"is_correct\",\n",
    "        value_name=\"text\",\n",
    "    )\n",
    "\n",
    "    # Set 'is_correct' to True for 'correct' and False for 'incorrect'\n",
    "    df_melted[\"is_correct\"] = df_melted[\"is_correct\"].apply(lambda x: x == \"correct\")\n",
    "\n",
    "    # Assign incorrect_words and correct_words only to incorrect sentences\n",
    "    df_melted[\"incorrect_words\"] = df_melted.apply(lambda row: row[\"incorrect_words\"] if not row[\"is_correct\"] else \"\", axis=1)\n",
    "    df_melted[\"correct_words\"] = df_melted.apply(lambda row: row[\"correct_words\"] if not row[\"is_correct\"] else \"\", axis=1)\n",
    "\n",
    "    # Sort by 'order' to ensure the pairs of correct/incorrect sentences are next to each other\n",
    "    df_melted = df_melted.sort_values(by=[\"order\", \"is_correct\"], ascending=[True, True])\n",
    "\n",
    "    # Reset index for clean output\n",
    "    df_melted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Drop the 'order' column as it's no longer needed\n",
    "    df_melted = df_melted.drop(columns=[\"order\"])\n",
    "\n",
    "    # Reorder columns to match the desired output\n",
    "    df_melted = df_melted[[\"text\", \"is_correct\", \"incorrect_words\", \"correct_words\"]]\n",
    "\n",
    "    return df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b368a83-0501-4d8b-afd2-836bb023b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1 = melt_and_sort_sentences(test_set_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a12427b-7fd4-4cb8-b397-1a1cd8e5d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>incorrect_words</th>\n",
       "      <th>correct_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ключа е на масата.</td>\n",
       "      <td>False</td>\n",
       "      <td>Ключа</td>\n",
       "      <td>Ключът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ключът е на масата.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Царя пие вино.</td>\n",
       "      <td>False</td>\n",
       "      <td>Царя</td>\n",
       "      <td>Царят</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Царят пие вино.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ученика е умен и трудолюбив.</td>\n",
       "      <td>False</td>\n",
       "      <td>Ученика</td>\n",
       "      <td>Ученикът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ученикът е умен и трудолюбив.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text  is_correct incorrect_words correct_words\n",
       "0             Ключа е на масата.       False           Ключа        Ключът\n",
       "1            Ключът е на масата.        True                              \n",
       "2                 Царя пие вино.       False            Царя         Царят\n",
       "3                Царят пие вино.        True                              \n",
       "4   Ученика е умен и трудолюбив.       False         Ученика      Ученикът\n",
       "5  Ученикът е умен и трудолюбив.        True                              "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7c4f0-8b35-48f9-8030-d114fce7aba9",
   "metadata": {},
   "source": [
    "### Add columns with Stanza NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a64d8fb5-8c07-4646-905f-d7039b4f74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # extract stanza features as new columns\n",
    "    feature_columns_st = [\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_tokens\"]\n",
    "    test_set_1[feature_columns_st] = test_set_1.apply(lambda r: extract_features(nlp_st, r, \"text\"), axis=1, result_type=\"expand\")\n",
    "    \n",
    "    # save in case we want to load it faster\n",
    "    test_set_1.to_csv(\"data/test_set_1_clean.csv\", index=None)\n",
    "else:\n",
    "    # load from file instead of the above, it is faster\n",
    "    test_set_1 = pd.read_csv(\"data/test_set_1_clean.csv\")\n",
    "    test_set_1[\"correct_words\"] = test_set_1[\"incorrect_words\"].fillna(\"\")\n",
    "    test_set_1[\"incorrect_words\"] = test_set_1[\"incorrect_words\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fe578ad-5570-4ece-a36a-98a732bef5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'is_correct', 'incorrect_words', 'correct_words', 'pos', 'tag',\n",
       "       'dep', 'morph', 'lemmas', 'left_edge', 'right_edge', 'num_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b98ea749-b1cb-49d2-b471-9905459b28e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Ключа е на масата.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tokens</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>NOUN,AUX,ADP,NOUN,PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <td>Ncmsh,Vxitf-r3s,R,Ncfsd,punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dep</th>\n",
       "      <td>nsubj,cop,case,root,punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph</th>\n",
       "      <td>Definite=Def|Gender=Masc|Number=Sing,Aspect=Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemmas</th>\n",
       "      <td>ключ,съм,на,маса,.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left_edge</th>\n",
       "      <td>Ключа,е,на,Ключа,.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_edge</th>\n",
       "      <td>Ключа,е,на,.,.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0\n",
       "text                                       Ключа е на масата.\n",
       "num_tokens                                                  5\n",
       "pos                                   NOUN,AUX,ADP,NOUN,PUNCT\n",
       "tag                             Ncmsh,Vxitf-r3s,R,Ncfsd,punct\n",
       "dep                                 nsubj,cop,case,root,punct\n",
       "morph       Definite=Def|Gender=Masc|Number=Sing,Aspect=Im...\n",
       "lemmas                                     ключ,съм,на,маса,.\n",
       "left_edge                                  Ключа,е,на,Ключа,.\n",
       "right_edge                                     Ключа,е,на,.,."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_1[[\"text\", \"num_tokens\", \"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\"]].head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07173321-5f86-4bae-9c5a-4aeaf2abaf32",
   "metadata": {},
   "source": [
    "## Define rule based logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07626842-f1cf-45f1-b22f-241892a589f4",
   "metadata": {},
   "source": [
    "### Implement NLP specific functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6836b6-0950-40d6-950a-e7803216513e",
   "metadata": {},
   "source": [
    "This section contains functions that extract grammatical details like gender, number, and sentence role from tagged words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fea25698-beaa-458b-851b-e42b18a31233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gender_from_tag(tag):\n",
    "    gender = \" \"\n",
    "    # gender is applicable to common noun, proper noun or adjective\n",
    "    if tag.startswith((\"Nc\", \"Np\", \"A\")):  \n",
    "        if \"m\" in tag:\n",
    "            gender = \"Masculine\"\n",
    "        elif \"f\" in tag:\n",
    "            gender = \"Feminine\"\n",
    "        elif \"n\" in tag:\n",
    "            gender = \"Neutral\"\n",
    "    return gender\n",
    "\n",
    "\n",
    "# TODO: need to exclude triple character patterns like \"p1s\": \"Past tense, 1st person sng\",\n",
    "def extract_number_from_tag(tag):\n",
    "    number = None\n",
    "    if \"s\" in tag:\n",
    "        number = \"Singular\"\n",
    "    elif \"p\" in tag:\n",
    "        number = \"Plural\"\n",
    "    return number\n",
    "\n",
    "\n",
    "def is_masculine(row_dict, i):\n",
    "    tag = row_dict[\"tag\"].split(\",\")[i]\n",
    "    return extract_gender_from_tag(tag) == \"Masculine\"\n",
    "\n",
    "\n",
    "def is_singular(row_dict, i):\n",
    "    tag = row_dict[\"tag\"].split(\",\")[i]\n",
    "    return extract_number_from_tag(tag) == \"Singular\"\n",
    "\n",
    "\n",
    "def is_masculine_singular(row_dict, i):\n",
    "    return is_masculine(row_dict, i) and is_singular(row_dict, i)\n",
    "\n",
    "\n",
    "def is_dep_subject(row_dict, i):\n",
    "    dep = row_dict[\"dep\"].split(\",\")[i]\n",
    "    return dep in {\"nsubj\", \"csubj\", \"nsubj:pass\", \"csubj:pass\"}\n",
    "\n",
    "\n",
    "def nlp_get_pos(row_dict, i):\n",
    "    return row_dict[\"pos\"].split(\",\")[i]\n",
    "\n",
    "\n",
    "def nlp_get_dep(row_dict, i):\n",
    "    return row_dict[\"dep\"].split(\",\")[i]\n",
    "\n",
    "\n",
    "def nlp_get_lemma(row_dict, i):\n",
    "    return row_dict[\"lemmas\"].split(\",\")[i]\n",
    "\n",
    "\n",
    "def nlp_get_article(row_dict, i):\n",
    "    morph = row_dict[\"morph\"].split(\",\")[i]\n",
    "    if \"Definite=Def\" in morph:\n",
    "        return \"definite\"\n",
    "    elif \"Definite=Ind\" in morph:\n",
    "        return \"indefinite\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cce723a8-bf82-4636-ad00-2e438f94c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for quick viewing the features\n",
    "# use updpipe object for the extraction of the word because of performance\n",
    "# use stanza object for determining features because of accuracy\n",
    "def inspect_word(row_dict, word_num):\n",
    "    word = nlp_ud(row_dict[\"text\"])[word_num].text\n",
    "    pos = row_dict[\"pos\"].split(\",\")[word_num]\n",
    "    tag = row_dict[\"tag\"].split(\",\")[word_num]\n",
    "    dep = row_dict[\"dep\"].split(\",\")[word_num]\n",
    "    gen_s = extract_gender_from_tag(tag)[0:1]  # M - Masculine, F - Feminine, N - Neutral\n",
    "    num_s = extract_number_from_tag(tag)[0:1]\n",
    "\n",
    "    return f\"{row_dict['index']} {word:<15} POS:{pos:<{10}} Gen:{gen_s}    Num:{num_s}   DEP:{dep:<{10}} Sent: {row_dict[\"text\"]:<30}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5763a-dac2-4631-9746-6aad52c7be4f",
   "metadata": {},
   "source": [
    "### Implement generic testing function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190505ef-c71c-43a5-85f1-52b072466723",
   "metadata": {},
   "source": [
    "Before we start implementing any rules, we should first create a testing function for them. Since we don’t have the specific rule functions ready, we’ll set up a general testing function - actually, we’ll create three functions - that can take in a list of conditions and a list of rules. It’s important that both lists have the same length. The testing function will process text, apply these conditions and rules to detect errors, and then compare the results with expected outcomes, logging whether each test passes or fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1df9be14-e52e-4fff-8a71-d870153af4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_rules(row_dict, condition_fns, rule_fns):\n",
    "    # ⚠️Make sure the sentence always ends with a punctuation. This is a workaround! \n",
    "    # UDPipe not always separates into tokens correctly, sometimes reports the word+punctuation (or special symbol) as single token.\n",
    "    # Stanza has bad performance and this function is called iteratively multiple times, not a good idea to use Stanza here.\n",
    "    sentence = row_dict[\"text\"] + \".\"  \n",
    "    doc = nlp_ud(sentence)\n",
    "    errors = []\n",
    "\n",
    "    # ⚠️This is a very ugly workaround. UDPipe does not correctly split into tokens when there is punctuation\n",
    "    # in the middle of the sentence. We return \"no errors\" here which might make some tests fail but \n",
    "    # the goal is not to raise an exception. The correct solution is not to use UDPipe at all and pre-calculate the tokens\n",
    "    # in the beginning.\n",
    "    if (len(doc) != row_dict['num_tokens']):\n",
    "        return errors\n",
    "\n",
    "    # Iterate over token pairs with indices\n",
    "    # for i in range(len(doc) - 1):\n",
    "    for i in range(row_dict['num_tokens'] - 1):\n",
    "        token1 = doc[i].text\n",
    "        token2 = doc[i + 1].text\n",
    "\n",
    "        conditions = [condition_fn(row_dict, i) for condition_fn in condition_fns]\n",
    "\n",
    "        for condition, rule_fn in zip(conditions, rule_fns):\n",
    "            if condition:\n",
    "                errors += rule_fn(token1, token2, i)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb26302-028c-4502-9d2c-12af484dd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_definite_article(row_dict, condition_fns, rule_fns):\n",
    "    actual_wrong_words = []\n",
    "    expected_wrong_words = [word.strip() for word in row_dict[\"incorrect_words\"].split(\",\") if word.strip() != \"\"]\n",
    "    actual_wrong_words = all_rules(row_dict, condition_fns, rule_fns)\n",
    "\n",
    "    test_res = \"Pass\" if set(actual_wrong_words) == set(expected_wrong_words) else \"Fail\"\n",
    "\n",
    "    return (test_res, actual_wrong_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "565efc7c-f779-422c-b95a-783792c1543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests all sentences from a dataset that already contains NLP tags\n",
    "def test_definite_article_all(nlp_df, conditions_fns, rules_fns, print_passed=True, print_failed=True, print_total=True):\n",
    "    \"\"\"Tests definite articles in sentences and logs results.\"\"\"\n",
    "    idx_failed, idx_passed = [], []\n",
    "    \n",
    "    for i, row in nlp_df.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        res = test_definite_article(row_dict, conditions_fns, rules_fns)\n",
    "        status, incorrect = res[0], res[1]\n",
    "        \n",
    "        if status == \"Fail\":\n",
    "            idx_failed.append(i)\n",
    "            if print_failed:\n",
    "                print(i, f'❌ {row_dict[\"text\"]} (Actual: \\'{\",\".join(incorrect)}\\', Expected: \\'{row_dict[\"incorrect_words\"]}\\')')\n",
    "        else:\n",
    "            idx_passed.append(i)\n",
    "            message = f'✅ {row_dict[\"text\"]} (\\'{\",\".join(incorrect)}\\' is incorrect)' if incorrect else f'✅ {row_dict[\"text\"]} (The sentence is correct)'\n",
    "            if print_passed:\n",
    "                print(i, message)\n",
    "\n",
    "    if print_total:\n",
    "        n_failed = len(idx_failed)\n",
    "        print(\"✅ All tests passed\" if n_failed == 0 else f\"❌ {n_failed}/{len(nlp_df)} failed.\")\n",
    "        \n",
    "    return idx_passed, idx_failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f6117-22a9-4bd3-aa89-c7761f469411",
   "metadata": {},
   "source": [
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acbd7a-cb63-4649-99c7-3adcf7f83996",
   "metadata": {},
   "source": [
    "#### Implement Rule1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a2b905-b382-43b5-b04a-6722070858d3",
   "metadata": {},
   "source": [
    "According to Rule1, long definite article should be used when the noun takes the role of the subject. Additionally, in order to exclude groups of adjective + noun, which fall under Rule3, we need to exclude noun that follow an adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5925e27c-ed32-43ae-975f-f21d414b7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_rule1(row_dict, i):\n",
    "    \"\"\"Searches for a NOUN, masculine, singular, which is the SUBJECT (nominal or clausal) in the sentence,\n",
    "       and is not preceded by an ADJective\"\"\"    \n",
    "    is_token1_adj = nlp_get_pos(row_dict, i) == \"ADJ\"\n",
    "    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n",
    "    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n",
    "    is_token1_subj = is_dep_subject(row_dict, i)\n",
    "\n",
    "    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n",
    "    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n",
    "    is_token2_subj = is_dep_subject(row_dict, i + 1)\n",
    "\n",
    "    # if token is masculine single noun and subj, but the previous token is not an adjective\n",
    "    if i == 0 and is_token1_masc_sg and is_token1_noun and is_token1_subj:\n",
    "        return True\n",
    "    if i != 0 and not is_token1_adj and is_token2_masc_sg and is_token2_noun and is_token2_subj:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75f5166d-e14e-4eb0-bcc2-aa6d9d6d9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule1(token1, token2, token_idx):\n",
    "    errors = []\n",
    "    word = token1 if token_idx == 0 else token2\n",
    "    if not word.endswith((\"ът\", \"ят\")):\n",
    "        errors.append(word)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bde6f-2651-4911-a195-6271e0dcf858",
   "metadata": {},
   "source": [
    "#### Test Rule1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9be184b3-6d53-4a38-8736-94dc962c4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ✅ Ключа е на масата. ('Ключа' is incorrect)\n",
      "1 ✅ Ключът е на масата. (The sentence is correct)\n",
      "2 ✅ Царя пие вино. ('Царя' is incorrect)\n",
      "3 ✅ Царят пие вино. (The sentence is correct)\n",
      "4 ✅ Ученика е умен и трудолюбив. ('Ученика' is incorrect)\n",
      "5 ✅ Ученикът е умен и трудолюбив. (The sentence is correct)\n",
      "6 ✅ Приятеля ми е в чужбина. ('Приятеля' is incorrect)\n",
      "7 ✅ Приятелят ми е в чужбина. (The sentence is correct)\n",
      "8 ✅ Госта пристигна. ('Госта' is incorrect)\n",
      "9 ✅ Гостът пристигна. (The sentence is correct)\n",
      "10 ❌ Готвача приготви обяда. (Actual: '', Expected: 'Готвача')\n",
      "11 ✅ Готвачът приготви обяда. (The sentence is correct)\n",
      "12 ✅ Влака спря на гара София. ('Влака' is incorrect)\n",
      "13 ✅ Влакът спря на гара София. (The sentence is correct)\n",
      "14 ✅ Учителя говореше за Стефан Стамболов. ('Учителя' is incorrect)\n",
      "15 ✅ Учителят говореше за Стефан Стамболов. (The sentence is correct)\n",
      "16 ❌ Таня търси лекарят. (Actual: '', Expected: 'лекарят')\n",
      "17 ✅ Таня търси лекаря. (The sentence is correct)\n",
      "18 ❌ Говорим за лекарят. (Actual: '', Expected: 'лекарят')\n",
      "19 ✅ Говорим за лекаря. (The sentence is correct)\n",
      "20 ❌ Таня търси Ангел Иванчев, лекарят. (Actual: '', Expected: 'лекарят')\n",
      "21 ✅ Таня търси Ангел Иванчев, лекаря. (The sentence is correct)\n",
      "22 ❌ Говорим за Ангел Иванчев, лекарят. (Actual: '', Expected: 'лекарят')\n",
      "23 ✅ Говорим за Ангел Иванчев, лекаря. (The sentence is correct)\n",
      "24 ❌ Той ми даде ключът от къщата. (Actual: '', Expected: 'ключът')\n",
      "25 ✅ Той ми даде ключа от къщата. (The sentence is correct)\n",
      "26 ❌ Принца говори с царят. (Actual: '', Expected: 'Принца,царят')\n",
      "27 ✅ Принцът говори с царя. (The sentence is correct)\n",
      "28 ❌ Аз помагам на ученикът. (Actual: '', Expected: 'ученикът')\n",
      "29 ✅ Аз помагам на ученика. (The sentence is correct)\n",
      "30 ❌ Много пътници слязоха от влакът. (Actual: '', Expected: 'влакът')\n",
      "31 ✅ Много пътници слязоха от влака. (The sentence is correct)\n",
      "32 ❌ Слушахме с интерес учителят. (Actual: '', Expected: 'учителят')\n",
      "33 ✅ Слушахме с интерес учителя. (The sentence is correct)\n",
      "34 ❌ Дългоочаквания гост дойде. (Actual: '', Expected: 'Дългоочаквания')\n",
      "35 ✅ Дългоочакваният гост дойде. (The sentence is correct)\n",
      "36 ❌ Иван, госта от Сопот, дойде. (Actual: '', Expected: 'госта')\n",
      "37 ✅ Иван, гостът от Сопот, дойде. (The sentence is correct)\n",
      "38 ❌ Иван е съученика ми. (Actual: '', Expected: 'съученика')\n",
      "39 ✅ Иван е съученикът ми. (The sentence is correct)\n",
      "40 ❌ Иван е добрия. (Actual: '', Expected: 'добрия')\n",
      "41 ✅ Иван е добрият. (The sentence is correct)\n",
      "42 ❌ Иван е успелия. (Actual: '', Expected: 'успелия')\n",
      "43 ✅ Иван е успелият. (The sentence is correct)\n",
      "44 ❌ Пешо се оказа най-верния му приятел. (Actual: '', Expected: 'най-верния')\n",
      "45 ✅ Пешо се оказа най-верният му приятел. (The sentence is correct)\n",
      "46 ❌ Пешо се оказа дарителя на училището. (Actual: '', Expected: 'дарителя')\n",
      "47 ✅ Пешо се оказа дарителят на училището. (The sentence is correct)\n",
      "48 ❌ Ученикът на първия чин изглежда най-доволния от всички. (Actual: '', Expected: 'най-доволния')\n",
      "49 ✅ Ученикът на първия чин изглежда най-доволният от всички. (The sentence is correct)\n",
      "50 ❌ Малкия, заповядай едно бонбонче! (Actual: '', Expected: 'Малкия')\n",
      "51 ✅ Малкият, заповядай едно бонбонче! (The sentence is correct)\n",
      "52 ✅ Потребителя се регистрира успешно. ('Потребителя' is incorrect)\n",
      "53 ✅ Потребителят се регистрира успешно. (The sentence is correct)\n",
      "54 ❌ Обадих се на ръководителят. (Actual: '', Expected: 'ръководителят')\n",
      "55 ✅ Обадих се на ръководителя. (The sentence is correct)\n",
      "56 ✅ Лекаря живее тука. ('Лекаря' is incorrect)\n",
      "57 ✅ Лекарят живее тука. (The sentence is correct)\n",
      "58 ❌ Приятеля ни е лекаря. (Actual: 'Приятеля', Expected: 'Приятеля,лекаря')\n",
      "59 ✅ Приятелят ни е лекарят. (The sentence is correct)\n",
      "60 ❌ Ангел Иванчев, лекаря, живее тука. (Actual: '', Expected: 'лекаря')\n",
      "61 ✅ Ангел Иванчев, лекарят, живее тука. (The sentence is correct)\n",
      "62 ❌ Приятеля ни е Ангел Иванчев, лекаря. (Actual: '', Expected: 'Приятеля,лекаря')\n",
      "63 ✅ Приятелят ни е Ангел Иванчев, лекарят. (The sentence is correct)\n",
      "64 ❌ Той е най-високия и хубав в стаята. (Actual: '', Expected: 'най-високия')\n",
      "65 ✅ Той е най-високият и хубав в стаята. (The sentence is correct)\n",
      "66 ❌ Аз живея в новият бял блок. (Actual: '', Expected: 'новият')\n",
      "67 ✅ Аз живея в новия бял блок. (The sentence is correct)\n",
      "68 ❌ Високия бял блок е нов. (Actual: '', Expected: 'Високия')\n",
      "69 ✅ Високият бял блок е нов. (The sentence is correct)\n",
      "70 ✅ Телевизора е поправен от новия техник. ('Телевизора' is incorrect)\n",
      "71 ✅ Телевизорът е поправен от новия техник. (The sentence is correct)\n",
      "72 ❌ Ученикът, а не учителят извика при себе си директорът. (Actual: '', Expected: 'Ученикът,учителят')\n",
      "73 ❌ Ученика, а не учителя извика при себе си директорът. (Actual: 'Ученика', Expected: '')\n",
      "74 ✅ Заекът видя сокола. (The sentence is correct)\n",
      "75 ✅ Заекът видя сокола. (The sentence is correct)\n",
      "76 ✅ Заека видя соколът. (The sentence is correct)\n",
      "77 ✅ Заека видя соколът. (The sentence is correct)\n",
      "❌ 28/78 failed.\n"
     ]
    }
   ],
   "source": [
    "idx_passed, idx_current = test_definite_article_all(test_set_1, [cond_rule1], [rule1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea29537-08d2-4a94-8365-39ff48a85908",
   "metadata": {},
   "source": [
    "##### Analyze some of the failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e521677-cf9a-4e31-aa4f-2ce1aacfe2a3",
   "metadata": {},
   "source": [
    "Now let's taкe the first several failed tests and figure out why they failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b52274d4-612a-4749-9968-5066043a7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_dict(df, index):\n",
    "    row_dict = df.loc[index].to_dict()\n",
    "    row_dict[\"index\"] = index\n",
    "    return row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dfb8087-71e7-42b3-808b-2fecfcda448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Готвача         POS:NOUN       Gen:F    Num:S   DEP:nsubj      Sent: Готвача приготви обяда.       \n",
      "16 лекарят         POS:NOUN       Gen:M    Num:S   DEP:nsubj      Sent: Таня търси лекарят.           \n",
      "18 лекарят         POS:NOUN       Gen:M    Num:S   DEP:iobj       Sent: Говорим за лекарят.           \n",
      "20 лекарят         POS:NOUN       Gen:M    Num:S   DEP:nmod       Sent: Таня търси Ангел Иванчев, лекарят.\n",
      "22 лекарят         POS:NOUN       Gen:M    Num:S   DEP:conj       Sent: Говорим за Ангел Иванчев, лекарят.\n",
      "24 ключът          POS:NOUN       Gen:M    Num:S   DEP:obj        Sent: Той ми даде ключът от къщата. \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 10), 0))  # 👉Готвача приготви обяда.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 16), 2))  # Таня търси 👉лекарят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 18), 2))  # Говорим за 👉лекарят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 20), 5))  # Таня търси Ангел Иванчев, 👉лекарят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 22), 5))  # Говорим за Ангел Иванчев, 👉лекарят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 24), 3))  # Той ми даде 👉ключът от къщата.\n",
    "print(\"\\n\".join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d331a6c-a36a-4a1b-8f6b-201325d73360",
   "metadata": {},
   "source": [
    "The problem with _**готвача**_ is that it is considered to be feminine by Stanza. For now we **will postpone fixing** because without context it is impossible to determine the gender, and without gender we can't apply Rule1.\n",
    "\n",
    "The word _**лекарят**_ in _Таня търси лекарят_ is determined as an nsubj (nominal subject) by Stanza but the correct dependency is object. Well, grammatically it would be correct if we assume that the doctor is the doer in the sentence. However, that is the less popular word order. Let's **postpone fixing** this sentence for later.\n",
    "\n",
    "The word _**Лекарят**_ in the sentences \\\n",
    "_Говорим за лекарят_, \\\n",
    "_Таня търси Ангел Иванчев, лекарят_ \\\n",
    "and _Говорим за Ангел Иванчев, лекарят._ \\\n",
    "is determined to be iobj (indirect object), nmod (nominal modifier) and conj (conjust) so that falls under Rule2.\n",
    "\n",
    "_**ключът**_ is marked as object so it also falls under Rule2.\n",
    "\n",
    "So the last 4 failures are expected to be fixed after we implement Rule2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19233606-0f59-4fd8-adb8-18db158c4968",
   "metadata": {},
   "source": [
    "Separate the failed and analyzed tests into one list and the passed tests into another list. The one with the passed tests will be used for regression testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce0dc7e2-a07e-4194-ac50-595c2e575728",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_passed = sorted(list(set(idx_passed) - set([10, 16])))\n",
    "idx_current = sorted(list(set(idx_current) - set([10, 16])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7445dda-5de1-41a3-adbd-534bab042fd5",
   "metadata": {},
   "source": [
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5962f-e021-48c6-b1af-7717a339e3a4",
   "metadata": {},
   "source": [
    "#### Implement Rule2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f865be-d745-48c7-9275-aec4017b1f19",
   "metadata": {},
   "source": [
    "Here we will implement the first part of Rule2, which states that when the noun takes the role of the object, then the short form of the definite article should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dbafb0f-41be-484f-a048-5b38d0e8d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_rule2(row_dict, i):\n",
    "    \"\"\"Searches for masculine singular nouns that are the object in the sentence\"\"\"\n",
    "    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n",
    "    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n",
    "    is_token1_subj = is_dep_subject(row_dict, i)\n",
    "\n",
    "    if is_token1_noun and is_token1_masc_sg and not is_token1_subj:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3c8102b-b7c2-461b-a3c6-0ef00d3ee77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule2(token1, token2, idx_token):\n",
    "    errors = []\n",
    "    if token1.endswith((\"ът\", \"ят\")):  # objects should not have full article\n",
    "        errors.append(token1)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8709711-3a4e-4599-9316-03d4bb091077",
   "metadata": {},
   "source": [
    "#### Test Rule2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e44b8ee8-f284-45f7-bfb8-f134c315b934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ✅ Говорим за лекарят. ('лекарят' is incorrect)\n",
      "20 ✅ Таня търси Ангел Иванчев, лекарят. ('лекарят' is incorrect)\n",
      "22 ✅ Говорим за Ангел Иванчев, лекарят. ('лекарят' is incorrect)\n",
      "24 ✅ Той ми даде ключът от къщата. ('ключът' is incorrect)\n",
      "26 ❌ Принца говори с царят. (Actual: 'царят', Expected: 'Принца,царят')\n",
      "28 ✅ Аз помагам на ученикът. ('ученикът' is incorrect)\n",
      "30 ✅ Много пътници слязоха от влакът. ('влакът' is incorrect)\n",
      "32 ✅ Слушахме с интерес учителят. ('учителят' is incorrect)\n",
      "34 ❌ Дългоочаквания гост дойде. (Actual: '', Expected: 'Дългоочаквания')\n",
      "36 ❌ Иван, госта от Сопот, дойде. (Actual: '', Expected: 'госта')\n",
      "38 ❌ Иван е съученика ми. (Actual: '', Expected: 'съученика')\n",
      "40 ❌ Иван е добрия. (Actual: '', Expected: 'добрия')\n",
      "42 ❌ Иван е успелия. (Actual: '', Expected: 'успелия')\n",
      "44 ❌ Пешо се оказа най-верния му приятел. (Actual: '', Expected: 'най-верния')\n",
      "46 ❌ Пешо се оказа дарителя на училището. (Actual: '', Expected: 'дарителя')\n",
      "48 ❌ Ученикът на първия чин изглежда най-доволния от всички. (Actual: '', Expected: 'най-доволния')\n",
      "50 ❌ Малкия, заповядай едно бонбонче! (Actual: '', Expected: 'Малкия')\n",
      "54 ✅ Обадих се на ръководителят. ('ръководителят' is incorrect)\n",
      "58 ❌ Приятеля ни е лекаря. (Actual: 'Приятеля', Expected: 'Приятеля,лекаря')\n",
      "60 ❌ Ангел Иванчев, лекаря, живее тука. (Actual: '', Expected: 'лекаря')\n",
      "62 ❌ Приятеля ни е Ангел Иванчев, лекаря. (Actual: '', Expected: 'Приятеля,лекаря')\n",
      "64 ❌ Той е най-високия и хубав в стаята. (Actual: '', Expected: 'най-високия')\n",
      "66 ❌ Аз живея в новият бял блок. (Actual: '', Expected: 'новият')\n",
      "68 ❌ Високия бял блок е нов. (Actual: '', Expected: 'Високия')\n",
      "72 ❌ Ученикът, а не учителят извика при себе си директорът. (Actual: 'учителят,директорът', Expected: 'Ученикът,учителят')\n",
      "73 ❌ Ученика, а не учителя извика при себе си директорът. (Actual: 'Ученика,директорът', Expected: '')\n",
      "❌ 18/26 failed.\n"
     ]
    }
   ],
   "source": [
    "p, c = test_definite_article_all(test_set_1.loc[idx_current], [cond_rule1, cond_rule2], [rule1, rule2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e301348-0499-405a-8acf-dbc72a78b0af",
   "metadata": {},
   "source": [
    "In the previous run rows 18, 20, 22 and 24 failed, now after implementing Rule2 they pass. Additionally, 4 more tests pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46b951-bea2-400f-81b6-afcd3449cebb",
   "metadata": {},
   "source": [
    "##### Analyze some of the failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b76fcdb7-3b63-4da9-8759-0fb865251052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 Принца          POS:NOUN       Gen:F    Num:S   DEP:nsubj      Sent: Принца говори с царят.        \n",
      "34 Дългоочаквания  POS:ADJ        Gen:M    Num:S   DEP:amod       Sent: Дългоочаквания гост дойде.    \n",
      "34 гост            POS:NOUN       Gen:M    Num:S   DEP:nsubj      Sent: Дългоочаквания гост дойде.    \n",
      "36 госта           POS:NOUN       Gen:M    Num:S   DEP:nmod       Sent: Иван, госта от Сопот, дойде.  \n",
      "38 съученика       POS:NOUN       Gen:M    Num:S   DEP:root       Sent: Иван е съученика ми.          \n",
      "40 добрия          POS:ADJ        Gen:M    Num:S   DEP:root       Sent: Иван е добрия.                \n",
      "42 успелия         POS:VERB       Gen:     Num:S   DEP:root       Sent: Иван е успелия.               \n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 26), 0))  # 👉Принца говори с царят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 34), 0))  # 👉Дългоочаквания гост дойде.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 34), 1))  # Дългоочаквания 👉гост дойде.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 36), 2))  # Иван, 👉госта от Сопот, дойде.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 38), 2))  # Иван е 👉съученика ми.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 40), 2))  # Иван е 👉добрия.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 42), 2))  # Иван е 👉успелия.\n",
    "print(\"\\n\".join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038949a4-35d4-4a2f-bc3e-9cc0b22ca7e8",
   "metadata": {},
   "source": [
    "* _Принца_ - considered feminine, which is wrong, let's postpone fixing for now.\n",
    "* _Дългоочаквания_  - will be fixed by Rule3\n",
    "* _гост_            - also will be fixed by Rule3\n",
    "* _госта_           - add to later (not sure yet which rule to apply)\n",
    "* _съученика_       - add to later (because root)\n",
    "* _добрия_          - add to later (because root)\n",
    "* _успелия_         - Stanza thinks this is a VERB, which is wrong, so let's add to the list of \"will not fix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58b7aa85-e66b-42f7-81ee-0265a2c8269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the lists of passed and current tests up to date\n",
    "idx_failed = [26, 36, 38, 40, 42]\n",
    "idx_passed = sorted(set(idx_passed + p))\n",
    "idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n",
    "idx_current = sorted(list(set(idx_current) - set(p)))\n",
    "idx_current = sorted(list(set(idx_current) - set(idx_failed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6d997-9847-4d3e-aab5-bae054ffc763",
   "metadata": {},
   "source": [
    "#### Regression Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed54248-7a08-45e3-b32d-e43ad1e70348",
   "metadata": {},
   "source": [
    "Test the previously successful sentences to determine if Rule2 caused any breakages. Perform the regression using all rules defined till now (Rule1, Rule2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c77dfb9-1cf8-4e86-a64f-20dbfe82874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 ❌ Иван, гостът от Сопот, дойде. (Actual: 'гостът', Expected: '')\n",
      "39 ❌ Иван е съученикът ми. (Actual: 'съученикът', Expected: '')\n",
      "59 ❌ Приятелят ни е лекарят. (Actual: 'лекарят', Expected: '')\n",
      "61 ❌ Ангел Иванчев, лекарят, живее тука. (Actual: 'лекарят', Expected: '')\n",
      "63 ❌ Приятелят ни е Ангел Иванчев, лекарят. (Actual: 'Приятелят,лекарят', Expected: '')\n",
      "❌ 5/58 failed.\n"
     ]
    }
   ],
   "source": [
    "_ = test_definite_article_all(test_set_1.loc[idx_passed], [cond_rule1, cond_rule2], [rule1, rule2], print_passed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358211a9-9f26-4801-a5b4-60309e07d494",
   "metadata": {},
   "source": [
    "##### Analyze results from the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58e9e7ff-07d4-46ff-885e-4bc64f0f9c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 гостът          POS:NOUN       Gen:M    Num:S   DEP:nmod       Sent: Иван, гостът от Сопот, дойде. \n",
      "39 съученикът      POS:NOUN       Gen:M    Num:S   DEP:root       Sent: Иван е съученикът ми.         \n",
      "59 лекарят         POS:NOUN       Gen:M    Num:S   DEP:root       Sent: Приятелят ни е лекарят.       \n",
      "61 лекарят         POS:NOUN       Gen:M    Num:S   DEP:nmod       Sent: Ангел Иванчев, лекарят, живее тука.\n",
      "63 лекарят         POS:NOUN       Gen:M    Num:S   DEP:conj       Sent: Приятелят ни е Ангел Иванчев, лекарят.\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 37), 2))  # Иван, 👉гостът от Сопот, дойде.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 39), 2))  # Иван е 👉съученикът ми.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 59), 3))  # Приятелят ни е 👉лекарят.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 61), 3))  # Ангел Иванчев, 👉лекарят, живее тука.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 63), 6))  # Приятелят ни е Ангел Иванчев, 👉лекарят.\n",
    "print(\"\\n\".join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe35db-5c4e-4b47-aa8f-28e3a0a0cd19",
   "metadata": {},
   "source": [
    "When we implement the next rules these failures should be fixed. For now let's move them to the list with failed tests. We'll get back to them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a21d6-7d6d-4893-a5c7-c00680c4496f",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db3dcac6-716e-47e5-a6ed-fe946190d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_failed = [37, 39, 59, 61, 63]\n",
    "idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e1491-2db5-4ef1-981a-8555e1514d53",
   "metadata": {},
   "source": [
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b1429-7f4e-4778-b66f-9ba6588bb586",
   "metadata": {},
   "source": [
    "#### Implement Rule3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b66351-0f31-4b33-a58f-0893d0628ecc",
   "metadata": {},
   "source": [
    "Rule3 states that adjectives, numerals, participles and possessive pronouns take the same article as the noun they agree with. Let's first implement the riles for adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa6ec4a4-fdf5-4030-8b25-077e5c13abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пълен член се появява в цялата група на подлога, към която принадлежат неговите определения или приложения. [3]\n",
    "# In adjective-noun phrases, only the adjective takes a definite article ending.\n",
    "def cond_rule3(row_dict, i):\n",
    "    \"\"\"Searches for ADJ/amod + NOUN/nsubj, both masculine/singular\"\"\"\n",
    "    is_token1_adj = nlp_get_pos(row_dict, i) == \"ADJ\"\n",
    "    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n",
    "    is_token1_amod = nlp_get_dep(row_dict, i) == \"amod\"\n",
    "\n",
    "    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n",
    "    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n",
    "    is_token2_nsubj = nlp_get_dep(row_dict, i + 1) == \"nsubj\"\n",
    "\n",
    "    if is_token1_adj and is_token2_noun:\n",
    "        if is_token1_masc_sg and is_token2_masc_sg:\n",
    "            if is_token1_amod and is_token2_nsubj:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "032345fd-199f-42ea-b114-33553f67cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule3(token1, token2, idx_token):\n",
    "    errors = []\n",
    "\n",
    "    # Дългоочаквания гост\n",
    "    if token1.endswith((\"я\")):  # прилагателното трябва да е с пълен член\n",
    "        errors.append(token1)\n",
    "\n",
    "    # Дългоочакваният гост\n",
    "    if token2.endswith((\"ът\", \"ят\")):  # съществителното трябва да е с непълен член\n",
    "        errors.append(token2)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048b432-52b5-44a3-b01a-299d7217961c",
   "metadata": {},
   "source": [
    "#### Test Rule3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52b911e9-fd1f-4a51-8256-827088fd8970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 ✅ Дългоочаквания гост дойде. ('Дългоочаквания' is incorrect)\n",
      "44 ❌ Пешо се оказа най-верния му приятел. (Actual: '', Expected: 'най-верния')\n",
      "46 ❌ Пешо се оказа дарителя на училището. (Actual: '', Expected: 'дарителя')\n",
      "48 ❌ Ученикът на първия чин изглежда най-доволния от всички. (Actual: '', Expected: 'най-доволния')\n",
      "50 ❌ Малкия, заповядай едно бонбонче! (Actual: '', Expected: 'Малкия')\n",
      "58 ❌ Приятеля ни е лекаря. (Actual: 'Приятеля', Expected: 'Приятеля,лекаря')\n",
      "60 ❌ Ангел Иванчев, лекаря, живее тука. (Actual: '', Expected: 'лекаря')\n",
      "62 ❌ Приятеля ни е Ангел Иванчев, лекаря. (Actual: '', Expected: 'Приятеля,лекаря')\n",
      "64 ❌ Той е най-високия и хубав в стаята. (Actual: '', Expected: 'най-високия')\n",
      "66 ❌ Аз живея в новият бял блок. (Actual: '', Expected: 'новият')\n",
      "68 ❌ Високия бял блок е нов. (Actual: '', Expected: 'Високия')\n",
      "72 ❌ Ученикът, а не учителят извика при себе си директорът. (Actual: 'учителят,директорът', Expected: 'Ученикът,учителят')\n",
      "73 ❌ Ученика, а не учителя извика при себе си директорът. (Actual: 'Ученика,директорът', Expected: '')\n",
      "❌ 12/13 failed.\n"
     ]
    }
   ],
   "source": [
    "conditions = [cond_rule1, cond_rule2, cond_rule3]\n",
    "rules = [rule1, rule2, rule3]\n",
    "p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100aa3e-4313-4ae5-a9ca-029bf124fe3d",
   "metadata": {},
   "source": [
    "##### Analyze the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f4640bf-7d57-4188-91c5-f3fda0770e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 най-верния      POS:ADJ        Gen:M    Num:S   DEP:amod       Sent: Пешо се оказа най-верния му приятел.\n",
      "46 дарителя        POS:NOUN       Gen:M    Num:S   DEP:obj        Sent: Пешо се оказа дарителя на училището.\n",
      "48 най-доволния    POS:ADJ        Gen:M    Num:S   DEP:obj        Sent: Ученикът на първия чин изглежда най-доволния от всички.\n",
      "50 Малкия          POS:ADJ        Gen:M    Num:S   DEP:vocative   Sent: Малкия, заповядай едно бонбонче!\n",
      "58 Приятеля        POS:NOUN       Gen:M    Num:S   DEP:nsubj      Sent: Приятеля ни е лекаря.         \n",
      "60 лекаря          POS:NOUN       Gen:M    Num:S   DEP:nmod       Sent: Ангел Иванчев, лекаря, живее тука.\n",
      "62 Приятеля        POS:NOUN       Gen:M    Num:S   DEP:root       Sent: Приятеля ни е Ангел Иванчев, лекаря.\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 44), 3))  # Пешо се оказа 👉най-верния му приятел.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 46), 3))  # Пешо се оказа 👉дарителя на училището.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 48), 5))  # Ученикът на първия чин изглежда 👉най-доволния от всички.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 50), 0))  # 👉Малкия, заповядай едно бонбонче!\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 58), 0))  # 👉Приятеля ни е 👉лекаря.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 60), 3))  # Ангел Иванчев, 👉лекаря, живее тука.\n",
    "res.append(inspect_word(row_to_dict(test_set_1, 62), 0))  # 👉Приятеля ни е Ангел Иванчев, 👉лекаря.\n",
    "print(\"\\n\".join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af207e60-004c-44e4-84bc-a2f716d2c180",
   "metadata": {},
   "source": [
    "* 44 _най-верния_ - should be fixed by Rule4\n",
    "* 46 _дарителя_ - should be fixed by Rule4\n",
    "* 48 _най_доволния_ - should be fixed by Rule4\n",
    "* 50 _Малкия_ - should be fixed by Rule_6\n",
    "* 58 _Приятеля_ on row 58 58 - should be fixed by Rule_7\n",
    "* 60 _лекаря_ - should be fixed by Rule_7\n",
    "* 62 _Приятеля_ on row 62 - should be fixed by Rule_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef6f6f01-2d40-46a3-b53f-32bcd2ef2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the lists with passing and current tests up to date\n",
    "idx_failed = [50, 58, 60, 62]\n",
    "idx_passed = sorted(set(idx_passed + p))\n",
    "idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n",
    "idx_current = sorted(list(set(idx_current) - set(p)))\n",
    "idx_current = sorted(list(set(idx_current) - set(idx_failed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1d148-3f24-4c17-a754-e11c1ff6664d",
   "metadata": {},
   "source": [
    "#### Regression Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57310678-31cd-4edb-836d-50b6914930e5",
   "metadata": {},
   "source": [
    "Ensure that we have not violated Rule 1 and Rule 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdec3910-5f91-4c68-af5f-264c3bfad583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dcd2b-6a12-4135-a91a-59b77a3b12a2",
   "metadata": {},
   "source": [
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3949a979-ccfb-4971-9027-511bc01de984",
   "metadata": {},
   "source": [
    "#### Implement Rule4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dea907-9a28-434f-bb10-32994a36c1d7",
   "metadata": {},
   "source": [
    "According to Rule4, the full definite article should be used when a noun is after verbs like съм, бъда, оказвам се, изглеждам, etc. In order to check the previous verb, we need to check the _lemma_ of the verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781512d-c745-43a3-b3bf-f1a345545262",
   "metadata": {},
   "source": [
    "First let's see what the previously failed sentences look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d46e149d-c94b-4c39-95c7-b14984cdf20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Иван            Tag: Npmsi           POS: PROPN      Lemma: иван            Dep: nsubj     \n",
      "Token: е               Tag: Vxitf-r3s       POS: AUX        Lemma: съм             Dep: cop       \n",
      "Token: съученикът      Tag: Ncmsf           POS: NOUN       Lemma: съученик        Dep: root      \n",
      "Token: ми              Tag: Psot--1         POS: PRON       Lemma: аз              Dep: det       \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n",
      "Token: Пешо            Tag: Npmsi           POS: PROPN      Lemma: пешо            Dep: nsubj     \n",
      "Token: се              Tag: Ppxta           POS: PRON       Lemma: се              Dep: expl      \n",
      "Token: оказа           Tag: Vpptf-o3s       POS: VERB       Lemma: окажа-(се)      Dep: root      \n",
      "Token: най-верния      Tag: Amsh            POS: ADJ        Lemma: верен           Dep: amod      \n",
      "Token: му              Tag: Psot--3--m      POS: PRON       Lemma: мой             Dep: det       \n",
      "Token: приятел         Tag: Ncmsi           POS: NOUN       Lemma: приятел         Dep: obj       \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n",
      "Token: Пешо            Tag: Npmsi           POS: PROPN      Lemma: пешо            Dep: nsubj     \n",
      "Token: се              Tag: Ppxta           POS: PRON       Lemma: се              Dep: expl      \n",
      "Token: оказа           Tag: Vpptf-o3s       POS: VERB       Lemma: окажа-(се)      Dep: root      \n",
      "Token: дарителя        Tag: Ncmsh           POS: NOUN       Lemma: дарител         Dep: obj       \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: училището       Tag: Ncnsd           POS: NOUN       Lemma: училище         Dep: nmod      \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n",
      "Token: Ученикът        Tag: Ncmsf           POS: NOUN       Lemma: ученик          Dep: nsubj     \n",
      "Token: на              Tag: R               POS: ADP        Lemma: на              Dep: case      \n",
      "Token: първия          Tag: Momsh           POS: ADJ        Lemma: пръв            Dep: amod      \n",
      "Token: чин             Tag: Ncmsi           POS: NOUN       Lemma: чин             Dep: nmod      \n",
      "Token: изглежда        Tag: Vpiif-r3s       POS: VERB       Lemma: изглежда        Dep: root      \n",
      "Token: най-доволния    Tag: Amsh            POS: ADJ        Lemma: говолен         Dep: obj       \n",
      "Token: от              Tag: R               POS: ADP        Lemma: от              Dep: case      \n",
      "Token: всички          Tag: Pce-op          POS: PRON       Lemma: всеки           Dep: obl       \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_spacy_doc(nlp_st(test_set_1.loc[39, \"text\"]))\n",
    "inspect_spacy_doc(nlp_st(test_set_1.loc[44, \"text\"]))\n",
    "inspect_spacy_doc(nlp_st(test_set_1.loc[46, \"text\"]))\n",
    "inspect_spacy_doc(nlp_st(test_set_1.loc[48, \"text\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fbdc986-53c8-4166-b84a-a3cebf3245f5",
   "metadata": {},
   "source": [
    "<img src=\"images/rule4_pattern_new.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614dc031-14d5-467f-bf70-f68aa81114b5",
   "metadata": {},
   "source": [
    "The above pattern shows that the first token is a verb (including auxiliary), while the second token is either a noun or an adjective, both of which must be in masculine singular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8626cab8-80d0-433a-a7e9-027d7f2df2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пълен е членът и на името, употребено след глаголи като съм, бъда, оказвам се, изглеждам и др. [3]\n",
    "def cond_rule4(row_dict, i):\n",
    "    is_token1_aux = nlp_get_pos(row_dict, i) == \"AUX\"\n",
    "    is_token1_verb = nlp_get_pos(row_dict, i) == \"VERB\"\n",
    "\n",
    "    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n",
    "    is_token2_adj = nlp_get_pos(row_dict, i + 1) == \"ADJ\"\n",
    "    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n",
    "    is_article_indefinite = nlp_get_article(row_dict, i + 1) == \"indefinite\"\n",
    "\n",
    "    is_lemma_aux_syn = False\n",
    "\n",
    "    if is_token2_masc_sg:\n",
    "        if is_token2_noun or (is_token2_adj and not is_article_indefinite):\n",
    "            if is_token1_aux or is_token1_verb:\n",
    "                doc = nlp_st(row_dict[\"text\"])\n",
    "                lemma = doc[i].lemma_\n",
    "                # Винаги след глагола „съм“ или след глаголи, които са с преносна употреба и може да бъдат синоними на\n",
    "                # глагола „съм“ (оказа се, изглежда, казвам се), се пише пълен член (-ът/-ят)\n",
    "                is_lemma_aux_syn = lemma in (\"е\", \"съм\", \"окажа-(се)\", \"изглежда\")\n",
    "                if is_lemma_aux_syn:\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d75b3d0f-27da-4a8b-9a1c-df016d8c6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule4(token1, token2, idx_token):\n",
    "    errors = []\n",
    "\n",
    "    # е        съученикът\n",
    "    # оказа    най_верния\n",
    "    # оказа    дарителя\n",
    "    # изглежда най-доволния\n",
    "    if not token2.endswith((\"ът\", \"ят\")):  # след глагол думата трябва да е с пълен опр. член\n",
    "        errors.append(token2)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28d2e4-35ee-4c72-9197-aff38931a51b",
   "metadata": {},
   "source": [
    "#### Test Rule4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b594291-e2b9-4c7a-b901-b0db615bbe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 ❌ Иван е съученикът ми. (Actual: 'съученикът', Expected: '')\n",
      "44 ✅ Пешо се оказа най-верния му приятел. ('най-верния' is incorrect)\n",
      "46 ✅ Пешо се оказа дарителя на училището. ('дарителя' is incorrect)\n",
      "48 ✅ Ученикът на първия чин изглежда най-доволния от всички. ('най-доволния' is incorrect)\n",
      "❌ 1/4 failed.\n"
     ]
    }
   ],
   "source": [
    "conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4]\n",
    "rules = [rule1, rule2, rule3, rule4]\n",
    "\n",
    "p, c = test_definite_article_all(test_set_1.loc[[39, 44, 46, 48]], conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beedff-19c9-4034-9c5d-1d6aaa861c8d",
   "metadata": {},
   "source": [
    "##### Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1997e19-fa5f-4567-a3d8-04de5d2ef462",
   "metadata": {},
   "source": [
    "We expected row 39 to pass but it is still failing. This is likely due to one of the existing rules. We should run tests on each rule individually to identify which one is causing the issue, specifically the one that returns the word _съученикът_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ed83737-7b6a-443f-b6cc-e74573fc365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "p, c = test_definite_article_all(test_set_1.loc[[39]], [cond_rule1], [rule1], print_passed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2e3f5d4-5170-421b-9a4c-381fc52008fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 ❌ Иван е съученикът ми. (Actual: 'съученикът', Expected: '')\n",
      "❌ 1/1 failed.\n"
     ]
    }
   ],
   "source": [
    "p, c = test_definite_article_all(test_set_1.loc[[39]], [cond_rule2], [rule2], print_passed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f63fe2-536b-4b83-8fcd-b97029276ade",
   "metadata": {},
   "source": [
    "Row 39 doesn't pass due to Rule2. In Rule4 we checked whether the previous token was AUX or a VERB, so in Rule2 we need to introduce an exception that specifies the previous token cannot be a VERB or AUX. Otherwise we will have two rules acting on the same pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7bacc-3f9f-4646-bb36-e6d82d40e935",
   "metadata": {},
   "source": [
    "#### Update Rule2 and test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7927294d-7fce-4373-91df-186322046539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the old rule if we need to test with it\n",
    "cond_rule2_prev = cond_rule2\n",
    "rule2_prev = rule2\n",
    "\n",
    "\n",
    "def cond_rule2(row_dict, i):\n",
    "    \"\"\"Search for either:\n",
    "        - single, masculine NOUN, not subject, not preceded by a verb\n",
    "        - preceding token is a verb but different from съм, оказвам се, излгежда, etc.\"\"\"\n",
    "    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n",
    "    is_token1_verb = nlp_get_pos(row_dict, i) == \"VERB\"\n",
    "    is_token1_aux = nlp_get_pos(row_dict, i) == \"AUX\"\n",
    "    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n",
    "    is_token1_subj = is_dep_subject(row_dict, i)\n",
    "\n",
    "    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n",
    "    is_token2_subj = is_dep_subject(row_dict, i + 1)\n",
    "    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n",
    "\n",
    "    # if token is masculine single noun and !subj, and the previous token is not a verb\n",
    "    if i == 0 and is_token1_noun and is_token1_masc_sg and not is_token1_subj:\n",
    "        return True\n",
    "\n",
    "    is_like_verb = is_token1_verb or is_token1_aux\n",
    "\n",
    "    if i != 0 and is_token2_noun and is_token2_masc_sg and not is_token2_subj:\n",
    "        lemma = nlp_get_lemma(row_dict, i)\n",
    "\n",
    "        is_lemma_aux_syn = lemma in (\"е\", \"съм\", \"окажа-(се)\", \"изглежда\")\n",
    "        is_non_aux_syn = not is_like_verb or (is_like_verb and not is_lemma_aux_syn)\n",
    "        if is_non_aux_syn:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "561625fc-c0a1-41c0-b34a-7cf42e218b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule2(token1, token2, token_idx):\n",
    "    errors = []\n",
    "    word = token1 if token_idx == 0 else token2\n",
    "    if word.endswith((\"ът\", \"ят\")):  # objects should not have full article\n",
    "        errors.append(word)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ac6fb-7be7-485c-baf3-4f5b914a350f",
   "metadata": {},
   "source": [
    "First test with a small set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23e35011-342f-42c3-80f6-5106daf029a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 ✅ Иван е съученикът ми. (The sentence is correct)\n",
      "44 ✅ Пешо се оказа най-верния му приятел. ('най-верния' is incorrect)\n",
      "46 ✅ Пешо се оказа дарителя на училището. ('дарителя' is incorrect)\n",
      "48 ✅ Ученикът на първия чин изглежда най-доволния от всички. ('най-доволния' is incorrect)\n",
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4]\n",
    "rules = [rule1, rule2, rule3, rule4]\n",
    "p, c = test_definite_article_all(test_set_1.loc[[39, 44, 46, 48]], conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c687298-7116-4780-a276-b4e86be0f468",
   "metadata": {},
   "source": [
    "Next test with the remaining rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4de0c865-e752-4f96-8b93-a653d1c6a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ✅ Пешо се оказа най-верния му приятел. ('най-верния' is incorrect)\n",
      "46 ✅ Пешо се оказа дарителя на училището. ('дарителя' is incorrect)\n",
      "48 ✅ Ученикът на първия чин изглежда най-доволния от всички. ('най-доволния' is incorrect)\n",
      "64 ✅ Той е най-високия и хубав в стаята. ('най-високия' is incorrect)\n",
      "66 ❌ Аз живея в новият бял блок. (Actual: '', Expected: 'новият')\n",
      "68 ❌ Високия бял блок е нов. (Actual: '', Expected: 'Високия')\n",
      "72 ❌ Ученикът, а не учителят извика при себе си директорът. (Actual: 'учителят,директорът', Expected: 'Ученикът,учителят')\n",
      "73 ❌ Ученика, а не учителя извика при себе си директорът. (Actual: 'Ученика,директорът', Expected: '')\n",
      "❌ 4/8 failed.\n"
     ]
    }
   ],
   "source": [
    "p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c7efd-bcc3-4a9d-aecf-c27b4b80d5c4",
   "metadata": {},
   "source": [
    "##### Analyze the remaining failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "54bac706-f3df-4550-abc9-6a2e721bddb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Аз              Tag: Ppe-os1         POS: PRON       Lemma: аз              Dep: nsubj     \n",
      "Token: живея           Tag: Vpitf-r1s       POS: VERB       Lemma: живея           Dep: root      \n",
      "Token: в               Tag: R               POS: ADP        Lemma: в               Dep: case      \n",
      "Token: новият          Tag: Amsf            POS: ADJ        Lemma: нов             Dep: amod      \n",
      "Token: бял             Tag: Amsi            POS: ADJ        Lemma: бял             Dep: amod      \n",
      "Token: блок            Tag: Ncmsi           POS: NOUN       Lemma: блок            Dep: iobj      \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n",
      "Token: Високия         Tag: Amsh            POS: ADJ        Lemma: висок           Dep: amod      \n",
      "Token: бял             Tag: Amsi            POS: ADJ        Lemma: бял             Dep: amod      \n",
      "Token: блок            Tag: Ncmsi           POS: NOUN       Lemma: блок            Dep: nsubj     \n",
      "Token: е               Tag: Vxitf-r3s       POS: AUX        Lemma: съм             Dep: cop       \n",
      "Token: нов             Tag: Amsi            POS: ADJ        Lemma: нов             Dep: root      \n",
      "Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspect_spacy_doc(nlp_st(test_set_1.loc[66, \"text\"]))\n",
    "inspect_spacy_doc(nlp_st(test_set_1.loc[68, \"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ab3de-808c-4e4a-8652-2714a192a979",
   "metadata": {},
   "source": [
    "* 66 _новият бял блок_ and 68 _Високия бял блок_ - the pattern ADJ/ADJ/NOUN points to Rule5.\n",
    "* 72 and 73 depend on the order of words. We don;t know who is the doer of the action in those sentences. Let's postpone fixing them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "172bb6b4-3a03-4560-985e-af3f5bdf1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_failed = [72, 73]\n",
    "idx_passed = sorted(set(idx_passed + p))\n",
    "idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n",
    "idx_current = sorted(list(set(idx_current) - set(p)))\n",
    "idx_current = sorted(list(set(idx_current) - set(idx_failed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a18aa-00fe-47af-94b2-1d45fdd9970e",
   "metadata": {},
   "source": [
    "#### Regression Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba32b45a-c40e-4ada-925e-69acb82d39b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bd7763-94eb-4cc3-a8e2-247eb012e950",
   "metadata": {},
   "source": [
    "### Iteration 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441deff4-7730-41c5-9edb-cdfa5f61aa98",
   "metadata": {},
   "source": [
    "#### Implement Rule5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb458b-66c8-467d-8243-eca3b6200482",
   "metadata": {},
   "source": [
    "Rule5 says that when there are two or more adjectives in front of the noun, only the first adjective takes the definite article, which could be short or long. In the example with rows 66 and 68 which were analyzed in the previous section, we see that the two phrases _новият бял блок_ and _високия бял блок_ which are identical from grammatical standpoint, cannot be distinguished just by looking at their part of speech. We need to also analyze their relation to the entire sentence. The difference here is that in the first case Stanza correctly determined the noun _блок_ as an indirect object, therefore requiring the short form of the definite article, and the same word in the second sentence and nominal subject, requiring full definite article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55fd73-6791-4143-a0a7-22ae6f097806",
   "metadata": {},
   "source": [
    "<img src=\"images/rule7_pattern_new.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf7c6a-04c6-4192-b636-fd202cf038ca",
   "metadata": {},
   "source": [
    "Although we expressed the condition verbally as one rule, we need to create two sets of functions for the cases of short and long definite article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e316a49b-5c42-45e7-a93f-cb862711546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The adjectives, as well as the pronouns, the ordinal numerals etc., used as attributes in the sentence\n",
    "# are usually placed in front of the nouns they qualify. In this case, the definite article, if needed,\n",
    "# is joined to the _first_ attribute of the noun phrase. [4],[5]\n",
    "def cond_rule5_helper(row_dict, i):\n",
    "    \"\"\"\n",
    "    POS: ADJ / ADJ / NOUN iobj,  all masc. singular -> first ADJ must have def. art. short form\n",
    "    - or -\n",
    "    POS: ADJ / ADJ / NOUN nsubj, all masc. singular -> first ADJ must have def. art. long form\n",
    "    \"\"\"    \n",
    "    if i >= row_dict[\"num_tokens\"] - 2:\n",
    "        return False\n",
    "\n",
    "    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n",
    "    is_token1_adj = nlp_get_pos(row_dict, i) == \"ADJ\"\n",
    "\n",
    "    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n",
    "    is_token2_adj = nlp_get_pos(row_dict, i + 1) == \"ADJ\"\n",
    "\n",
    "    is_token3_masc_sg = is_masculine_singular(row_dict, i + 2)\n",
    "    is_token3_noun = nlp_get_pos(row_dict, i + 2) == \"NOUN\"\n",
    "\n",
    "    if is_token1_masc_sg and is_token2_masc_sg and is_token3_masc_sg:\n",
    "        if is_token1_adj and is_token2_adj and is_token3_noun:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a596790c-ae3d-4097-965b-a7cce11ac7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_rule5_short(row_dict, i):\n",
    "    if cond_rule5_helper(row_dict, i):\n",
    "        noun_dep = nlp_get_dep(row_dict, i + 2)\n",
    "        if noun_dep in (\"iobj\"):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "937162e9-19a2-448f-b6e8-34180d1eac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_rule5_long(row_dict, i):\n",
    "    if cond_rule5_helper(row_dict, i):\n",
    "        noun_dep = nlp_get_dep(row_dict, i + 2)\n",
    "        if noun_dep in (\"nsubj\"):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3e3e8b9-5128-4bf5-80d9-d41c5f74a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule5_short(token1, token2, token_idx):\n",
    "    errors = []\n",
    "\n",
    "    # Аз живея в новият бял блок.\n",
    "    if not token1.endswith((\"я\")):  # първото прилагателно в групата трябва да е с непълен член\n",
    "        errors.append(token1)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f41f9005-a53e-4edb-b448-77ba560c7956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule5_long(token1, token2, token_idx):\n",
    "    errors = []\n",
    "\n",
    "    # Високия бял блок е нов.\n",
    "    if not token1.endswith((\"ят\")):  # първото прилагателно в групата трябва да е с пълен член\n",
    "        errors.append(token1)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbbe7b1-4118-413d-a1bd-fd3858c74f9f",
   "metadata": {},
   "source": [
    "#### Test Rule5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25787732-5233-40c0-b9bd-dbaf507438df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 ✅ Аз живея в новият бял блок. ('новият' is incorrect)\n",
      "68 ✅ Високия бял блок е нов. ('Високия' is incorrect)\n",
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4, cond_rule5_short, cond_rule5_long]\n",
    "rules = [rule1, rule2, rule3, rule4, rule5_short, rule5_long]\n",
    "p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e9381-f131-48d7-b871-f6ef8134ceb7",
   "metadata": {},
   "source": [
    "#### Regression test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c59c5021-73f3-4796-8675-05cc35093491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tests passed\n"
     ]
    }
   ],
   "source": [
    "_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115df14d-efba-4b5c-aac2-d803e5d950ae",
   "metadata": {},
   "source": [
    "#### Final test with the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a732e00-9683-4212-b2a6-dae09239d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ✅ Ключа е на масата. ('Ключа' is incorrect)\n",
      "1 ✅ Ключът е на масата. (The sentence is correct)\n",
      "2 ✅ Царя пие вино. ('Царя' is incorrect)\n",
      "3 ✅ Царят пие вино. (The sentence is correct)\n",
      "4 ✅ Ученика е умен и трудолюбив. ('Ученика' is incorrect)\n",
      "5 ✅ Ученикът е умен и трудолюбив. (The sentence is correct)\n",
      "6 ✅ Приятеля ми е в чужбина. ('Приятеля' is incorrect)\n",
      "7 ✅ Приятелят ми е в чужбина. (The sentence is correct)\n",
      "8 ✅ Госта пристигна. ('Госта' is incorrect)\n",
      "9 ✅ Гостът пристигна. (The sentence is correct)\n",
      "10 ❌ Готвача приготви обяда. (Actual: '', Expected: 'Готвача')\n",
      "11 ✅ Готвачът приготви обяда. (The sentence is correct)\n",
      "12 ✅ Влака спря на гара София. ('Влака' is incorrect)\n",
      "13 ✅ Влакът спря на гара София. (The sentence is correct)\n",
      "14 ✅ Учителя говореше за Стефан Стамболов. ('Учителя' is incorrect)\n",
      "15 ✅ Учителят говореше за Стефан Стамболов. (The sentence is correct)\n",
      "16 ❌ Таня търси лекарят. (Actual: '', Expected: 'лекарят')\n",
      "17 ✅ Таня търси лекаря. (The sentence is correct)\n",
      "18 ✅ Говорим за лекарят. ('лекарят' is incorrect)\n",
      "19 ✅ Говорим за лекаря. (The sentence is correct)\n",
      "20 ✅ Таня търси Ангел Иванчев, лекарят. ('лекарят' is incorrect)\n",
      "21 ✅ Таня търси Ангел Иванчев, лекаря. (The sentence is correct)\n",
      "22 ✅ Говорим за Ангел Иванчев, лекарят. ('лекарят' is incorrect)\n",
      "23 ✅ Говорим за Ангел Иванчев, лекаря. (The sentence is correct)\n",
      "24 ✅ Той ми даде ключът от къщата. ('ключът' is incorrect)\n",
      "25 ✅ Той ми даде ключа от къщата. (The sentence is correct)\n",
      "26 ❌ Принца говори с царят. (Actual: 'царят', Expected: 'Принца,царят')\n",
      "27 ✅ Принцът говори с царя. (The sentence is correct)\n",
      "28 ✅ Аз помагам на ученикът. ('ученикът' is incorrect)\n",
      "29 ✅ Аз помагам на ученика. (The sentence is correct)\n",
      "30 ✅ Много пътници слязоха от влакът. ('влакът' is incorrect)\n",
      "31 ✅ Много пътници слязоха от влака. (The sentence is correct)\n",
      "32 ✅ Слушахме с интерес учителят. ('учителят' is incorrect)\n",
      "33 ✅ Слушахме с интерес учителя. (The sentence is correct)\n",
      "34 ✅ Дългоочаквания гост дойде. ('Дългоочаквания' is incorrect)\n",
      "35 ✅ Дългоочакваният гост дойде. (The sentence is correct)\n",
      "36 ❌ Иван, госта от Сопот, дойде. (Actual: '', Expected: 'госта')\n",
      "37 ❌ Иван, гостът от Сопот, дойде. (Actual: 'гостът', Expected: '')\n",
      "38 ✅ Иван е съученика ми. ('съученика' is incorrect)\n",
      "39 ✅ Иван е съученикът ми. (The sentence is correct)\n",
      "40 ✅ Иван е добрия. ('добрия' is incorrect)\n",
      "41 ✅ Иван е добрият. (The sentence is correct)\n",
      "42 ❌ Иван е успелия. (Actual: '', Expected: 'успелия')\n",
      "43 ✅ Иван е успелият. (The sentence is correct)\n",
      "44 ✅ Пешо се оказа най-верния му приятел. ('най-верния' is incorrect)\n",
      "45 ✅ Пешо се оказа най-верният му приятел. (The sentence is correct)\n",
      "46 ✅ Пешо се оказа дарителя на училището. ('дарителя' is incorrect)\n",
      "47 ✅ Пешо се оказа дарителят на училището. (The sentence is correct)\n",
      "48 ✅ Ученикът на първия чин изглежда най-доволния от всички. ('най-доволния' is incorrect)\n",
      "49 ✅ Ученикът на първия чин изглежда най-доволният от всички. (The sentence is correct)\n",
      "50 ❌ Малкия, заповядай едно бонбонче! (Actual: '', Expected: 'Малкия')\n",
      "51 ✅ Малкият, заповядай едно бонбонче! (The sentence is correct)\n",
      "52 ✅ Потребителя се регистрира успешно. ('Потребителя' is incorrect)\n",
      "53 ✅ Потребителят се регистрира успешно. (The sentence is correct)\n",
      "54 ✅ Обадих се на ръководителят. ('ръководителят' is incorrect)\n",
      "55 ✅ Обадих се на ръководителя. (The sentence is correct)\n",
      "56 ✅ Лекаря живее тука. ('Лекаря' is incorrect)\n",
      "57 ✅ Лекарят живее тука. (The sentence is correct)\n",
      "58 ✅ Приятеля ни е лекаря. ('Приятеля,лекаря' is incorrect)\n",
      "59 ✅ Приятелят ни е лекарят. (The sentence is correct)\n",
      "60 ❌ Ангел Иванчев, лекаря, живее тука. (Actual: '', Expected: 'лекаря')\n",
      "61 ❌ Ангел Иванчев, лекарят, живее тука. (Actual: 'лекарят', Expected: '')\n",
      "62 ❌ Приятеля ни е Ангел Иванчев, лекаря. (Actual: '', Expected: 'Приятеля,лекаря')\n",
      "63 ❌ Приятелят ни е Ангел Иванчев, лекарят. (Actual: 'Приятелят,лекарят', Expected: '')\n",
      "64 ✅ Той е най-високия и хубав в стаята. ('най-високия' is incorrect)\n",
      "65 ✅ Той е най-високият и хубав в стаята. (The sentence is correct)\n",
      "66 ✅ Аз живея в новият бял блок. ('новият' is incorrect)\n",
      "67 ✅ Аз живея в новия бял блок. (The sentence is correct)\n",
      "68 ✅ Високия бял блок е нов. ('Високия' is incorrect)\n",
      "69 ✅ Високият бял блок е нов. (The sentence is correct)\n",
      "70 ✅ Телевизора е поправен от новия техник. ('Телевизора' is incorrect)\n",
      "71 ✅ Телевизорът е поправен от новия техник. (The sentence is correct)\n",
      "72 ❌ Ученикът, а не учителят извика при себе си директорът. (Actual: 'учителят,директорът', Expected: 'Ученикът,учителят')\n",
      "73 ❌ Ученика, а не учителя извика при себе си директорът. (Actual: 'Ученика,директорът', Expected: '')\n",
      "74 ✅ Заекът видя сокола. (The sentence is correct)\n",
      "75 ✅ Заекът видя сокола. (The sentence is correct)\n",
      "76 ✅ Заека видя соколът. (The sentence is correct)\n",
      "77 ✅ Заека видя соколът. (The sentence is correct)\n",
      "❌ 13/78 failed.\n"
     ]
    }
   ],
   "source": [
    "_ = test_definite_article_all(test_set_1, conditions, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13be08b-5515-4b1c-9b8c-5f6b8f0f8ae6",
   "metadata": {},
   "source": [
    "We didn't predict correctly the usage of the definite article in 13 out of the 78 sentences. In some cases it is due to the NLP tag being incorrect, for example the case where the gender of the noun was tagged wrongly by Stanza. In other case it was because we still haven't implemented Rule7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf6623-44ee-4504-b851-7d313ec210f3",
   "metadata": {},
   "source": [
    "## Test with real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1131c-38d5-4f91-b53e-a31042c11d7e",
   "metadata": {},
   "source": [
    "We've initially evaluated our rules using brief, uncomplicated sentences. These were intentionally kept short to clearly demonstrate each specific rule. However, real-world language usage typically involves lengthier and more intricate sentences. It's now necessary to apply our rules to authentic texts to assess their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf148ad-a02c-4501-9aa6-c8d7290aa0a8",
   "metadata": {},
   "source": [
    "We will work with the dataset [bulgarian-grammar-mistakes](https://huggingface.co/datasets/thebogko/bulgarian-grammar-mistakes) from huggingface. The data was originally collected from articles from Bulgarian Wikipedia as well as rows from OSCAR's Bulgarian datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcc32a-5f12-459a-ab59-ba2af4b805f6",
   "metadata": {},
   "source": [
    "### Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c506fd73-d949-4abb-84dd-258304611a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors = pd.read_csv(\"data/grammar_errors_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60cac664-961b-4e3b-9245-1047c7d5492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7587, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50fece92-6419-4123-825d-41c01d42fbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>erroneous</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>От какво беше направен входа на двора на скини...</td>\n",
       "      <td>От какво беше направен входът на двора на скин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Танева е предупредила, че документа ще се отра...</td>\n",
       "      <td>Танева е предупредила, че документът ще се отр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Патогенетичният механизъм на развитието на хип...</td>\n",
       "      <td>Патогенетичният механизъм на развитието на хип...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Президента и БСП осъдиха екстремизма и езика н...</td>\n",
       "      <td>Президентът и БСП осъдиха екстремизма и езика ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Под дарението стоят името и подписа на просвет...</td>\n",
       "      <td>Под дарението стоят името и подписът на просве...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error_type                                          erroneous  \\\n",
       "0  article_misuse  От какво беше направен входа на двора на скини...   \n",
       "1  article_misuse  Танева е предупредила, че документа ще се отра...   \n",
       "2  article_misuse  Патогенетичният механизъм на развитието на хип...   \n",
       "3  article_misuse  Президента и БСП осъдиха екстремизма и езика н...   \n",
       "4  article_misuse  Под дарението стоят името и подписа на просвет...   \n",
       "\n",
       "                                             correct  \n",
       "0  От какво беше направен входът на двора на скин...  \n",
       "1  Танева е предупредила, че документът ще се отр...  \n",
       "2  Патогенетичният механизъм на развитието на хип...  \n",
       "3  Президентът и БСП осъдиха екстремизма и езика ...  \n",
       "4  Под дарението стоят името и подписът на просве...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bf35e-7202-4a3c-9dd9-0928723ccd3b",
   "metadata": {},
   "source": [
    "#### Filter only errors related to article misuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "508388a9-0423-4788-ab69-c087c335ddd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['article_misuse', 'pronoun_misuse', 'incorrect_verb_suffix_me',\n",
       "       'noun_adjective_disagreement'], dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.error_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "66545708-56f3-49c8-9b67-f3be2d742116",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors = grammar_errors[grammar_errors[\"error_type\"] == \"article_misuse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed80a4ce-9ec0-4631-ab93-06371816762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2349, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb65785-ac38-4ce3-aa8d-88fa1d0533b1",
   "metadata": {},
   "source": [
    "#### Rename column geadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b1988e29-233e-47dc-b926-6c83b7787fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors = grammar_errors.rename(columns={\"erroneous\": \"incorrect\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983486ad-493d-4400-a528-9cd09ee26a4b",
   "metadata": {},
   "source": [
    "#### Add a column with differing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e5d2126-4078-454f-9fec-f32d9aa2e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors[['incorrect', 'correct']] = grammar_errors[['incorrect', 'correct']].map(str.strip)\n",
    "grammar_errors[[\"correct_words\", \"incorrect_words\"]] = grammar_errors.apply(get_differing_words, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c907237-7370-454b-bde5-c02ee2bc98d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "      <th>correct_words</th>\n",
       "      <th>incorrect_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>От какво беше направен входа на двора на скини...</td>\n",
       "      <td>От какво беше направен входът на двора на скин...</td>\n",
       "      <td>входа</td>\n",
       "      <td>входът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Танева е предупредила, че документа ще се отра...</td>\n",
       "      <td>Танева е предупредила, че документът ще се отр...</td>\n",
       "      <td>документа</td>\n",
       "      <td>документът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article_misuse</td>\n",
       "      <td>Патогенетичният механизъм на развитието на хип...</td>\n",
       "      <td>Патогенетичният механизъм на развитието на хип...</td>\n",
       "      <td>излишъка</td>\n",
       "      <td>излишъкът</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error_type                                          incorrect  \\\n",
       "0  article_misuse  От какво беше направен входа на двора на скини...   \n",
       "1  article_misuse  Танева е предупредила, че документа ще се отра...   \n",
       "2  article_misuse  Патогенетичният механизъм на развитието на хип...   \n",
       "\n",
       "                                             correct correct_words  \\\n",
       "0  От какво беше направен входът на двора на скин...         входа   \n",
       "1  Танева е предупредила, че документът ще се отр...     документа   \n",
       "2  Патогенетичният механизъм на развитието на хип...      излишъка   \n",
       "\n",
       "  incorrect_words  \n",
       "0          входът  \n",
       "1      документът  \n",
       "2       излишъкът  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd393de-73e8-464f-a7eb-2043d09c619a",
   "metadata": {},
   "source": [
    "#### Melt the dataset and sort pairs of correct/incorrect sentences to be together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7eb07c3b-6aa5-425a-89c4-ea092e741e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2349, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbbb9be4-95d2-4343-94af-37e92e9e693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors = melt_and_sort_sentences(grammar_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07bd8c5d-043c-4ffd-b54c-399aa5e3bdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4698, 4)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81c25413-fece-437c-b3b8-cfc9197adf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>incorrect_words</th>\n",
       "      <th>correct_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>От какво беше направен входа на двора на скини...</td>\n",
       "      <td>False</td>\n",
       "      <td>входа</td>\n",
       "      <td>входът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>От какво беше направен входът на двора на скин...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Танева е предупредила, че документа ще се отра...</td>\n",
       "      <td>False</td>\n",
       "      <td>документа</td>\n",
       "      <td>документът</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Танева е предупредила, че документът ще се отр...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_correct  \\\n",
       "0  От какво беше направен входа на двора на скини...       False   \n",
       "1  От какво беше направен входът на двора на скин...        True   \n",
       "2  Танева е предупредила, че документа ще се отра...       False   \n",
       "3  Танева е предупредила, че документът ще се отр...        True   \n",
       "\n",
       "  incorrect_words correct_words  \n",
       "0           входа        входът  \n",
       "1                                \n",
       "2       документа    документът  \n",
       "3                                "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577393bc-0932-4268-b1b9-65460a81eb1b",
   "metadata": {},
   "source": [
    "#### Add NLP tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509ef8d-b6be-44e8-b904-68468896560d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:bisque\">⚠️Note that calculating the features using Stanza takes around 1 hour on a laptop with average specs, therefore here we are loading a pre-saved file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "589959b4-463d-490d-a0ba-9c318ae77fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    feature_columns_st = [\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_tokens\", \"n_sents\"]\n",
    "    grammar_errors[feature_columns_st] = df.apply(lambda r: extract_features(nlp_st, r, \"text\"), axis=1, result_type=\"expand\")\n",
    "    grammar_errors.to_csv(\"data/grammar_errors_with_nlp.csv\", index=None)\n",
    "else:\n",
    "    # load from file instead of the above, it is faster\n",
    "    grammar_errors = pd.read_csv(\"data/grammar_errors_with_nlp.csv\")\n",
    "    grammar_errors[\"correct_words\"] = grammar_errors[\"correct_words\"].fillna(\"\")\n",
    "    grammar_errors[\"incorrect_words\"] = grammar_errors[\"incorrect_words\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9d292-af53-4166-bb96-a291da742be5",
   "metadata": {},
   "source": [
    "#### Filter only rows with 1 sentence, no quotes and other special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6069d5c9-16f9-4fed-bcba-23a395d3a8b5",
   "metadata": {},
   "source": [
    "We need to filter out such texts since our rules can't deal with quoted text inside a sentence. Special characters also cause issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83de9b24-569c-499b-a43c-1958ea7c4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors = grammar_errors[grammar_errors[\"n_sents\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b91e10c6-425d-4e59-a1dc-fd7aac1ec83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"[\\'\\\"‘’“”°/≈\\:]\"\n",
    "grammar_errors = grammar_errors[~grammar_errors['text'].str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8738b042-550f-46eb-9379-f08b708f5eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3605, 13)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b1d83-24d2-4ed1-b0f1-580480ab7913",
   "metadata": {},
   "source": [
    "### Test with small subset of the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "39a53b1c-5c27-44ea-a9eb-ea06ac17828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_errors_10tokens = grammar_errors[grammar_errors[\"num_tokens\"] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48a375b2-c8f5-4b39-b05d-93fe15fd84c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 ❌ Сайта Уча. се е в тяхна помощ. (Actual: '', Expected: 'Сайта')\n",
      "32 ❌ Бих искал и аз да дам своя принос. (Actual: '', Expected: 'своя')\n",
      "50 ❌ Заема има предназначение за обзавеждане на дома. (Actual: '', Expected: 'Заема')\n",
      "258 ❌ Рейс контрола пусна кола за сигурност. (Actual: 'Рейс', Expected: 'контрола')\n",
      "259 ❌ Рейс контролът пусна кола за сигурност. (Actual: 'Рейс', Expected: '')\n",
      "332 ❌ Сайта е разработен от Медия груп 24 ООД. (Actual: '', Expected: 'Сайта')\n",
      "338 ❌ Да, това е Учителят. (Actual: 'Учителят', Expected: '')\n",
      "339 ❌ Да, това е Учителят. (Actual: 'Учителят', Expected: '')\n",
      "366 ❌ Триумвирата е мъртъв. (Actual: '', Expected: 'Триумвирата')\n",
      "416 ❌ Пика на есен 2010 ме хвана в София. (Actual: '', Expected: 'Пика')\n",
      "454 ❌ По какво се различава домата от трактора? (Actual: '', Expected: 'домата')\n",
      "458 ❌ Сайта е написан с Notepad. (Actual: '', Expected: 'Сайта')\n",
      "672 ❌ Нужен ли е сапуна за съществуването на човека? (Actual: '', Expected: 'сапуна')\n",
      "702 ❌ Името на философа носи кратера Платон на Луната. (Actual: '', Expected: 'кратера')\n",
      "720 ❌ Като правило кашалота живее в топлите морета. (Actual: '', Expected: 'кашалота')\n",
      "728 ❌ Немеца с гордост казва (Actual: '', Expected: 'Немеца')\n",
      "746 ❌ Постепенно отпада матриархата и се утвърждава патриархата. (Actual: '', Expected: 'матриархата')\n",
      "880 ❌ Бюфета разполага с три шкафа с вътрешни рафтове, (Actual: '', Expected: 'Бюфета')\n",
      "884 ❌ Въпроса е защо? (Actual: '', Expected: 'Въпроса')\n",
      "938 ❌ Гена влиза в състава на хромозомите. (Actual: '', Expected: 'Гена')\n",
      "1048 ❌ Подписа задължително се поставя след завещателните разпореждания. (Actual: '', Expected: 'Подписа')\n",
      "1122 ❌ Не позволявайте на перфекционизмът да бъде враг на производителността (Actual: '', Expected: 'перфекционизмът')\n",
      "1286 ❌ Предизвика истински фурор, неузнаваемият е! (Actual: '', Expected: 'неузнаваемият')\n",
      "1406 ❌ Браво продължавай тъчеш .. (Actual: '', Expected: 'тъчеш')\n",
      "1668 ❌ Името на философът носи кратерът Платон на Луната. (Actual: 'философът,кратерът', Expected: 'философът')\n",
      "1966 ❌ Много често се образува вълнистият повърхност. (Actual: '', Expected: 'вълнистият')\n",
      "2022 ❌ Администраторът на форума така е решил. (Actual: '', Expected: 'Администраторът')\n",
      "2023 ❌ Администратора на форума така е решил. (Actual: 'Администратора', Expected: '')\n",
      "2112 ❌ Има деликатна консистенция и порестият структура. (Actual: '', Expected: 'порестият')\n",
      "2156 ❌ След полимеризация дисперсионния слой се отстранява с Cleaner. (Actual: '', Expected: 'дисперсионния')\n",
      "2186 ❌ Най-левия е за слонове и коне. (Actual: '', Expected: 'Най-левия')\n",
      "2218 ❌ Първоначалния им брой е 500000 души. (Actual: 'брой', Expected: 'Първоначалния')\n",
      "2219 ❌ Първоначалният им брой е 500000 души. (Actual: 'брой', Expected: '')\n",
      "2228 ❌ да отпадне регулаторния натиск върху цените на генерични медикаменти (Actual: '', Expected: 'регулаторния')\n",
      "2300 ❌ Английския не е официален език в САЩ. (Actual: '', Expected: 'Английския')\n",
      "2328 ❌ Английския е най-често използваният език в науката. (Actual: '', Expected: 'Английския')\n",
      "2330 ❌ Баскетболния Екип GIVOVA Kit Power е изработен от .. (Actual: '', Expected: 'Баскетболния')\n",
      "2378 ❌ Максималния му въртяш момент е 350 Nm. (Actual: '', Expected: 'Максималния')\n",
      "2426 ❌ Кафка е обсебен от деспотичния си баща. (Actual: '', Expected: 'деспотичния')\n",
      "2466 ❌ Какво каза новия американски посланик у нас (Actual: '', Expected: 'новия')\n",
      "2682 ❌ Витаминния комплекс се прилага перорално. (Actual: '', Expected: 'Витаминния')\n",
      "3046 ❌ Бариевия дифлуорид се използва в безоксидните стъкла. (Actual: '', Expected: 'Бариевия')\n",
      "3060 ❌ Новия кандидат-премиер е най-видният масон сред лекарите (Actual: '', Expected: 'Новия')\n",
      "3070 ❌ Върховния съд в Калифорния отмени забраната върху гей-браковете (Actual: '', Expected: 'Върховния')\n",
      "3100 ❌ 1 декември- Лисабонския договор влиза в сила. (Actual: '', Expected: 'Лисабонския')\n",
      "3144 ❌ Следваща статия от категорията Йоан- богословът и църковния политик (Actual: '', Expected: 'църковния')\n",
      "3160 ❌ Пловдивския окръжен съд остави в ареста фалшификатор-рецидивист (Actual: '', Expected: 'Пловдивския')\n",
      "3166 ❌ Къде трябва да бъде поставен ръчния багаж макс. (Actual: '', Expected: 'ръчния')\n",
      "3220 ❌ Доказана свръхчувствителност към съставките на лекарственият продукт. (Actual: '', Expected: 'лекарственият')\n",
      "3308 ❌ Това наложи необходимостта от промяна на лечебният алгоритъм. (Actual: '', Expected: 'лечебният')\n",
      "3328 ❌ Страната е един от последните бастиони на световният комунизъм (Actual: '', Expected: 'световният')\n",
      "3384 ❌ Бисквитката съхранява езиковият код на последната прегледана страница. (Actual: '', Expected: 'езиковият')\n",
      "3396 ❌ Официалният език на форума е българският. (Actual: '', Expected: 'Официалният')\n",
      "3397 ❌ Официалния език на форума е българският. (Actual: 'Официалния', Expected: '')\n",
      "3508 ❌ Хранещи се от чревният химус на гостоприемника. (Actual: '', Expected: 'чревният')\n",
      "3650 ❌ Следваща статияНамаляване на адвокатското възнаграждение в изпълнителният процес (Actual: '', Expected: 'изпълнителният')\n",
      "3812 ❌ Разделете се на няколко приема през целият ден. (Actual: '', Expected: 'целият')\n",
      "3916 ❌ ГЕРБ, ДПС и БСП върнаха хартиеният вот. (Actual: '', Expected: 'хартиеният')\n",
      "3942 ❌ Това е успокоителният хап за съвестта му ... (Actual: '', Expected: 'успокоителният')\n",
      "3943 ❌ Това е успокоителния хап за съвестта му ... (Actual: 'успокоителния', Expected: '')\n",
      "3952 ❌ Картината беше на правилният слой. (Actual: '', Expected: 'правилният')\n",
      "3964 ❌ Най-близък до английският е шотландският език. (Actual: '', Expected: 'английският')\n",
      "4014 ❌ Наградата била 15 -минутен полет със злополучният самолет. (Actual: '', Expected: 'злополучният')\n",
      "4024 ❌ Дуриан е наистина най-миризливият плод в света. (Actual: '', Expected: 'най-миризливият')\n",
      "4034 ❌ Тези инструменти били използвани в симфоничният оркестър. (Actual: '', Expected: 'симфоничният')\n",
      "4098 ❌ Най-старите известни държави са тези от Древният Изток. (Actual: '', Expected: 'Древният')\n",
      "4110 ❌ Задържаха областният координатор на ГЕРБ в Пловдив Георги Мараджиев (Actual: '', Expected: 'областният')\n",
      "4130 ❌ Който пък е роден в днешният град Ниш. (Actual: '', Expected: 'днешният')\n",
      "❌ 68/250 failed.\n"
     ]
    }
   ],
   "source": [
    "# execution will take 30 sec\n",
    "passed, failed = test_definite_article_all(grammar_errors_10tokens, conditions, rules, print_passed=False, print_failed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e8622-cd5c-4501-a6fa-6e69b96ae543",
   "metadata": {},
   "source": [
    "Let's review the outcomes.\n",
    "\n",
    "**To begin with**, the rules failed to detect errors in nearly a quarter (24%) of the tests.\n",
    "However, upon closer inspection of the failures, a pattern emerges. Upon closer look, it is evident that most of the failed tests have even-numbered indices. This suggests that while correctly formed sentences were accurately identified, not all erroneous sentences were successfully detected.\n",
    "\n",
    "Let's take a closer look at the instances where the tests failed for sentences that were initially correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87cdc332-0891-44fd-aca3-da2df60884ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>incorrect_words</th>\n",
       "      <th>correct_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Да, това е Учителят.</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Да, това е Учителят.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Администраторът на форума така е решил.</td>\n",
       "      <td>False</td>\n",
       "      <td>Администраторът</td>\n",
       "      <td>Администратора</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Администратора на форума така е решил.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>Официалният език на форума е българският.</td>\n",
       "      <td>False</td>\n",
       "      <td>Официалният</td>\n",
       "      <td>Официалния</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>Официалния език на форума е българският.</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>Това е успокоителният хап за съвестта му ...</td>\n",
       "      <td>False</td>\n",
       "      <td>успокоителният</td>\n",
       "      <td>успокоителния</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>Това е успокоителния хап за съвестта му ...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  is_correct  \\\n",
       "338                           Да, това е Учителят.       False   \n",
       "339                           Да, това е Учителят.        True   \n",
       "2022       Администраторът на форума така е решил.       False   \n",
       "2023        Администратора на форума така е решил.        True   \n",
       "3396     Официалният език на форума е българският.       False   \n",
       "3397      Официалния език на форума е българският.        True   \n",
       "3942  Това е успокоителният хап за съвестта му ...       False   \n",
       "3943   Това е успокоителния хап за съвестта му ...        True   \n",
       "\n",
       "      incorrect_words   correct_words  \n",
       "338                                    \n",
       "339                                    \n",
       "2022  Администраторът  Администратора  \n",
       "2023                                   \n",
       "3396      Официалният      Официалния  \n",
       "3397                                   \n",
       "3942   успокоителният   успокоителния  \n",
       "3943                                   "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.loc[[338, 339, 2022, 2023, 3396, 3397, 3942, 3943 ]][['text', 'is_correct', 'incorrect_words', 'correct_words']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b0bd2b-2d8e-4253-b528-578e2599e078",
   "metadata": {},
   "source": [
    "The sentence _Да, това е Учителят_ is listed as both correct and incorrect.\n",
    "\n",
    "The sentence _Администратора на форума така е решил_ is listed as correct, but in fact it is not.\n",
    "\n",
    "The sentence _Това е успокоителния хап за съвестта му_ is also listed as correct, but in fact it is incorrect.\n",
    "\n",
    "Therefore, in at least these 3 examples, the rules correctly identified the error, but the expected result was wrong bcause the original data in the dataset was wrong. \n",
    "\n",
    "The assumption about the original wrong data is, that the data was scraped from various sources and considered \"correct\", then errors were automatically introduced to produce the incorrect version. However, it's important to note that the source material itself may not always be grammatically accurate. For exmaple, the sentence _Това е успокоителния хап за съвестта му_ can be found [in a blog comment from 2010](https://petdoshkov.blog.bg/drugi/2010/05/10/vyzzivnoto-reshenie-za-nakazanieto-zabelejka.542411). This example demonstrates that even the original text contained grammatical errors, challenging the assumption that the initial data was entirely correct before deliberate mistakes were added.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6e2d3-eb68-4651-a094-cd6391e08fad",
   "metadata": {},
   "source": [
    "**Another reason** of the many failures is that we still haven't implemented all rules listed in the Grammas section. Additionally, we tested on a small set of 39 pairs of simple sentences so we didn't verify our \"model\" with enough data. Another explanation is that in the NLP features we extracted there are two still unused ones - left edge and right edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22819899-bcfd-4ce1-8f1b-6cc21cdc3070",
   "metadata": {},
   "source": [
    "### Test with the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "08bc0c40-1ab1-4a6f-9f5a-168b0fb5642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3605, 13)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef08480-abab-4652-8b2d-9ae260951eb6",
   "metadata": {},
   "source": [
    "<div style=\"background-color:Bisque\">\n",
    "\n",
    "⚠️The below test will take ~ 18 minutes. As an alternative to executing it you may take a look at the screenshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "68ee147a-d38b-4162-8012-568185691cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    passed, failed = test_definite_article_all(grammar_errors, conditions, rules, print_passed=False, print_failed=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time_st = end_time - start_time\n",
    "    print(f\"Execution time (stanza): {execution_time_st} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68588f7c-de57-4021-ae8d-bced38631a98",
   "metadata": {},
   "source": [
    "Screenshot of the result:\n",
    "\n",
    "<img src=\"images/whole_dataset_result.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb232d5-6a7b-4a5c-9134-355b9dd972e9",
   "metadata": {},
   "source": [
    "Testing with the whole dataset we see that one third of the tests failed. Certainly there is room for improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f673fcc-1dd8-4ab3-a0e3-002660e97a5d",
   "metadata": {},
   "source": [
    "Although the results of the final test were not as encouraging as hoped, the project still yielded valuable insights.\n",
    "\n",
    "Initially, selecting the appropriate NLP library was a challenging task. While UDPipe offered good performance, it lacked accuracy, and although Stanza delivered better results, it was much slower. This experience highlighted the importance of carefully balancing accuracy and performance when choosing tools for linguistic analysis.\n",
    "\n",
    "Another key realization was the unexpected complexity of Bulgarian grammar, particularly the rules surrounding the use of the definite article. This complexity necessitated a deeper investigation into the language's linguistic structures.\n",
    "\n",
    "Parsing text to detect incorrect definite articles also proved to be more complicated than expected. The development of effective rules for this task was hindered by the diversity of sentence structures encountered.\n",
    "\n",
    "Additionally, the testing dataset posed its own challenges, as it contained inaccuracies that affected the validation process. This emphasized the crucial need for high-quality, accurate datasets.\n",
    "\n",
    "Despite these obstacles, the implementation of rule-based methods produced promising results, especially in identifying errors in shorter sentences. This success demonstrated that even in the face of linguistic complexity, well-designed rules are essential for achieving accurate outcomes.\n",
    "\n",
    "The insights gained from this effort will undoubtedly contribute to the broader field of computational linguistics and inspire more accurate and efficient solutions for grammatical analysis in Bulgarian. As we continue to refine our approach and expand our rule set, we are confident in our ability to develop a robust and reliable tool for checking the correctness of definite articles in Bulgarian texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab702264-ac2f-4fe8-b244-7e0bd6f9f529",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "<div id=\"ref1\">[1] Astoria Academy, <a href=\"https://astoria-academy.com/the-definite-articles-of-bulgarian/\">The Definite articles of Bulgarian,</a> 2023</div>\n",
    "\n",
    "<div id=\"ref2\">[2] CoLanguage <a href=\"https://www.colanguage.com/definite-article-bulgarian-nouns\">Definite article of the Bulgarian nouns</a></div>\n",
    "\n",
    "<div id=\"ref3\">[3] в. „Аз Буки“ бр. 16 <a href=\"https://ibl.bas.bg/ezikovi_spravki/otnovo-za-palniya-i-kratkiya-tchlen/\">Отново за пълния и краткия член</a></div>\n",
    "\n",
    "<div id=\"ref4\">[4] Raquel Jacob <a href=\"https://help.unbabel.com/hc/en-us/articles/360022878854-Language-Guidelines-Bulgarian\">Language Guidelines – Bulgarian</a></div>\n",
    "\n",
    "<div id=\"ref5\">[5] Andonova, Sabeva, Zagorova <a href=\"https://caritas.bg/cms/wp-content/uploads/2015/04/A1-English.pdf?x10535\">Bulgarian for Refugees,</a> 2014</div>\n",
    "\n",
    "<div id=\"ref6\">[6] John Leafgren <a href=\"http://www.seelrc.org:8080/grammar/pdf/stand_alone_bulgarian.pdf\">A Concise Bulgarian\n",
    "Grammar</a></div>\n",
    "\n",
    "<div id=\"ref7\">[7] G. Popova <a href=\"https://www.english-linguistics.de/archives/clark/SIMOV/CM/popova.pdf\">Towards an HPSG Account of the\n",
    "Bulgarian Definite Article</a></div>\n",
    "\n",
    "<div id=\"ref8\">[8] K. Bontcheva <a href=\"https://theswissbay.ch/pdf/Books/Linguistics/Mega%20linguistics%20pack/Indo-European/Balto-Slavic/Bulgarian%20Grammar%2C%20Elementary%20%28Bontcheva%29.pdf\">Bulgarian Language - Grammar</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228196e-4193-4c5c-86ae-e9ac57b8051d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jpcodetoc-showcode": false,
  "jpcodetoc-showmarkdowntxt": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
