{"cells":[{"cell_type":"code","source":["!ls -al"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZDTCS6XrcUU","executionInfo":{"status":"ok","timestamp":1737275289971,"user_tz":-120,"elapsed":310,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"a75ffdb9-2d2e-4f0f-d476-99c4063d9ac6"},"id":"HZDTCS6XrcUU","execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["total 14048\n","drwxr-xr-x 1 root root     4096 Jan 19 07:22 .\n","drwxr-xr-x 1 root root     4096 Jan 19 07:17 ..\n","-rw-r--r-- 1 root root 14360705 Jan 19 08:00 bulgarian-btb-ud-2.5-191206.udpipe\n","drwxr-xr-x 4 root root     4096 Jan 16 14:29 .config\n","drwxr-xr-x 1 root root     4096 Jan 16 14:29 sample_data\n","drwxr-xr-x 3 root root     4096 Jan 19 07:22 stanza_resources\n"]}]},{"cell_type":"code","execution_count":71,"id":"cc07f59a-1d00-47d5-9119-805cd963b645","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc07f59a-1d00-47d5-9119-805cd963b645","executionInfo":{"status":"ok","timestamp":1737275292364,"user_tz":-120,"elapsed":2096,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"439d5ab3-d0dc-4594-cfef-6d3e2acdee7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ufal.udpipe in /usr/local/lib/python3.11/dist-packages (1.3.1.1)\n"]}],"source":["!pip install ufal.udpipe"]},{"cell_type":"code","execution_count":72,"id":"47ba6dbb-7300-4aa4-be29-9428e6935672","metadata":{"id":"47ba6dbb-7300-4aa4-be29-9428e6935672","executionInfo":{"status":"ok","timestamp":1737275292364,"user_tz":-120,"elapsed":6,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["from spacy.tokens import Doc\n","from ufal.udpipe import Model, Pipeline\n","\n","import os\n","import pandas as pd\n","import re\n","import spacy\n","import spacy_stanza\n","import stanza\n","import time\n","import urllib.request\n","import warnings"]},{"cell_type":"code","execution_count":73,"id":"89c20c6e-a84f-4573-8ee9-862665a570fc","metadata":{"id":"89c20c6e-a84f-4573-8ee9-862665a570fc","executionInfo":{"status":"ok","timestamp":1737275292365,"user_tz":-120,"elapsed":6,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# Suppress specific warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*torch.load.*\")"]},{"cell_type":"code","source":["USE_STANZA=False"],"metadata":{"id":"zu0xmzBUdxpA","executionInfo":{"status":"ok","timestamp":1737275292365,"user_tz":-120,"elapsed":6,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"zu0xmzBUdxpA","execution_count":74,"outputs":[]},{"cell_type":"markdown","id":"e30debef-d1a9-4421-897e-eefc36abc031","metadata":{"id":"e30debef-d1a9-4421-897e-eefc36abc031"},"source":["# Linguistic Rule-Based System for Definite Article Verification in Bulgarian Language"]},{"cell_type":"markdown","id":"a4992f6d-bfa2-44e9-8c58-8ba891bde1e0","metadata":{"id":"a4992f6d-bfa2-44e9-8c58-8ba891bde1e0"},"source":["## 3 Experiments with Stanza and UDPipe"]},{"cell_type":"markdown","id":"9db3f3a8-f662-4859-a172-c7487ada73a1","metadata":{"id":"9db3f3a8-f662-4859-a172-c7487ada73a1"},"source":["### 3.1 Download and initialize Bulgarian models"]},{"cell_type":"code","execution_count":75,"id":"dce83e48-74be-44de-bbb3-93bd76c8d883","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dce83e48-74be-44de-bbb3-93bd76c8d883","executionInfo":{"status":"ok","timestamp":1737275297973,"user_tz":-120,"elapsed":5614,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"d0ddaae3-2b30-465f-8c9a-bfd6a33373f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('bulgarian-btb-ud-2.5-191206.udpipe',\n"," <http.client.HTTPMessage at 0x7d29716a7f50>)"]},"metadata":{},"execution_count":75}],"source":["# Download the UDPipe Bulgarian model\n","model_url_udpipe = \"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3131/bulgarian-btb-ud-2.5-191206.udpipe?sequence=6&isAllowed=y\"\n","model_filename_udpipe = \"bulgarian-btb-ud-2.5-191206.udpipe\"\n","urllib.request.urlretrieve(model_url_udpipe, model_filename_udpipe)"]},{"cell_type":"code","execution_count":76,"id":"54c8e261-95cd-4193-b25f-40b99b7b801f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54c8e261-95cd-4193-b25f-40b99b7b801f","executionInfo":{"status":"ok","timestamp":1737275298404,"user_tz":-120,"elapsed":5,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"eee869df-8ede-4772-9c49-6ce1fae909c3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]}],"source":["# Load the UDPipe nlp pipeline\n","model_udpipe = Model.load(model_filename_udpipe)\n","pipeline_udpipe = Pipeline(model_udpipe, \"tokenize\", Pipeline.DEFAULT, Pipeline.DEFAULT, \"conllu\")\n","nlp_spacy_udpipe = spacy.blank(\"bg\")"]},{"cell_type":"markdown","id":"6e66b855-df4c-41d0-9761-b65813309cf2","metadata":{"id":"6e66b855-df4c-41d0-9761-b65813309cf2"},"source":["### 3.2 Define initial functions"]},{"cell_type":"markdown","id":"e80b6ee7-285a-47e6-a5a0-9c5c6d37c0c8","metadata":{"id":"e80b6ee7-285a-47e6-a5a0-9c5c6d37c0c8"},"source":["We need some functions for creating the NLP objects for Stanza and UDPipe."]},{"cell_type":"code","source":["def extract_gender_from_tag(tag):\n","    gender = \" \"\n","    # gender is applicable to common noun, proper noun or adjective\n","    if tag.startswith((\"Nc\", \"Np\", \"A\")):\n","        if \"m\" in tag:\n","            gender = \"Masculine\"\n","        elif \"f\" in tag:\n","            gender = \"Feminine\"\n","        elif \"n\" in tag:\n","            gender = \"Neutral\"\n","    return gender\n","\n","# TODO: need to exclude triple character patterns like \"p1s\": \"Past tense, 1st person sng\",\n","def extract_number_from_tag(tag):\n","    number = None\n","    if \"s\" in tag:\n","        number = \"Singular\"\n","    elif \"p\" in tag:\n","        number = \"Plural\"\n","    return number\n","\n","def is_masculine(row_dict, i):\n","    tag = row_dict[\"tag\"].split(\",\")[i]\n","    return extract_gender_from_tag(tag) == \"Masculine\"\n","\n","def is_singular(row_dict, i):\n","    tag = row_dict[\"tag\"].split(\",\")[i]\n","    return extract_number_from_tag(tag) == \"Singular\"\n","\n","def is_masculine_singular(row_dict, i):\n","    return is_masculine(row_dict, i) and is_singular(row_dict, i)\n","\n","def is_dep_subject(row_dict, i):\n","    dep = row_dict[\"dep\"].split(\",\")[i]\n","    return dep in {\"nsubj\", \"csubj\", \"nsubj:pass\", \"csubj:pass\"}\n","\n","def nlp_get_pos(row_dict, i):\n","    return row_dict[\"pos\"].split(\",\")[i]\n","\n","def nlp_get_dep(row_dict, i):\n","    return row_dict[\"dep\"].split(\",\")[i]\n","\n","def nlp_get_lemma(row_dict, i):\n","    return row_dict[\"lemmas\"].split(\",\")[i]\n","\n","def nlp_get_article(row_dict, i):\n","    morph = row_dict[\"morph\"].split(\",\")[i]\n","    if \"Definite=Def\" in morph:\n","        return \"definite\"\n","    elif \"Definite=Ind\" in morph:\n","        return \"indefinite\"\n","    else:\n","        return \"\""],"metadata":{"id":"Qj85KXhW27fL","executionInfo":{"status":"ok","timestamp":1737275298404,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"Qj85KXhW27fL","execution_count":77,"outputs":[]},{"cell_type":"code","source":["# for quick viewing the features\n","# use updpipe object for the extraction of the word because of performance\n","# use stanza object for determining features because of accuracy\n","def inspect_word_prev(row_dict, word_num):\n","    word = nlp_ud(row_dict[\"text\"])[word_num].text\n","    pos = row_dict[\"pos\"].split(\",\")[word_num]\n","    tag = row_dict[\"tag\"].split(\",\")[word_num]\n","    dep = row_dict[\"dep\"].split(\",\")[word_num]\n","\n","    gen_s = extract_gender_from_tag(tag)[0:1]  # M - Masculine, F - Feminine, N - Neutral\n","    gen_s = extract_gender_from_tag(tag)[0:1] if extract_gender_from_tag(tag) else \" \"\n","    # num_s = extract_number_from_tag(tag)[0:1]\n","    num_s = extract_number_from_tag(tag)[0:1] if extract_number_from_tag(tag) else \"\"\n","\n","    # return f\"{row_dict['index']} {word:<15} POS:{pos:<{10}} Gen:{gen_s}    Num:{num_s}   DEP:{dep:<{10}} Sent: {row_dict[\"text\"]:<30}\"\n","    return f\"{row_dict['index']} {word:<15} POS:{pos:<{10}} Gen:{gen_s}    Num:{num_s}   DEP:{dep:<{10}} Sent: {row_dict['text'][:30]}\""],"metadata":{"id":"qXk_a5a63UEa","executionInfo":{"status":"ok","timestamp":1737275298404,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"qXk_a5a63UEa","execution_count":78,"outputs":[]},{"cell_type":"code","source":["# for quick viewing the features\n","# use updpipe object for the extraction of the word because of performance\n","# use stanza object for determining features because of accuracy\n","def inspect_word(row_dict, word_num):\n","    word = nlp_ud(row_dict[\"text\"])[word_num].text\n","    pos = row_dict[\"pos\"].split(\",\")[word_num]\n","    tag = row_dict[\"tag\"].split(\",\")[word_num]\n","    dep = row_dict[\"dep\"].split(\",\")[word_num]\n","\n","    gen_s = extract_gender_from_tag(tag)[0:1]  # M - Masculine, F - Feminine, N - Neutral\n","    gen_s = extract_gender_from_tag(tag)[0:1] if extract_gender_from_tag(tag) else \" \"\n","    # num_s = extract_number_from_tag(tag)[0:1]\n","    num_s = extract_number_from_tag(tag)[0:1] if extract_number_from_tag(tag) else \"\"\n","\n","    # return f\"{row_dict['index']} {word:<15} POS:{pos:<{10}} Gen:{gen_s}    Num:{num_s}   DEP:{dep:<{10}} Sent: {row_dict[\"text\"]:<30}\"\n","    return f\"{row_dict['index']} {word:<15} POS:{pos:<{10}} Gen:{gen_s}    Num:{num_s}   DEP:{dep:<{10}} Sent: {row_dict['text'][:30]}\""],"metadata":{"id":"-mPtBinHdfiK","executionInfo":{"status":"ok","timestamp":1737275298405,"user_tz":-120,"elapsed":5,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"-mPtBinHdfiK","execution_count":79,"outputs":[]},{"cell_type":"code","source":["def row_to_dict(df, index):\n","    row_dict = df.loc[index].to_dict()\n","    row_dict[\"index\"] = index\n","    return row_dict"],"metadata":{"id":"FwhVja5C3y9k","executionInfo":{"status":"ok","timestamp":1737275298405,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"FwhVja5C3y9k","execution_count":80,"outputs":[]},{"cell_type":"code","execution_count":81,"id":"1bb8d1c4-7f37-47f6-926c-88f36e66f998","metadata":{"id":"1bb8d1c4-7f37-47f6-926c-88f36e66f998","executionInfo":{"status":"ok","timestamp":1737275298405,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def udpipe_to_spacy(text, nlp):\n","    \"\"\"Parses a CoNLL-U formatted string into a spaCy Doc object.\"\"\"\n","    doc_str = pipeline_udpipe.process(text)\n","    lines = doc_str.strip().splitlines()\n","    words = []\n","    lemmas = []\n","    spaces = []\n","    pos_tags = []\n","    morph_tags = []\n","    dep_heads = []\n","    dep_rels = []\n","\n","    for line in lines:\n","        if line.startswith(\"#\") or not line.strip():\n","            continue\n","\n","        parts = line.split(\"\\t\")\n","        index, word, lemma, pos, tag, feats, head, dep_rel, _, misc = parts\n","\n","        words.append(word)\n","        lemmas.append(lemma)\n","        pos_tags.append(pos)  # POS tag (simpler POS category)\n","        morph_tags.append(tag)  # Detailed morphological tag\n","        dep_heads.append(int(head) - 1)  # Convert to zero-indexed\n","        dep_rels.append(dep_rel)\n","\n","        if \"SpaceAfter=No\" in misc:\n","            spaces.append(False)\n","        else:\n","            spaces.append(True)\n","\n","    # Create the Doc object\n","    doc = Doc(nlp.vocab, words=words, spaces=spaces)\n","\n","    # Set the POS tags, morphological tags, lemmas, and dependency parsing information\n","    for token, lemma, pos, morph_tag, head, dep_rel in zip(doc, lemmas, pos_tags, morph_tags, dep_heads, dep_rels):\n","        token.lemma_ = lemma\n","        token.pos_ = pos  # Simple POS tag\n","        token.tag_ = morph_tag  # Detailed morphological tag\n","        token.head = doc[head] if head >= 0 else token\n","        token.dep_ = dep_rel\n","\n","    return doc"]},{"cell_type":"code","execution_count":82,"id":"babaecc9-7543-4510-bd5c-b37b88e1b3c6","metadata":{"id":"babaecc9-7543-4510-bd5c-b37b88e1b3c6","executionInfo":{"status":"ok","timestamp":1737275298405,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def nlp_ud(txt):\n","    return udpipe_to_spacy(txt, nlp_spacy_udpipe)"]},{"cell_type":"markdown","id":"be7dab88-0168-481c-a3ff-cd130a69dfb1","metadata":{"id":"be7dab88-0168-481c-a3ff-cd130a69dfb1"},"source":["### 3.3 Compare NLP features"]},{"cell_type":"code","execution_count":83,"id":"f94ece13-75b0-4531-b845-f8b382992548","metadata":{"id":"f94ece13-75b0-4531-b845-f8b382992548","executionInfo":{"status":"ok","timestamp":1737275298405,"user_tz":-120,"elapsed":4,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# A helper function for displaying useful NLP features in easy to read format\n","def inspect_spacy_doc(doc):\n","    for token in doc:\n","        print(f\"Token: {token.text:<15} Tag: {token.tag_:<15} POS: {token.pos_:<10} Lemma: {token.lemma_:<15} Dep: {token.dep_:<10}\")\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":84,"id":"63283d73-0b39-49b5-8666-6e82566ece38","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63283d73-0b39-49b5-8666-6e82566ece38","executionInfo":{"status":"ok","timestamp":1737275298864,"user_tz":-120,"elapsed":463,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"4e73ccea-a078-49b3-98b1-8199b540784d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","NLP features from UDPipe:\n","Token: –°—Ä–µ–¥            Tag: R               POS: ADP        Lemma: —Å—Ä–µ–¥            Dep: case      \n","Token: –≥–æ—Å—Ç–∏—Ç–µ         Tag: Ncmpd           POS: NOUN       Lemma: –≥–æ—Å—Ç            Dep: nmod      \n","Token: –Ω–∞              Tag: R               POS: ADP        Lemma: –Ω–∞              Dep: case      \n","Token: –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞     Tag: Afsd            POS: ADJ        Lemma: –æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω       Dep: amod      \n","Token: —Ü–µ—Ä–µ–º–æ–Ω–∏—è       Tag: Ncfsi           POS: NOUN       Lemma: —Ü–µ—Ä–µ–º–æ–Ω–∏—è       Dep: nmod      \n","Token: –ø–æ              Tag: R               POS: ADP        Lemma: –ø–æ              Dep: case      \n","Token: –≤—Å—Ç—ä–ø–≤–∞–Ω–µ       Tag: Ncnsi           POS: NOUN       Lemma: –≤—Å—Ç—ä–ø–≤–∞–Ω–µ       Dep: nmod      \n","Token: –≤               Tag: R               POS: ADP        Lemma: –≤               Dep: case      \n","Token: –¥–ª—ä–∂–Ω–æ—Å—Ç        Tag: Ncfsi           POS: NOUN       Lemma: –¥–ª—ä–∂–Ω–æ—Å—Ç        Dep: nmod      \n","Token: –Ω–∞              Tag: R               POS: ADP        Lemma: –Ω–∞              Dep: case      \n","Token: –Ω–æ–≤–æ–∏–∑–±—Ä–∞–Ω–∏—è    Tag: Amsh            POS: ADJ        Lemma: –Ω–æ–≤–æ–∏–∑–±—Ä–∞–º      Dep: amod      \n","Token: –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç       Tag: Ncmsi           POS: NOUN       Lemma: –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç       Dep: nmod      \n","Token: —â–µ              Tag: Tx              POS: AUX        Lemma: —â–µ              Dep: aux       \n","Token: –±—ä–¥–∞—Ç           Tag: Vyptf-r3p       POS: AUX        Lemma: –±—ä–¥–∞            Dep: cop       \n","Token: –±—ä–ª–≥–∞—Ä—Å–∫–∏—è—Ç     Tag: Amsf            POS: ADJ        Lemma: –±—ä–ª–≥–∞—Ä—Å–∫–∏       Dep: amod      \n","Token: –¥—ä—Ä–∂–∞–≤–µ–Ω        Tag: Amsi            POS: ADJ        Lemma: –¥—ä—Ä–∂–∞–≤–µ–Ω        Dep: amod      \n","Token: –≥–ª–∞–≤–∞           Tag: Ncmsi           POS: NOUN       Lemma: –≥–ª–∞–≤–∞           Dep: root      \n","Token: –†—É–º–µ–Ω           Tag: Npmsi           POS: PROPN      Lemma: —Ä—É–º–µ–Ω           Dep: nmod      \n","Token: –†–∞–¥–µ–≤           Tag: Hmsi            POS: PROPN      Lemma: —Ä–∞–¥–µ–≤           Dep: flat      \n","Token: ,               Tag: punct           POS: PUNCT      Lemma: ,               Dep: punct     \n","Token: –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—ä—Ç     Tag: Ncmsf           POS: NOUN       Lemma: –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç       Dep: nsubj     \n","Token: –Ω–∞              Tag: R               POS: ADP        Lemma: –Ω–∞              Dep: case      \n","Token: –ê–ª–±–∞–Ω–∏—è         Tag: Npfsi           POS: PROPN      Lemma: –∞–ª–±–∞–Ω–∏—è         Dep: nmod      \n","Token: –ò–ª–∏—Ä            Tag: Hfsi            POS: PROPN      Lemma: –ò–ª–∏—Ä            Dep: nmod      \n","Token: –ú–µ—Ç–∞            Tag: Npfsi           POS: PROPN      Lemma: –ú–µ—Ç–∞            Dep: flat      \n","Token: –∏               Tag: Cp              POS: CCONJ      Lemma: –∏               Dep: cc        \n","Token: –Ω–∞              Tag: R               POS: ADP        Lemma: –Ω–∞              Dep: case      \n","Token: –ö–æ—Å–æ–≤–æ          Tag: Npnsi           POS: PROPN      Lemma: –∫–æ—Å–æ–≤–æ          Dep: conj      \n","Token: –•–∞—à–∏–º           Tag: Npmsi           POS: PROPN      Lemma: –•–∞—à–∏–º           Dep: flat      \n","Token: –¢–∞—á–∏            Tag: Tv              POS: PART       Lemma: –¢–∞—á–∞            Dep: discourse \n","Token: .               Tag: punct           POS: PUNCT      Lemma: .               Dep: punct     \n","\n","\n"]}],"source":["sentence = \"\"\"–°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏—è –ø–æ –≤—Å—Ç—ä–ø–≤–∞–Ω–µ –≤ –¥–ª—ä–∂–Ω–æ—Å—Ç –Ω–∞ –Ω–æ–≤–æ–∏–∑–±—Ä–∞–Ω–∏—è –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç —â–µ –±—ä–¥–∞—Ç –±—ä–ª–≥–∞—Ä—Å–∫–∏—è—Ç \\\n","–¥—ä—Ä–∂–∞–≤–µ–Ω –≥–ª–∞–≤–∞ –†—É–º–µ–Ω –†–∞–¥–µ–≤, –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—ä—Ç –Ω–∞ –ê–ª–±–∞–Ω–∏—è –ò–ª–∏—Ä –ú–µ—Ç–∞ –∏ –Ω–∞ –ö–æ—Å–æ–≤–æ –•–∞—à–∏–º –¢–∞—á–∏.\"\"\"\n","doc_ud = nlp_ud(sentence)\n","\n","print(\"\\nNLP features from UDPipe:\")\n","inspect_spacy_doc(doc_ud)"]},{"cell_type":"markdown","id":"48993890-ac0d-46d3-af2b-c5efc329681b","metadata":{"id":"48993890-ac0d-46d3-af2b-c5efc329681b"},"source":["### 3.5 Compare performance with large amount of data"]},{"cell_type":"code","execution_count":87,"id":"584a0d7b-3e74-4c18-9dbc-becf2144a153","metadata":{"id":"584a0d7b-3e74-4c18-9dbc-becf2144a153","executionInfo":{"status":"ok","timestamp":1737275298865,"user_tz":-120,"elapsed":9,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# Create a DataFrame with 10 rows, use same sentence for simplicity\n","test_df = pd.DataFrame({\"text\": [sentence] * 10})"]},{"cell_type":"code","execution_count":95,"id":"8e16bfd3-ae98-4980-9ceb-18ac29eadfb8","metadata":{"id":"8e16bfd3-ae98-4980-9ceb-18ac29eadfb8","executionInfo":{"status":"ok","timestamp":1737275441288,"user_tz":-120,"elapsed":281,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def sent_features_to_string(sent):\n","    \"\"\"Converts sentence features to strings\"\"\"\n","    pos = \",\".join([tk.pos_ for tk in sent])\n","    tag = \",\".join([tk.tag_ for tk in sent])\n","    dep = \",\".join([tk.dep_ for tk in sent])\n","    morph = \",\".join([str(tk.morph) for tk in sent])\n","    lemmas = \",\".join([str(tk.lemma_) for tk in sent])\n","    n_tokens = len(sent)\n","\n","    return pos, tag, dep, morph, lemmas,n_tokens\n","\n","def udpipe_sentence_to_features(nlp, row, col):\n","    \"\"\"Extracts linguistic features from a text column using a given NLP model\"\"\"\n","    value = row[col]\n","    doc = nlp(value)\n","    return sent_features_to_string(doc)"]},{"cell_type":"markdown","id":"50f483e6-4278-47b3-b550-06bfb838241d","metadata":{"id":"50f483e6-4278-47b3-b550-06bfb838241d"},"source":["#### 3.5.2 Extracting features using UDPipe"]},{"cell_type":"code","execution_count":96,"id":"c65572e8-e775-4e62-83c0-f083a622792b","metadata":{"id":"c65572e8-e775-4e62-83c0-f083a622792b","executionInfo":{"status":"ok","timestamp":1737275443915,"user_tz":-120,"elapsed":261,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_df[[\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"num_words\"]] = test_df.apply(\n","    lambda r: udpipe_sentence_to_features(nlp_ud, r, \"text\"), axis=1, result_type=\"expand\"\n",")"]},{"cell_type":"markdown","id":"014a8804-5952-40c5-ae60-efce738a0e4b","metadata":{"id":"014a8804-5952-40c5-ae60-efce738a0e4b"},"source":["#### 3.5.3 Comparison of the performance"]},{"cell_type":"code","source":["test_df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dr7PlARY1GiX","executionInfo":{"status":"ok","timestamp":1737275299164,"user_tz":-120,"elapsed":307,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"8e2d82d5-e8e7-49f9-e9fe-81cbd096eaf8"},"id":"Dr7PlARY1GiX","execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['text', 'pos', 'tag', 'dep', 'morph', 'lemmas', 'num_words'], dtype='object')"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["test_df.loc[0, 'lemmas']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"Z-r4rJPTAifT","executionInfo":{"status":"ok","timestamp":1737275299164,"user_tz":-120,"elapsed":5,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"512530c4-6d80-48df-a746-c5825468b6bf"},"id":"Z-r4rJPTAifT","execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'—Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,–≤,–¥–ª—ä–∂–Ω–æ—Å—Ç,–Ω–∞,–Ω–æ–≤–æ–∏–∑–±—Ä–∞–º,–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç,—â–µ,–±—ä–¥–∞,–±—ä–ª–≥–∞—Ä—Å–∫–∏,–¥—ä—Ä–∂–∞–≤–µ–Ω,–≥–ª–∞–≤–∞,—Ä—É–º–µ–Ω,—Ä–∞–¥–µ–≤,,,–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç,–Ω–∞,–∞–ª–±–∞–Ω–∏—è,–ò–ª–∏—Ä,–ú–µ—Ç–∞,–∏,–Ω–∞,–∫–æ—Å–æ–≤–æ,–•–∞—à–∏–º,–¢–∞—á–∞,.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["assert test_df.loc[0, 'lemmas'] == '—Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,–≤,–¥–ª—ä–∂–Ω–æ—Å—Ç,–Ω–∞,–Ω–æ–≤–æ–∏–∑–±—Ä–∞–º,–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç,—â–µ,–±—ä–¥–∞,–±—ä–ª–≥–∞—Ä—Å–∫–∏,–¥—ä—Ä–∂–∞–≤–µ–Ω,–≥–ª–∞–≤–∞,—Ä—É–º–µ–Ω,—Ä–∞–¥–µ–≤,,,–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç,–Ω–∞,–∞–ª–±–∞–Ω–∏—è,–ò–ª–∏—Ä,–ú–µ—Ç–∞,–∏,–Ω–∞,–∫–æ—Å–æ–≤–æ,–•–∞—à–∏–º,–¢–∞—á–∞,.'"],"metadata":{"id":"qm1GKwyzrgnO","executionInfo":{"status":"ok","timestamp":1737275379561,"user_tz":-120,"elapsed":276,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"qm1GKwyzrgnO","execution_count":94,"outputs":[]},{"cell_type":"code","source":["test_df.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":271},"id":"gJ61SkelfhDW","executionInfo":{"status":"ok","timestamp":1737273674459,"user_tz":-120,"elapsed":501,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"e87a7eb1-f0da-4994-d408-b23e272fe74b"},"id":"gJ61SkelfhDW","execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  \\\n","0  –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏—è –ø–æ –≤—Å—Ç—ä–ø...   \n","1  –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏—è –ø–æ –≤—Å—Ç—ä–ø...   \n","\n","                                                 pos  \\\n","0  ADP,NOUN,ADP,ADJ,NOUN,ADP,NOUN,ADP,NOUN,ADP,AD...   \n","1  ADP,NOUN,ADP,ADJ,NOUN,ADP,NOUN,ADP,NOUN,ADP,AD...   \n","\n","                                                 tag  \\\n","0  R,Ncmpd,R,Afsd,Ncfsi,R,Ncnsi,R,Ncfsi,R,Amsh,Nc...   \n","1  R,Ncmpd,R,Afsd,Ncfsi,R,Ncnsi,R,Ncfsi,R,Amsh,Nc...   \n","\n","                                                 dep  \\\n","0  case,nmod,case,amod,nmod,case,nmod,case,nmod,c...   \n","1  case,nmod,case,amod,nmod,case,nmod,case,nmod,c...   \n","\n","                            morph  \\\n","0  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,   \n","1  ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,   \n","\n","                                              lemmas  num_words  \n","0  —Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,...         31  \n","1  —Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,...         31  "],"text/html":["\n","  <div id=\"df-0b787dc9-9503-4820-9221-991bb2d663fb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>pos</th>\n","      <th>tag</th>\n","      <th>dep</th>\n","      <th>morph</th>\n","      <th>lemmas</th>\n","      <th>num_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>–°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏—è –ø–æ –≤—Å—Ç—ä–ø...</td>\n","      <td>ADP,NOUN,ADP,ADJ,NOUN,ADP,NOUN,ADP,NOUN,ADP,AD...</td>\n","      <td>R,Ncmpd,R,Afsd,Ncfsi,R,Ncnsi,R,Ncfsi,R,Amsh,Nc...</td>\n","      <td>case,nmod,case,amod,nmod,case,nmod,case,nmod,c...</td>\n","      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n","      <td>—Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,...</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>–°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ—Ä–µ–º–æ–Ω–∏—è –ø–æ –≤—Å—Ç—ä–ø...</td>\n","      <td>ADP,NOUN,ADP,ADJ,NOUN,ADP,NOUN,ADP,NOUN,ADP,AD...</td>\n","      <td>R,Ncmpd,R,Afsd,Ncfsi,R,Ncnsi,R,Ncfsi,R,Amsh,Nc...</td>\n","      <td>case,nmod,case,amod,nmod,case,nmod,case,nmod,c...</td>\n","      <td>,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,</td>\n","      <td>—Å—Ä–µ–¥,–≥–æ—Å—Ç,–Ω–∞,–æ—Ñ–∏—Ü–∏–∞–ª–µ–Ω,—Ü–µ—Ä–µ–º–æ–Ω–∏—è,–ø–æ,–≤—Å—Ç—ä–ø–≤–∞–Ω–µ,...</td>\n","      <td>31</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b787dc9-9503-4820-9221-991bb2d663fb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0b787dc9-9503-4820-9221-991bb2d663fb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0b787dc9-9503-4820-9221-991bb2d663fb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e38a8c90-1e02-49a2-9e1a-3c6242fe5c41\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e38a8c90-1e02-49a2-9e1a-3c6242fe5c41')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e38a8c90-1e02-49a2-9e1a-3c6242fe5c41 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0421\\u0440\\u0435\\u0434 \\u0433\\u043e\\u0441\\u0442\\u0438\\u0442\\u0435 \\u043d\\u0430 \\u043e\\u0444\\u0438\\u0446\\u0438\\u0430\\u043b\\u043d\\u0430\\u0442\\u0430 \\u0446\\u0435\\u0440\\u0435\\u043c\\u043e\\u043d\\u0438\\u044f \\u043f\\u043e \\u0432\\u0441\\u0442\\u044a\\u043f\\u0432\\u0430\\u043d\\u0435 \\u0432 \\u0434\\u043b\\u044a\\u0436\\u043d\\u043e\\u0441\\u0442 \\u043d\\u0430 \\u043d\\u043e\\u0432\\u043e\\u0438\\u0437\\u0431\\u0440\\u0430\\u043d\\u0438\\u044f \\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442 \\u0449\\u0435 \\u0431\\u044a\\u0434\\u0430\\u0442 \\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438\\u044f\\u0442 \\u0434\\u044a\\u0440\\u0436\\u0430\\u0432\\u0435\\u043d \\u0433\\u043b\\u0430\\u0432\\u0430 \\u0420\\u0443\\u043c\\u0435\\u043d \\u0420\\u0430\\u0434\\u0435\\u0432, \\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442\\u044a\\u0442 \\u043d\\u0430 \\u0410\\u043b\\u0431\\u0430\\u043d\\u0438\\u044f \\u0418\\u043b\\u0438\\u0440 \\u041c\\u0435\\u0442\\u0430 \\u0438 \\u043d\\u0430 \\u041a\\u043e\\u0441\\u043e\\u0432\\u043e \\u0425\\u0430\\u0448\\u0438\\u043c \\u0422\\u0430\\u0447\\u0438.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ADP,NOUN,ADP,ADJ,NOUN,ADP,NOUN,ADP,NOUN,ADP,ADJ,NOUN,AUX,AUX,ADJ,ADJ,NOUN,PROPN,PROPN,PUNCT,NOUN,ADP,PROPN,PROPN,PROPN,CCONJ,ADP,PROPN,PROPN,PART,PUNCT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"R,Ncmpd,R,Afsd,Ncfsi,R,Ncnsi,R,Ncfsi,R,Amsh,Ncmsi,Tx,Vyptf-r3p,Amsf,Amsi,Ncmsi,Npmsi,Hmsi,punct,Ncmsf,R,Npfsi,Hfsi,Npfsi,Cp,R,Npnsi,Npmsi,Tv,punct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dep\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"case,nmod,case,amod,nmod,case,nmod,case,nmod,case,amod,nmod,aux,cop,amod,amod,root,nmod,flat,punct,nsubj,case,nmod,nmod,flat,cc,case,conj,flat,discourse,punct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"morph\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmas\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\\u0441\\u0440\\u0435\\u0434,\\u0433\\u043e\\u0441\\u0442,\\u043d\\u0430,\\u043e\\u0444\\u0438\\u0446\\u0438\\u0430\\u043b\\u0435\\u043d,\\u0446\\u0435\\u0440\\u0435\\u043c\\u043e\\u043d\\u0438\\u044f,\\u043f\\u043e,\\u0432\\u0441\\u0442\\u044a\\u043f\\u0432\\u0430\\u043d\\u0435,\\u0432,\\u0434\\u043b\\u044a\\u0436\\u043d\\u043e\\u0441\\u0442,\\u043d\\u0430,\\u043d\\u043e\\u0432\\u043e\\u0438\\u0437\\u0431\\u0440\\u0430\\u043c,\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442,\\u0449\\u0435,\\u0431\\u044a\\u0434\\u0430,\\u0431\\u044a\\u043b\\u0433\\u0430\\u0440\\u0441\\u043a\\u0438,\\u0434\\u044a\\u0440\\u0436\\u0430\\u0432\\u0435\\u043d,\\u0433\\u043b\\u0430\\u0432\\u0430,\\u0440\\u0443\\u043c\\u0435\\u043d,\\u0440\\u0430\\u0434\\u0435\\u0432,,,\\u043f\\u0440\\u0435\\u0437\\u0438\\u0434\\u0435\\u043d\\u0442,\\u043d\\u0430,\\u0430\\u043b\\u0431\\u0430\\u043d\\u0438\\u044f,\\u0418\\u043b\\u0438\\u0440,\\u041c\\u0435\\u0442\\u0430,\\u0438,\\u043d\\u0430,\\u043a\\u043e\\u0441\\u043e\\u0432\\u043e,\\u0425\\u0430\\u0448\\u0438\\u043c,\\u0422\\u0430\\u0447\\u0430,.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 31,\n        \"max\": 31,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["res = []\n","res.append(inspect_word(row_to_dict(test_df, 1), 0))\n","res.append(inspect_word(row_to_dict(test_df, 1), 1))\n","res.append(inspect_word(row_to_dict(test_df, 2), 2))\n","res.append(inspect_word(row_to_dict(test_df, 2), 3))\n","res.append(inspect_word(row_to_dict(test_df, 2), 4))\n","print(\"\\n\".join(res))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcqIDxsb34Wo","executionInfo":{"status":"ok","timestamp":1737273684566,"user_tz":-120,"elapsed":246,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"8f5f5993-3ab6-4a79-ebcd-de60bafe66f0"},"id":"fcqIDxsb34Wo","execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["1 –°—Ä–µ–¥            POS:ADP        Gen:     Num:   DEP:case       Sent: –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ\n","1 –≥–æ—Å—Ç–∏—Ç–µ         POS:NOUN       Gen:M    Num:P   DEP:nmod       Sent: –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ\n","2 –Ω–∞              POS:ADP        Gen:     Num:   DEP:case       Sent: –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ\n","2 –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞     POS:ADJ        Gen:F    Num:S   DEP:amod       Sent: –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ\n","2 —Ü–µ—Ä–µ–º–æ–Ω–∏—è       POS:NOUN       Gen:F    Num:S   DEP:nmod       Sent: –°—Ä–µ–¥ –≥–æ—Å—Ç–∏—Ç–µ –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª–Ω–∞—Ç–∞ —Ü–µ\n"]}]},{"cell_type":"code","source":["DO TUK"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"ayUKm7xd045b","executionInfo":{"status":"error","timestamp":1737273623435,"user_tz":-120,"elapsed":31,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}},"outputId":"bac52d65-c00f-4eff-b76e-6dbfef6f077b"},"id":"ayUKm7xd045b","execution_count":62,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-62-7d37760df8dc>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-7d37760df8dc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    DO TUK\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","id":"9b37a288-3cf9-4a46-b2b8-f32eadb66e08","metadata":{"id":"9b37a288-3cf9-4a46-b2b8-f32eadb66e08"},"source":["The output indicates that Stanza took much longer to execute compared to UDPipe for the same task of extracting NLP features from 10 sentences."]},{"cell_type":"markdown","id":"faccc383-ae15-4974-ac25-65ca58018232","metadata":{"id":"faccc383-ae15-4974-ac25-65ca58018232"},"source":["#### 3.5.3 Final verdict"]},{"cell_type":"markdown","id":"46863683-9bcf-4f60-bdb0-5186b744592e","metadata":{"id":"46863683-9bcf-4f60-bdb0-5186b744592e"},"source":["Stanza in much better at splitting into sentences and supports more features, whereas UDPipe has significantly better performance. So the next steps will be performed mainly with Stanza in order to get more accurate results but let's be open to the possibility of using UDPipe in certain situations."]},{"cell_type":"markdown","id":"11b9f655-d5ac-44f6-869a-559ce8bef07c","metadata":{"id":"11b9f655-d5ac-44f6-869a-559ce8bef07c"},"source":["## 4 Proof of concept"]},{"cell_type":"markdown","id":"2a2ea0a8-81f4-41a8-a8bd-0cfbc0b18594","metadata":{"id":"2a2ea0a8-81f4-41a8-a8bd-0cfbc0b18594"},"source":["Let's create a minimal program as a proof of concept. The goal is to illustrate the idea behind text processing and determining the correctness of the definite article."]},{"cell_type":"markdown","id":"5048c5b4-4d8a-49a5-97f4-b57324db39b1","metadata":{"id":"5048c5b4-4d8a-49a5-97f4-b57324db39b1"},"source":["### 4.1 Define one rule"]},{"cell_type":"markdown","id":"2c6dc2e2-de7b-4fcd-8561-9ca0728e0bc9","metadata":{"id":"2c6dc2e2-de7b-4fcd-8561-9ca0728e0bc9"},"source":["Define one simple rule and put it in a testing function. The rule is: if the word is a noun, is preceded by a preposition, and ends in _—ä—Ç_ or _—è—Ç_, then the long form of the definite article is incorrect. Note that in reality this rule is not enough to determine the correct usage of the definite article but for the purposes of the POC it will suffice."]},{"cell_type":"code","execution_count":null,"id":"f305d53d-1558-4b91-a9bc-a17648f10692","metadata":{"id":"f305d53d-1558-4b91-a9bc-a17648f10692","executionInfo":{"status":"aborted","timestamp":1737273623435,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def verify_definite_article(doc):\n","    \"\"\"Detects incorrect usage of the definite article based on POS tags and word endings\"\"\"\n","    errors = []\n","\n","    for i, token in enumerate(doc):\n","        # Check if the token is a noun with a definite article (full form)\n","        if token.pos_ == \"NOUN\" and token.text.endswith((\"—ä—Ç\", \"—è—Ç\")):\n","            # Check if the preceding token is a preposition (ADP), like \"–≤\"\n","            if i > 0 and doc[i - 1].pos_ == \"ADP\":\n","                errors.append(f\"Incorrect usage of full definite article: '{token.text}' in sentence: '{doc.text}'\")\n","    return errors"]},{"cell_type":"markdown","id":"6c5876a5-24fd-458e-9863-dc29e362648b","metadata":{"id":"6c5876a5-24fd-458e-9863-dc29e362648b"},"source":["### 4.2 Test and validate"]},{"cell_type":"code","execution_count":null,"id":"72660762-a0a3-4959-8584-106f8da8aca8","metadata":{"id":"72660762-a0a3-4959-8584-106f8da8aca8","executionInfo":{"status":"aborted","timestamp":1737273623435,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["valid_sentences = [\"–ê–∑ –æ—Ç–∏–≤–∞–º –≤ –æ—Ñ–∏—Å–∞.\", \"–ò–≤–∞–Ω –æ—Ç–∏–≤–∞ –≤ –æ—Ñ–∏—Å–∞.\", \"–û—Ñ–∏—Å—ä—Ç –µ –≤ –°–æ—Ñ–∏—è.\"]\n","invalid_sentences = [\"–ê–∑ –æ—Ç–∏–≤–∞–º –≤ –æ—Ñ–∏—Å—ä—Ç.\", \"–ò–≤–∞–Ω –æ—Ç–∏–≤–∞ –≤ –æ—Ñ–∏—Å—ä—Ç.\", \"–û—Ñ–∏—Å–∞ –µ –≤ –°–æ—Ñ–∏—è.\"]"]},{"cell_type":"code","execution_count":null,"id":"0055be9d-9da9-4d72-83cf-d64e2a673171","metadata":{"id":"0055be9d-9da9-4d72-83cf-d64e2a673171","executionInfo":{"status":"aborted","timestamp":1737273623435,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# Process each sentence with both libraries\n","results_st = []\n","results_ud = []\n","for sentence in valid_sentences + invalid_sentences:\n","    doc_st = nlp_st(sentence)\n","    doc_ud = nlp_ud(sentence)\n","\n","    results_st.append(verify_definite_article(doc_st))\n","    results_ud.append(verify_definite_article(doc_ud))"]},{"cell_type":"code","execution_count":null,"id":"673d0434-1d1b-45fe-ada4-354655d515d7","metadata":{"id":"673d0434-1d1b-45fe-ada4-354655d515d7","executionInfo":{"status":"aborted","timestamp":1737273623435,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["print(\"Results from Stanza:\")\n","for i, res in enumerate(results_st):\n","    print(f\"{i+1}:\", res)\n","\n","print(\"\\nResults from UDPipe:\")\n","for i, res in enumerate(results_ud):\n","    print(f\"{i+1}:\", res)"]},{"cell_type":"markdown","id":"a3b9fc97-3036-481f-b6d0-e4665d06d35d","metadata":{"id":"a3b9fc97-3036-481f-b6d0-e4665d06d35d"},"source":["Of course we can't expect much correctness of this simple rule but we can see that it did find some incorrect usages in two out of the six cases. Not bad, actually!"]},{"cell_type":"markdown","id":"cedf4369-b8bf-4a7c-b5bd-fc91d293836f","metadata":{"id":"cedf4369-b8bf-4a7c-b5bd-fc91d293836f"},"source":["## 5 Load and clean the testing data"]},{"cell_type":"markdown","id":"89d453a7-4c3f-48ca-878a-176923b8f758","metadata":{"id":"89d453a7-4c3f-48ca-878a-176923b8f758"},"source":["This short set of sentences contains some common misuses of the definite article and also the correct usage. We will use this set for initial testing of the rules we develop."]},{"cell_type":"code","execution_count":null,"id":"d88601c9-be0a-4ba3-907c-5209c22682a9","metadata":{"id":"d88601c9-be0a-4ba3-907c-5209c22682a9","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1 = pd.read_csv(\"https://raw.githubusercontent.com/MirkaIvanova/datasets/refs/heads/main/data_science_project/test_set_1.csv\")"]},{"cell_type":"code","execution_count":null,"id":"f9179b26-66ba-4f32-a551-d5dad82a5075","metadata":{"id":"f9179b26-66ba-4f32-a551-d5dad82a5075","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1.head()"]},{"cell_type":"markdown","id":"075343a4-74e5-408c-8bd0-2b73d6ddf900","metadata":{"id":"075343a4-74e5-408c-8bd0-2b73d6ddf900"},"source":["### 5.1 Trim the sentences of whitespaces"]},{"cell_type":"code","execution_count":null,"id":"8bd8d67c-b9a0-4e88-9eec-1d1739fc1e98","metadata":{"id":"8bd8d67c-b9a0-4e88-9eec-1d1739fc1e98","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1[['incorrect', 'correct']] = test_set_1[['incorrect', 'correct']].map(str.strip)"]},{"cell_type":"markdown","id":"6396147b-97bf-49e4-98b2-b43883de89cf","metadata":{"id":"6396147b-97bf-49e4-98b2-b43883de89cf"},"source":["### 5.2 Add column with the differing words"]},{"cell_type":"markdown","id":"65992d0c-4925-4ef4-adbc-7280f875a0e0","metadata":{"id":"65992d0c-4925-4ef4-adbc-7280f875a0e0"},"source":["In order to perform automated tests we will need to know were exactly is the error in the sentence, if there is an error. Therefore, we'll add a new column with the expected incorrect words. Before that we need to do some cleaning like removal of punctuation. Note that this function is designed to work with Bulgarian in order to keep words üü†"]},{"cell_type":"code","execution_count":null,"id":"b2bd8914-cd81-4f10-a4fe-f466ae6499b9","metadata":{"id":"b2bd8914-cd81-4f10-a4fe-f466ae6499b9","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def clean_sentence_bg(sentence):\n","    \"\"\"Cleans a Bulgarian sentence by removing unwanted punctuation but preserving valid dashes.\"\"\"\n","    # Remove dashes not surrounded by exactly two bg letters\n","    # keep also numbers in order to preserve words like 5-–≥–æ–¥–∏—à–µ–Ω\n","    sentence = re.sub(r\"(?<![0-9–∞-—è–ê-–Ø])-|-(?![–∞-—è–ê-–Ø])\", \"\", sentence)\n","\n","    # Remove all other punctuation except for valid dashes\n","    sentence = re.sub(r\"[^\\w\\s-]\", \"\", sentence)\n","\n","    return sentence"]},{"cell_type":"code","execution_count":null,"id":"434546f4-61b6-4c09-a523-f7b0270565ee","metadata":{"id":"434546f4-61b6-4c09-a523-f7b0270565ee","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def get_differing_words(row):\n","    \"\"\"Extracts differing words between two sentences and logs word count discrepancies.\"\"\"\n","    # Clean and split the sentences into words\n","    incorrect_words = clean_sentence_bg(row[\"incorrect\"]).split()\n","    correct_words = clean_sentence_bg(row[\"correct\"]).split()\n","\n","    # Log if word count differs\n","    if len(incorrect_words) != len(correct_words):\n","        print(f\"Word count differs: Incorrect - {len(incorrect_words)} words, Correct - {len(correct_words)} words\")\n","\n","    # Get words from the correct sentence that are not in the incorrect sentence\n","    differing_correct_words = [word for word in correct_words if word not in incorrect_words]\n","    differing_incorrect_words = [word for word in incorrect_words if word not in correct_words]\n","\n","    return \",\".join(differing_incorrect_words), \",\".join(differing_correct_words)"]},{"cell_type":"code","execution_count":null,"id":"8ad39063-05c2-42fd-b3fd-62b3405eb4b3","metadata":{"id":"8ad39063-05c2-42fd-b3fd-62b3405eb4b3","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# add a new column to hold the correct and incorrect words, they will be used for automated testing\n","test_set_1[[\"correct_words\", \"incorrect_words\"]] = test_set_1.apply(get_differing_words, axis=1, result_type=\"expand\")"]},{"cell_type":"code","execution_count":null,"id":"af0ffb9f-f844-4ed6-b28a-915929a5db25","metadata":{"id":"af0ffb9f-f844-4ed6-b28a-915929a5db25","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1.head(3)"]},{"cell_type":"markdown","id":"56036cc3-4e21-4fe5-a7bf-cc589f065371","metadata":{"id":"56036cc3-4e21-4fe5-a7bf-cc589f065371"},"source":["### 5.3 Melt and sort"]},{"cell_type":"markdown","id":"92405dd7-be0b-4232-a6bd-30626f4866ad","metadata":{"id":"92405dd7-be0b-4232-a6bd-30626f4866ad"},"source":["Merge the columns _incorrect_ and _correct_ to a single column _text_. Keep each pair of incorrect and correct sentences together."]},{"cell_type":"code","execution_count":null,"id":"4c902ec4-4227-448c-a958-2350601f074f","metadata":{"id":"4c902ec4-4227-448c-a958-2350601f074f","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def melt_and_sort_sentences(df):\n","    \"\"\"Transforms a DataFrame to melt sentence pairs, ensuring incorrect and correct sentences are paired.\"\"\"\n","\n","    # Swap 'incorrect_words' and 'correct_words' columns\n","    df = df.rename(columns={\"incorrect_words\": \"temp_correct_words\", \"correct_words\": \"incorrect_words\"})\n","    df = df.rename(columns={\"temp_correct_words\": \"correct_words\"})\n","\n","    # Add an order column to keep track of the original order\n","    df[\"order\"] = df.index\n","\n","    # Melt the DataFrame\n","    df_melted = pd.melt(\n","        df,\n","        id_vars=[\"correct_words\", \"incorrect_words\", \"order\"],\n","        value_vars=[\"incorrect\", \"correct\"],\n","        var_name=\"is_correct\",\n","        value_name=\"text\",\n","    )\n","\n","    # Set 'is_correct' to True for 'correct' and False for 'incorrect'\n","    df_melted[\"is_correct\"] = df_melted[\"is_correct\"].apply(lambda x: x == \"correct\")\n","\n","    # Assign incorrect_words and correct_words only to incorrect sentences\n","    df_melted[\"incorrect_words\"] = df_melted.apply(lambda row: row[\"incorrect_words\"] if not row[\"is_correct\"] else \"\", axis=1)\n","    df_melted[\"correct_words\"] = df_melted.apply(lambda row: row[\"correct_words\"] if not row[\"is_correct\"] else \"\", axis=1)\n","\n","    # Sort by 'order' to ensure the pairs of correct/incorrect sentences are next to each other\n","    df_melted = df_melted.sort_values(by=[\"order\", \"is_correct\"], ascending=[True, True])\n","\n","    # Reset index for clean output\n","    df_melted.reset_index(drop=True, inplace=True)\n","\n","    # Drop the 'order' column as it's no longer needed\n","    df_melted = df_melted.drop(columns=[\"order\"])\n","\n","    # Reorder columns to match the desired output\n","    df_melted = df_melted[[\"text\", \"is_correct\", \"incorrect_words\", \"correct_words\"]]\n","\n","    return df_melted"]},{"cell_type":"code","execution_count":null,"id":"5b368a83-0501-4d8b-afd2-836bb023b8f9","metadata":{"id":"5b368a83-0501-4d8b-afd2-836bb023b8f9","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1 = melt_and_sort_sentences(test_set_1)"]},{"cell_type":"code","execution_count":null,"id":"0a12427b-7fd4-4cb8-b397-1a1cd8e5d80f","metadata":{"id":"0a12427b-7fd4-4cb8-b397-1a1cd8e5d80f","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1.head(6)"]},{"cell_type":"markdown","id":"39a7c4f0-8b35-48f9-8030-d114fce7aba9","metadata":{"id":"39a7c4f0-8b35-48f9-8030-d114fce7aba9"},"source":["### 5.4 Add columns with Stanza NLP features"]},{"cell_type":"code","execution_count":null,"id":"a64d8fb5-8c07-4646-905f-d7039b4f74ec","metadata":{"id":"a64d8fb5-8c07-4646-905f-d7039b4f74ec","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["if True:\n","    # extract stanza features as new columns\n","    feature_columns_st = [\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_tokens\"]\n","    test_set_1[feature_columns_st] = test_set_1.apply(lambda r: extract_features(nlp_st, r, \"text\"), axis=1, result_type=\"expand\")\n","\n","    # save in case we want to load it faster\n","    if not os.path.exists(\"data\"):\n","        os.makedirs(\"data\")\n","    test_set_1.to_csv(\"data/test_set_1_clean.csv\", index=None)\n","else:\n","    # load from file instead of the above, it is faster\n","    test_set_1 = pd.read_csv(\"data/test_set_1_clean.csv\")\n","    test_set_1[\"correct_words\"] = test_set_1[\"incorrect_words\"].fillna(\"\")\n","    test_set_1[\"incorrect_words\"] = test_set_1[\"incorrect_words\"].fillna(\"\")"]},{"cell_type":"code","execution_count":null,"id":"0fe578ad-5570-4ece-a36a-98a732bef5f6","metadata":{"id":"0fe578ad-5570-4ece-a36a-98a732bef5f6","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1.columns"]},{"cell_type":"code","execution_count":null,"id":"b98ea749-b1cb-49d2-b471-9905459b28e7","metadata":{"id":"b98ea749-b1cb-49d2-b471-9905459b28e7","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["test_set_1[[\"text\", \"num_tokens\", \"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\"]].head(1).T"]},{"cell_type":"markdown","id":"07173321-5f86-4bae-9c5a-4aeaf2abaf32","metadata":{"id":"07173321-5f86-4bae-9c5a-4aeaf2abaf32"},"source":["## 6 Define rule based logic"]},{"cell_type":"markdown","id":"07626842-f1cf-45f1-b22f-241892a589f4","metadata":{"id":"07626842-f1cf-45f1-b22f-241892a589f4"},"source":["### 6.1 Implement NLP specific functions"]},{"cell_type":"markdown","id":"2e6836b6-0950-40d6-950a-e7803216513e","metadata":{"id":"2e6836b6-0950-40d6-950a-e7803216513e"},"source":["This section contains functions that extract grammatical details like gender, number, and sentence role from tagged words."]},{"cell_type":"code","execution_count":null,"id":"fea25698-beaa-458b-851b-e42b18a31233","metadata":{"id":"fea25698-beaa-458b-851b-e42b18a31233","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"cce723a8-bf82-4636-ad00-2e438f94c2f7","metadata":{"id":"cce723a8-bf82-4636-ad00-2e438f94c2f7","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"9ee5763a-dac2-4631-9746-6aad52c7be4f","metadata":{"id":"9ee5763a-dac2-4631-9746-6aad52c7be4f"},"source":["### 6.2 Implement generic testing function"]},{"cell_type":"markdown","id":"190505ef-c71c-43a5-85f1-52b072466723","metadata":{"id":"190505ef-c71c-43a5-85f1-52b072466723"},"source":["Before we start implementing any rules, we should first create a testing function for them. Since we don‚Äôt have the specific rule functions ready, we‚Äôll set up a general testing function - actually, we‚Äôll create three functions - that can take in a list of conditions and a list of rules. It‚Äôs important that both lists have the same length. The testing function will process text, apply these conditions and rules to detect errors, and then compare the results with expected outcomes, logging whether each test passes or fails."]},{"cell_type":"code","execution_count":null,"id":"1df9be14-e52e-4fff-8a71-d870153af4d6","metadata":{"id":"1df9be14-e52e-4fff-8a71-d870153af4d6","executionInfo":{"status":"aborted","timestamp":1737273623436,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def all_rules(row_dict, condition_fns, rule_fns):\n","    # ‚ö†Ô∏èMake sure the sentence always ends with a punctuation. This is a workaround!\n","    # UDPipe not always separates into tokens correctly, sometimes reports the word+punctuation (or special symbol) as single token.\n","    # Stanza has bad performance and this function is called iteratively multiple times, not a good idea to use Stanza here.\n","    sentence = row_dict[\"text\"] + \".\"\n","    doc = nlp_ud(sentence)\n","    errors = []\n","\n","    # ‚ö†Ô∏èThis is a very ugly workaround. UDPipe does not correctly split into tokens when there is punctuation\n","    # in the middle of the sentence. We return \"no errors\" here which might make some tests fail but\n","    # the goal is not to raise an exception. The correct solution is not to use UDPipe at all and pre-calculate the tokens\n","    # in the beginning.\n","    if (len(doc) != row_dict['num_tokens']):\n","        return errors\n","\n","    # Iterate over token pairs with indices\n","    # for i in range(len(doc) - 1):\n","    for i in range(row_dict['num_tokens'] - 1):\n","        token1 = doc[i].text\n","        token2 = doc[i + 1].text\n","\n","        conditions = [condition_fn(row_dict, i) for condition_fn in condition_fns]\n","\n","        for condition, rule_fn in zip(conditions, rule_fns):\n","            if condition:\n","                errors += rule_fn(token1, token2, i)\n","\n","    return errors"]},{"cell_type":"code","execution_count":null,"id":"1eb26302-028c-4502-9d2c-12af484dd2fd","metadata":{"id":"1eb26302-028c-4502-9d2c-12af484dd2fd","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def test_definite_article(row_dict, condition_fns, rule_fns):\n","    actual_wrong_words = []\n","    expected_wrong_words = [word.strip() for word in row_dict[\"incorrect_words\"].split(\",\") if word.strip() != \"\"]\n","    actual_wrong_words = all_rules(row_dict, condition_fns, rule_fns)\n","\n","    test_res = \"Pass\" if set(actual_wrong_words) == set(expected_wrong_words) else \"Fail\"\n","\n","    return (test_res, actual_wrong_words)"]},{"cell_type":"code","execution_count":null,"id":"565efc7c-f779-422c-b95a-783792c1543c","metadata":{"id":"565efc7c-f779-422c-b95a-783792c1543c","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# tests all sentences from a dataset that already contains NLP tags\n","def test_definite_article_all(nlp_df, conditions_fns, rules_fns, print_passed=True, print_failed=True, print_total=True):\n","    \"\"\"Tests definite articles in sentences and logs results.\"\"\"\n","    idx_failed, idx_passed = [], []\n","\n","    for i, row in nlp_df.iterrows():\n","        row_dict = row.to_dict()\n","        res = test_definite_article(row_dict, conditions_fns, rules_fns)\n","        status, incorrect = res[0], res[1]\n","\n","        if status == \"Fail\":\n","            idx_failed.append(i)\n","            if print_failed:\n","                print(i, f'‚ùå {row_dict[\"text\"]} (Actual: \\'{\",\".join(incorrect)}\\', Expected: \\'{row_dict[\"incorrect_words\"]}\\')')\n","        else:\n","            idx_passed.append(i)\n","            message = f'‚úÖ {row_dict[\"text\"]} (\\'{\",\".join(incorrect)}\\' is incorrect)' if incorrect else f'‚úÖ {row_dict[\"text\"]} (The sentence is correct)'\n","            if print_passed:\n","                print(i, message)\n","\n","    if print_total:\n","        n_failed = len(idx_failed)\n","        print(\"‚úÖ All tests passed\" if n_failed == 0 else f\"‚ùå {n_failed}/{len(nlp_df)} failed.\")\n","\n","    return idx_passed, idx_failed"]},{"cell_type":"markdown","id":"fb1f6117-22a9-4bd3-aa89-c7761f469411","metadata":{"id":"fb1f6117-22a9-4bd3-aa89-c7761f469411"},"source":["### 6.3 Iteration 1"]},{"cell_type":"markdown","id":"08acbd7a-cb63-4649-99c7-3adcf7f83996","metadata":{"id":"08acbd7a-cb63-4649-99c7-3adcf7f83996"},"source":["#### 6.3.1 Implement Rule1"]},{"cell_type":"markdown","id":"d9a2b905-b382-43b5-b04a-6722070858d3","metadata":{"id":"d9a2b905-b382-43b5-b04a-6722070858d3"},"source":["According to Rule1, long definite article should be used when the noun takes the role of the subject. Additionally, in order to exclude groups of adjective + noun, which fall under Rule3, we need to exclude noun that follow an adjective."]},{"cell_type":"code","execution_count":null,"id":"5925e27c-ed32-43ae-975f-f21d414b7bd0","metadata":{"id":"5925e27c-ed32-43ae-975f-f21d414b7bd0","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def cond_rule1(row_dict, i):\n","    \"\"\"Searches for a NOUN, masculine, singular, which is the SUBJECT (nominal or clausal) in the sentence,\n","       and is not preceded by an ADJective\"\"\"\n","    is_token1_adj = nlp_get_pos(row_dict, i) == \"ADJ\"\n","    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n","    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n","    is_token1_subj = is_dep_subject(row_dict, i)\n","\n","    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n","    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n","    is_token2_subj = is_dep_subject(row_dict, i + 1)\n","\n","    # if token is masculine singular noun and subj, and the previous token is not an adjective\n","    if i == 0 and is_token1_masc_sg and is_token1_noun and is_token1_subj:\n","        return True\n","    if i != 0 and not is_token1_adj and is_token2_masc_sg and is_token2_noun and is_token2_subj:\n","        return True\n","\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"75f5166d-e14e-4eb0-bcc2-aa6d9d6d9390","metadata":{"id":"75f5166d-e14e-4eb0-bcc2-aa6d9d6d9390","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule1(token1, token2, token_idx):\n","    errors = []\n","    word = token1 if token_idx == 0 else token2\n","    if not word.endswith((\"—ä—Ç\", \"—è—Ç\")):\n","        errors.append(word)\n","    return errors"]},{"cell_type":"markdown","id":"c52bde6f-2651-4911-a195-6271e0dcf858","metadata":{"id":"c52bde6f-2651-4911-a195-6271e0dcf858"},"source":["#### 6.3.2 Test Rule1"]},{"cell_type":"code","execution_count":null,"id":"9be184b3-6d53-4a38-8736-94dc962c4977","metadata":{"id":"9be184b3-6d53-4a38-8736-94dc962c4977","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["idx_passed, idx_current = test_definite_article_all(test_set_1, [cond_rule1], [rule1])"]},{"cell_type":"markdown","id":"1ea29537-08d2-4a94-8365-39ff48a85908","metadata":{"id":"1ea29537-08d2-4a94-8365-39ff48a85908"},"source":["##### Analyze some of the failures"]},{"cell_type":"markdown","id":"0e521677-cf9a-4e31-aa4f-2ce1aacfe2a3","metadata":{"id":"0e521677-cf9a-4e31-aa4f-2ce1aacfe2a3"},"source":["Now let's ta–∫e the first several failed tests and figure out why they failed."]},{"cell_type":"code","execution_count":null,"id":"b52274d4-612a-4749-9968-5066043a7035","metadata":{"id":"b52274d4-612a-4749-9968-5066043a7035","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def row_to_dict(df, index):\n","    row_dict = df.loc[index].to_dict()\n","    row_dict[\"index\"] = index\n","    return row_dict"]},{"cell_type":"code","execution_count":null,"id":"7dfb8087-71e7-42b3-808b-2fecfcda448e","metadata":{"id":"7dfb8087-71e7-42b3-808b-2fecfcda448e","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":29,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["res = []\n","res.append(inspect_word(row_to_dict(test_set_1, 10), 0))  # üëâ–ì–æ—Ç–≤–∞—á–∞ –ø—Ä–∏–≥–æ—Ç–≤–∏ –æ–±—è–¥–∞.\n","res.append(inspect_word(row_to_dict(test_set_1, 16), 2))  # –¢–∞–Ω—è —Ç—ä—Ä—Å–∏ üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 18), 2))  # –ì–æ–≤–æ—Ä–∏–º –∑–∞ üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 20), 5))  # –¢–∞–Ω—è —Ç—ä—Ä—Å–∏ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 22), 5))  # –ì–æ–≤–æ—Ä–∏–º –∑–∞ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 24), 3))  # –¢–æ–π –º–∏ –¥–∞–¥–µ üëâ–∫–ª—é—á—ä—Ç –æ—Ç –∫—ä—â–∞—Ç–∞.\n","print(\"\\n\".join(res))"]},{"cell_type":"markdown","id":"2d331a6c-a36a-4a1b-8f6b-201325d73360","metadata":{"id":"2d331a6c-a36a-4a1b-8f6b-201325d73360"},"source":["The problem with _**–≥–æ—Ç–≤–∞—á–∞**_ is that it is considered to be feminine by Stanza. For now we **will postpone fixing** because without context it is impossible to determine the gender, and without gender we can't apply Rule1.\n","\n","The word _**–ª–µ–∫–∞—Ä—è—Ç**_ in _–¢–∞–Ω—è —Ç—ä—Ä—Å–∏ –ª–µ–∫–∞—Ä—è—Ç_ is determined as an nsubj (nominal subject) by Stanza but the correct dependency is object. Well, grammatically it would be correct if we assume that the doctor is the doer in the sentence. However, that is the less popular word order. Let's **postpone fixing** this sentence for later.\n","\n","The word _**–õ–µ–∫–∞—Ä—è—Ç**_ in the sentences \\\n","_–ì–æ–≤–æ—Ä–∏–º –∑–∞ –ª–µ–∫–∞—Ä—è—Ç_, \\\n","_–¢–∞–Ω—è —Ç—ä—Ä—Å–∏ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, –ª–µ–∫–∞—Ä—è—Ç_ \\\n","and _–ì–æ–≤–æ—Ä–∏–º –∑–∞ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, –ª–µ–∫–∞—Ä—è—Ç._ \\\n","is determined to be iobj (indirect object), nmod (nominal modifier) and conj (conjust) so that falls under Rule2.\n","\n","_**–∫–ª—é—á—ä—Ç**_ is marked as object so it also falls under Rule2.\n","\n","So the last 4 failures are expected to be fixed after we implement Rule2."]},{"cell_type":"markdown","id":"19233606-0f59-4fd8-adb8-18db158c4968","metadata":{"id":"19233606-0f59-4fd8-adb8-18db158c4968"},"source":["Separate the failed and analyzed tests into one list and the passed tests into another list. The one with the passed tests will be used for regression testing."]},{"cell_type":"code","execution_count":null,"id":"ce0dc7e2-a07e-4194-ac50-595c2e575728","metadata":{"id":"ce0dc7e2-a07e-4194-ac50-595c2e575728","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["idx_passed = sorted(list(set(idx_passed) - set([10, 16])))\n","idx_current = sorted(list(set(idx_current) - set([10, 16])))"]},{"cell_type":"markdown","id":"a7445dda-5de1-41a3-adbd-534bab042fd5","metadata":{"id":"a7445dda-5de1-41a3-adbd-534bab042fd5"},"source":["### 6.4 Iteration 2"]},{"cell_type":"markdown","id":"c2a5962f-e021-48c6-b1af-7717a339e3a4","metadata":{"id":"c2a5962f-e021-48c6-b1af-7717a339e3a4"},"source":["#### 6.4.1 Implement Rule2"]},{"cell_type":"markdown","id":"83f865be-d745-48c7-9275-aec4017b1f19","metadata":{"id":"83f865be-d745-48c7-9275-aec4017b1f19"},"source":["Here we will implement the first part of Rule2, which states that when the noun takes the role of the object, then the short form of the definite article should be used."]},{"cell_type":"code","execution_count":null,"id":"2dbafb0f-41be-484f-a048-5b38d0e8d3ce","metadata":{"id":"2dbafb0f-41be-484f-a048-5b38d0e8d3ce","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def cond_rule2(row_dict, i):\n","    \"\"\"Searches for masculine singular nouns that are the object in the sentence\"\"\"\n","    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n","    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n","    is_token1_subj = is_dep_subject(row_dict, i)\n","\n","    if is_token1_noun and is_token1_masc_sg and not is_token1_subj:\n","        return True\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"e3c8102b-b7c2-461b-a3c6-0ef00d3ee77b","metadata":{"id":"e3c8102b-b7c2-461b-a3c6-0ef00d3ee77b","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule2(token1, token2, idx_token):\n","    errors = []\n","    if token1.endswith((\"—ä—Ç\", \"—è—Ç\")):  # objects should not have full article\n","        errors.append(token1)\n","    return errors"]},{"cell_type":"markdown","id":"f8709711-3a4e-4599-9316-03d4bb091077","metadata":{"id":"f8709711-3a4e-4599-9316-03d4bb091077"},"source":["#### 6.4.2 Test Rule2"]},{"cell_type":"code","execution_count":null,"id":"e44b8ee8-f284-45f7-bfb8-f134c315b934","metadata":{"id":"e44b8ee8-f284-45f7-bfb8-f134c315b934","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["p, c = test_definite_article_all(test_set_1.loc[idx_current], [cond_rule1, cond_rule2], [rule1, rule2])"]},{"cell_type":"markdown","id":"7e301348-0499-405a-8acf-dbc72a78b0af","metadata":{"id":"7e301348-0499-405a-8acf-dbc72a78b0af"},"source":["In the previous run rows 18, 20, 22 and 24 failed, now after implementing Rule2 they pass. Additionally, 4 more tests pass."]},{"cell_type":"markdown","id":"6e46b951-bea2-400f-81b6-afcd3449cebb","metadata":{"id":"6e46b951-bea2-400f-81b6-afcd3449cebb"},"source":["##### Analyze some of the failures"]},{"cell_type":"code","execution_count":null,"id":"b76fcdb7-3b63-4da9-8759-0fb865251052","metadata":{"id":"b76fcdb7-3b63-4da9-8759-0fb865251052","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["res = []\n","res.append(inspect_word(row_to_dict(test_set_1, 26), 0))  # üëâ–ü—Ä–∏–Ω—Ü–∞ –≥–æ–≤–æ—Ä–∏ —Å —Ü–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 34), 0))  # üëâ–î—ä–ª–≥–æ–æ—á–∞–∫–≤–∞–Ω–∏—è –≥–æ—Å—Ç –¥–æ–π–¥–µ.\n","res.append(inspect_word(row_to_dict(test_set_1, 34), 1))  # –î—ä–ª–≥–æ–æ—á–∞–∫–≤–∞–Ω–∏—è üëâ–≥–æ—Å—Ç –¥–æ–π–¥–µ.\n","res.append(inspect_word(row_to_dict(test_set_1, 36), 2))  # –ò–≤–∞–Ω, üëâ–≥–æ—Å—Ç–∞ –æ—Ç –°–æ–ø–æ—Ç, –¥–æ–π–¥–µ.\n","res.append(inspect_word(row_to_dict(test_set_1, 38), 2))  # –ò–≤–∞–Ω –µ üëâ—Å—ä—É—á–µ–Ω–∏–∫–∞ –º–∏.\n","res.append(inspect_word(row_to_dict(test_set_1, 40), 2))  # –ò–≤–∞–Ω –µ üëâ–¥–æ–±—Ä–∏—è.\n","res.append(inspect_word(row_to_dict(test_set_1, 42), 2))  # –ò–≤–∞–Ω –µ üëâ—É—Å–ø–µ–ª–∏—è.\n","print(\"\\n\".join(res))"]},{"cell_type":"markdown","id":"038949a4-35d4-4a2f-bc3e-9cc0b22ca7e8","metadata":{"id":"038949a4-35d4-4a2f-bc3e-9cc0b22ca7e8"},"source":["* _–ü—Ä–∏–Ω—Ü–∞_ - considered feminine, which is wrong, let's postpone fixing for now.\n","* _–î—ä–ª–≥–æ–æ—á–∞–∫–≤–∞–Ω–∏—è_  - will be fixed by Rule3\n","* _–≥–æ—Å—Ç_            - also will be fixed by Rule3\n","* _–≥–æ—Å—Ç–∞_           - add to later (not sure yet which rule to apply)\n","* _—Å—ä—É—á–µ–Ω–∏–∫–∞_       - add to later (because root)\n","* _–¥–æ–±—Ä–∏—è_          - add to later (because root)\n","* _—É—Å–ø–µ–ª–∏—è_         - Stanza thinks this is a VERB, which is wrong, so let's add to the list of \"will not fix\""]},{"cell_type":"code","execution_count":null,"id":"58b7aa85-e66b-42f7-81ee-0265a2c8269d","metadata":{"id":"58b7aa85-e66b-42f7-81ee-0265a2c8269d","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# keep the lists of passed and current tests up to date\n","idx_failed = [26, 36, 38, 40, 42]\n","idx_passed = sorted(set(idx_passed + p))\n","idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n","idx_current = sorted(list(set(idx_current) - set(p)))\n","idx_current = sorted(list(set(idx_current) - set(idx_failed)))"]},{"cell_type":"markdown","id":"7ee6d997-9847-4d3e-aab5-bae054ffc763","metadata":{"id":"7ee6d997-9847-4d3e-aab5-bae054ffc763"},"source":["#### 6.4.3 Regression Test"]},{"cell_type":"markdown","id":"2ed54248-7a08-45e3-b32d-e43ad1e70348","metadata":{"id":"2ed54248-7a08-45e3-b32d-e43ad1e70348"},"source":["Test the previously successful sentences to determine if Rule2 caused any breakages. Perform the regression using all rules defined till now (Rule1, Rule2)"]},{"cell_type":"code","execution_count":null,"id":"7c77dfb9-1cf8-4e86-a64f-20dbfe82874a","metadata":{"id":"7c77dfb9-1cf8-4e86-a64f-20dbfe82874a","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["_ = test_definite_article_all(test_set_1.loc[idx_passed], [cond_rule1, cond_rule2], [rule1, rule2], print_passed=False)"]},{"cell_type":"markdown","id":"358211a9-9f26-4801-a5b4-60309e07d494","metadata":{"id":"358211a9-9f26-4801-a5b4-60309e07d494"},"source":["##### Analyze results from the regression"]},{"cell_type":"code","execution_count":null,"id":"58e9e7ff-07d4-46ff-885e-4bc64f0f9c2c","metadata":{"id":"58e9e7ff-07d4-46ff-885e-4bc64f0f9c2c","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["res = []\n","res.append(inspect_word(row_to_dict(test_set_1, 37), 2))  # –ò–≤–∞–Ω, üëâ–≥–æ—Å—Ç—ä—Ç –æ—Ç –°–æ–ø–æ—Ç, –¥–æ–π–¥–µ.\n","res.append(inspect_word(row_to_dict(test_set_1, 39), 2))  # –ò–≤–∞–Ω –µ üëâ—Å—ä—É—á–µ–Ω–∏–∫—ä—Ç –º–∏.\n","res.append(inspect_word(row_to_dict(test_set_1, 59), 3))  # –ü—Ä–∏—è—Ç–µ–ª—è—Ç –Ω–∏ –µ üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","res.append(inspect_word(row_to_dict(test_set_1, 61), 3))  # –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è—Ç, –∂–∏–≤–µ–µ —Ç—É–∫–∞.\n","res.append(inspect_word(row_to_dict(test_set_1, 63), 6))  # –ü—Ä–∏—è—Ç–µ–ª—è—Ç –Ω–∏ –µ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è—Ç.\n","print(\"\\n\".join(res))"]},{"cell_type":"markdown","id":"eafe35db-5c4e-4b47-aa8f-28e3a0a0cd19","metadata":{"id":"eafe35db-5c4e-4b47-aa8f-28e3a0a0cd19"},"source":["When we implement the next rules these failures should be fixed. For now let's move them to the list with failed tests. We'll get back to them later."]},{"cell_type":"markdown","id":"747a21d6-7d6d-4893-a5c7-c00680c4496f","metadata":{"id":"747a21d6-7d6d-4893-a5c7-c00680c4496f"},"source":["\n","\n"]},{"cell_type":"code","execution_count":null,"id":"db3dcac6-716e-47e5-a6ed-fe946190d792","metadata":{"id":"db3dcac6-716e-47e5-a6ed-fe946190d792","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["idx_failed = [37, 39, 59, 61, 63]\n","idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))"]},{"cell_type":"markdown","id":"728e1491-2db5-4ef1-981a-8555e1514d53","metadata":{"id":"728e1491-2db5-4ef1-981a-8555e1514d53"},"source":["### 6.5 Iteration 3"]},{"cell_type":"markdown","id":"086b1429-7f4e-4778-b66f-9ba6588bb586","metadata":{"id":"086b1429-7f4e-4778-b66f-9ba6588bb586"},"source":["#### 6.5.1 Implement Rule3"]},{"cell_type":"markdown","id":"e8b66351-0f31-4b33-a58f-0893d0628ecc","metadata":{"id":"e8b66351-0f31-4b33-a58f-0893d0628ecc"},"source":["Rule3 states that adjectives, numerals, participles and possessive pronouns take the same article as the noun they agree with. Let's first implement the rules for adjectives."]},{"cell_type":"code","execution_count":null,"id":"032345fd-199f-42ea-b114-33553f67cde2","metadata":{"id":"032345fd-199f-42ea-b114-33553f67cde2","executionInfo":{"status":"aborted","timestamp":1737273623437,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule3(token1, token2, idx_token):\n","    errors = []\n","\n","    # –î—ä–ª–≥–æ–æ—á–∞–∫–≤–∞–Ω–∏—è –≥–æ—Å—Ç\n","    if token1.endswith((\"—è\")):  # –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª–Ω–æ—Ç–æ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ —Å –ø—ä–ª–µ–Ω —á–ª–µ–Ω\n","        errors.append(token1)\n","\n","    # –î—ä–ª–≥–æ–æ—á–∞–∫–≤–∞–Ω–∏—è—Ç –≥–æ—Å—Ç\n","    if token2.endswith((\"—ä—Ç\", \"—è—Ç\")):  # —Å—ä—â–µ—Å—Ç–≤–∏—Ç–µ–ª–Ω–æ—Ç–æ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ —Å –Ω–µ–ø—ä–ª–µ–Ω —á–ª–µ–Ω\n","        errors.append(token2)\n","\n","    return errors"]},{"cell_type":"markdown","id":"2048b432-52b5-44a3-b01a-299d7217961c","metadata":{"id":"2048b432-52b5-44a3-b01a-299d7217961c"},"source":["#### 6.5.2 Test Rule3"]},{"cell_type":"code","execution_count":null,"id":"52b911e9-fd1f-4a51-8256-827088fd8970","metadata":{"id":"52b911e9-fd1f-4a51-8256-827088fd8970","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["conditions = [cond_rule1, cond_rule2, cond_rule3]\n","rules = [rule1, rule2, rule3]\n","p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"]},{"cell_type":"markdown","id":"7100aa3e-4313-4ae5-a9ca-029bf124fe3d","metadata":{"id":"7100aa3e-4313-4ae5-a9ca-029bf124fe3d"},"source":["##### Analyze the test"]},{"cell_type":"code","execution_count":null,"id":"6f4640bf-7d57-4188-91c5-f3fda0770e98","metadata":{"id":"6f4640bf-7d57-4188-91c5-f3fda0770e98","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["res = []\n","res.append(inspect_word(row_to_dict(test_set_1, 44), 3))  # –ü–µ—à–æ —Å–µ –æ–∫–∞–∑–∞ üëâ–Ω–∞–π-–≤–µ—Ä–Ω–∏—è –º—É –ø—Ä–∏—è—Ç–µ–ª.\n","res.append(inspect_word(row_to_dict(test_set_1, 46), 3))  # –ü–µ—à–æ —Å–µ –æ–∫–∞–∑–∞ üëâ–¥–∞—Ä–∏—Ç–µ–ª—è –Ω–∞ —É—á–∏–ª–∏—â–µ—Ç–æ.\n","res.append(inspect_word(row_to_dict(test_set_1, 48), 5))  # –£—á–µ–Ω–∏–∫—ä—Ç –Ω–∞ –ø—ä—Ä–≤–∏—è —á–∏–Ω –∏–∑–≥–ª–µ–∂–¥–∞ üëâ–Ω–∞–π-–¥–æ–≤–æ–ª–Ω–∏—è –æ—Ç –≤—Å–∏—á–∫–∏.\n","res.append(inspect_word(row_to_dict(test_set_1, 50), 0))  # üëâ–ú–∞–ª–∫–∏—è, –∑–∞–ø–æ–≤—è–¥–∞–π –µ–¥–Ω–æ –±–æ–Ω–±–æ–Ω—á–µ!\n","res.append(inspect_word(row_to_dict(test_set_1, 58), 0))  # üëâ–ü—Ä–∏—è—Ç–µ–ª—è –Ω–∏ –µ üëâ–ª–µ–∫–∞—Ä—è.\n","res.append(inspect_word(row_to_dict(test_set_1, 60), 3))  # –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è, –∂–∏–≤–µ–µ —Ç—É–∫–∞.\n","res.append(inspect_word(row_to_dict(test_set_1, 62), 0))  # üëâ–ü—Ä–∏—è—Ç–µ–ª—è –Ω–∏ –µ –ê–Ω–≥–µ–ª –ò–≤–∞–Ω—á–µ–≤, üëâ–ª–µ–∫–∞—Ä—è.\n","print(\"\\n\".join(res))"]},{"cell_type":"markdown","id":"af207e60-004c-44e4-84bc-a2f716d2c180","metadata":{"id":"af207e60-004c-44e4-84bc-a2f716d2c180"},"source":["* 44 _–Ω–∞–π-–≤–µ—Ä–Ω–∏—è_ - should be fixed by Rule4\n","* 46 _–¥–∞—Ä–∏—Ç–µ–ª—è_ - should be fixed by Rule4\n","* 48 _–Ω–∞–π_–¥–æ–≤–æ–ª–Ω–∏—è_ - should be fixed by Rule4\n","* 50 _–ú–∞–ª–∫–∏—è_ - should be fixed by Rule_6\n","* 58 _–ü—Ä–∏—è—Ç–µ–ª—è_ on row 58 - should be fixed by Rule_7\n","* 60 _–ª–µ–∫–∞—Ä—è_ - should be fixed by Rule_7\n","* 62 _–ü—Ä–∏—è—Ç–µ–ª—è_ on row 62 - should be fixed by Rule_7"]},{"cell_type":"code","execution_count":null,"id":"ef6f6f01-2d40-46a3-b53f-32bcd2ef2938","metadata":{"id":"ef6f6f01-2d40-46a3-b53f-32bcd2ef2938","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# keep the lists with passing and current tests up to date\n","idx_failed = [50, 58, 60, 62]\n","idx_passed = sorted(set(idx_passed + p))\n","idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n","idx_current = sorted(list(set(idx_current) - set(p)))\n","idx_current = sorted(list(set(idx_current) - set(idx_failed)))"]},{"cell_type":"markdown","id":"d8d1d148-3f24-4c17-a754-e11c1ff6664d","metadata":{"id":"d8d1d148-3f24-4c17-a754-e11c1ff6664d"},"source":["#### 6.5.3 Regression Test"]},{"cell_type":"markdown","id":"57310678-31cd-4edb-836d-50b6914930e5","metadata":{"id":"57310678-31cd-4edb-836d-50b6914930e5"},"source":["Ensure that we have not violated Rule 1 and Rule 2:"]},{"cell_type":"code","execution_count":null,"id":"bdec3910-5f91-4c68-af5f-264c3bfad583","metadata":{"id":"bdec3910-5f91-4c68-af5f-264c3bfad583","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"]},{"cell_type":"markdown","id":"384dcd2b-6a12-4135-a91a-59b77a3b12a2","metadata":{"id":"384dcd2b-6a12-4135-a91a-59b77a3b12a2"},"source":["### 6.6 Iteration 4"]},{"cell_type":"markdown","id":"3949a979-ccfb-4971-9027-511bc01de984","metadata":{"id":"3949a979-ccfb-4971-9027-511bc01de984"},"source":["#### 6.6.1 Implement Rule4"]},{"cell_type":"markdown","id":"15dea907-9a28-434f-bb10-32994a36c1d7","metadata":{"id":"15dea907-9a28-434f-bb10-32994a36c1d7"},"source":["According to Rule4, the full definite article should be used when a noun is after verbs like _—Å—ä–º_, _–±—ä–¥–∞_, _–æ–∫–∞–∑–≤–∞–º —Å–µ_, _–∏–∑–≥–ª–µ–∂–¥–∞–º_, etc. In order to check the previous verb, we need to check the _lemma_ of the verb."]},{"cell_type":"markdown","id":"7781512d-c745-43a3-b3bf-f1a345545262","metadata":{"id":"7781512d-c745-43a3-b3bf-f1a345545262"},"source":["First let's see what the previously failed sentences look like."]},{"cell_type":"code","execution_count":null,"id":"d46e149d-c94b-4c39-95c7-b14984cdf20f","metadata":{"id":"d46e149d-c94b-4c39-95c7-b14984cdf20f","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["inspect_spacy_doc(nlp_st(test_set_1.loc[39, \"text\"]))\n","inspect_spacy_doc(nlp_st(test_set_1.loc[44, \"text\"]))\n","inspect_spacy_doc(nlp_st(test_set_1.loc[46, \"text\"]))\n","inspect_spacy_doc(nlp_st(test_set_1.loc[48, \"text\"]))"]},{"cell_type":"markdown","id":"6fbdc986-53c8-4166-b84a-a3cebf3245f5","metadata":{"id":"6fbdc986-53c8-4166-b84a-a3cebf3245f5"},"source":["<img src=\"images/rule4_pattern_new.png\" width=\"800\">"]},{"cell_type":"markdown","id":"614dc031-14d5-467f-bf70-f68aa81114b5","metadata":{"id":"614dc031-14d5-467f-bf70-f68aa81114b5"},"source":["The above pattern shows that the first token is a verb (including auxiliary), while the second token is either a noun or an adjective, both of which must be in masculine singular form."]},{"cell_type":"markdown","id":"ce28d2e4-35ee-4c72-9197-aff38931a51b","metadata":{"id":"ce28d2e4-35ee-4c72-9197-aff38931a51b"},"source":["#### 6.6.2 Test Rule4"]},{"cell_type":"code","execution_count":null,"id":"6b594291-e2b9-4c7a-b901-b0db615bbe75","metadata":{"id":"6b594291-e2b9-4c7a-b901-b0db615bbe75","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":28,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4]\n","rules = [rule1, rule2, rule3, rule4]\n","\n","p, c = test_definite_article_all(test_set_1.loc[[39, 44, 46, 48]], conditions, rules)"]},{"cell_type":"markdown","id":"f8beedff-19c9-4034-9c5d-1d6aaa861c8d","metadata":{"id":"f8beedff-19c9-4034-9c5d-1d6aaa861c8d"},"source":["##### Analyze"]},{"cell_type":"markdown","id":"e1997e19-fa5f-4567-a3d8-04de5d2ef462","metadata":{"id":"e1997e19-fa5f-4567-a3d8-04de5d2ef462"},"source":["We expected row 39 to pass but it is still failing. This is likely due to one of the existing rules. We should run tests on each rule individually to identify which one is causing the issue, specifically the one that returns the word _—Å—ä—É—á–µ–Ω–∏–∫—ä—Ç_."]},{"cell_type":"code","execution_count":null,"id":"6ed83737-7b6a-443f-b6cc-e74573fc365c","metadata":{"id":"6ed83737-7b6a-443f-b6cc-e74573fc365c","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["p, c = test_definite_article_all(test_set_1.loc[[39]], [cond_rule1], [rule1], print_passed=False)"]},{"cell_type":"code","execution_count":null,"id":"e2e3f5d4-5170-421b-9a4c-381fc52008fd","metadata":{"id":"e2e3f5d4-5170-421b-9a4c-381fc52008fd","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["p, c = test_definite_article_all(test_set_1.loc[[39]], [cond_rule2], [rule2], print_passed=False)"]},{"cell_type":"markdown","id":"28f63fe2-536b-4b83-8fcd-b97029276ade","metadata":{"id":"28f63fe2-536b-4b83-8fcd-b97029276ade"},"source":["Row 39 doesn't pass due to Rule2. In Rule4 we checked whether the previous token was AUX or a VERB, so in Rule2 we need to introduce an exception that specifies the previous token cannot be a VERB or AUX. Otherwise we will have two rules acting on the same pattern."]},{"cell_type":"markdown","id":"5da7bacc-3f9f-4646-bb36-e6d82d40e935","metadata":{"id":"5da7bacc-3f9f-4646-bb36-e6d82d40e935"},"source":["#### 6.6.3 Update Rule2 and test again"]},{"cell_type":"code","execution_count":null,"id":"7927294d-7fce-4373-91df-186322046539","metadata":{"id":"7927294d-7fce-4373-91df-186322046539","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# keep the old rule if we need to test with it\n","cond_rule2_prev = cond_rule2\n","rule2_prev = rule2\n","\n","\n","def cond_rule2(row_dict, i):\n","    \"\"\"Search for either:\n","        - single, masculine NOUN, not subject, not preceded by a verb\n","        - preceding token is a verb but different from —Å—ä–º, –æ–∫–∞–∑–≤–∞–º —Å–µ, –∏–∑–ª–≥–µ–∂–¥–∞, etc.\"\"\"\n","    is_token1_noun = nlp_get_pos(row_dict, i) == \"NOUN\"\n","    is_token1_verb = nlp_get_pos(row_dict, i) == \"VERB\"\n","    is_token1_aux = nlp_get_pos(row_dict, i) == \"AUX\"\n","    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n","    is_token1_subj = is_dep_subject(row_dict, i)\n","\n","    is_token2_noun = nlp_get_pos(row_dict, i + 1) == \"NOUN\"\n","    is_token2_subj = is_dep_subject(row_dict, i + 1)\n","    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n","\n","    # if token is masculine single noun and !subj, and the previous token is not a verb\n","    if i == 0 and is_token1_noun and is_token1_masc_sg and not is_token1_subj:\n","        return True\n","\n","    is_like_verb = is_token1_verb or is_token1_aux\n","\n","    if i != 0 and is_token2_noun and is_token2_masc_sg and not is_token2_subj:\n","        lemma = nlp_get_lemma(row_dict, i)\n","\n","        is_lemma_aux_syn = lemma in (\"–µ\", \"—Å—ä–º\", \"–æ–∫–∞–∂–∞-(—Å–µ)\", \"–∏–∑–≥–ª–µ–∂–¥–∞\")\n","        is_non_aux_syn = not is_like_verb or (is_like_verb and not is_lemma_aux_syn)\n","        if is_non_aux_syn:\n","            return True\n","\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"561625fc-c0a1-41c0-b34a-7cf42e218b17","metadata":{"id":"561625fc-c0a1-41c0-b34a-7cf42e218b17","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule2(token1, token2, token_idx):\n","    errors = []\n","    word = token1 if token_idx == 0 else token2\n","    if word.endswith((\"—ä—Ç\", \"—è—Ç\")):  # objects should not have full article\n","        errors.append(word)\n","\n","    return errors"]},{"cell_type":"markdown","id":"8b6ac6fb-7be7-485c-baf3-4f5b914a350f","metadata":{"id":"8b6ac6fb-7be7-485c-baf3-4f5b914a350f"},"source":["First test with a small set:"]},{"cell_type":"code","execution_count":null,"id":"23e35011-342f-42c3-80f6-5106daf029a3","metadata":{"id":"23e35011-342f-42c3-80f6-5106daf029a3","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4]\n","rules = [rule1, rule2, rule3, rule4]\n","p, c = test_definite_article_all(test_set_1.loc[[39, 44, 46, 48]], conditions, rules)"]},{"cell_type":"markdown","id":"6c687298-7116-4780-a276-b4e86be0f468","metadata":{"id":"6c687298-7116-4780-a276-b4e86be0f468"},"source":["Next test with the remaining rows:"]},{"cell_type":"code","execution_count":null,"id":"4de0c865-e752-4f96-8b93-a653d1c6a9c0","metadata":{"id":"4de0c865-e752-4f96-8b93-a653d1c6a9c0","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"]},{"cell_type":"markdown","id":"b10c7efd-bcc3-4a9d-aecf-c27b4b80d5c4","metadata":{"id":"b10c7efd-bcc3-4a9d-aecf-c27b4b80d5c4"},"source":["##### Analyze the remaining failures"]},{"cell_type":"code","execution_count":null,"id":"54bac706-f3df-4550-abc9-6a2e721bddb3","metadata":{"id":"54bac706-f3df-4550-abc9-6a2e721bddb3","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["inspect_spacy_doc(nlp_st(test_set_1.loc[66, \"text\"]))\n","inspect_spacy_doc(nlp_st(test_set_1.loc[68, \"text\"]))"]},{"cell_type":"markdown","id":"793ab3de-808c-4e4a-8652-2714a192a979","metadata":{"id":"793ab3de-808c-4e4a-8652-2714a192a979"},"source":["* 66 _–Ω–æ–≤–∏—è—Ç –±—è–ª –±–ª–æ–∫_ and 68 _–í–∏—Å–æ–∫–∏—è –±—è–ª –±–ª–æ–∫_ - the pattern ADJ/ADJ/NOUN points to Rule5.\n","* 72 and 73 depend on the order of words. We don't know who is the doer of the action in those sentences. Let's postpone fixing them for now."]},{"cell_type":"code","execution_count":null,"id":"172bb6b4-3a03-4560-985e-af3f5bdf1eb6","metadata":{"id":"172bb6b4-3a03-4560-985e-af3f5bdf1eb6","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["idx_failed = [72, 73]\n","idx_passed = sorted(set(idx_passed + p))\n","idx_passed = sorted(list(set(idx_passed) - set(idx_failed)))\n","idx_current = sorted(list(set(idx_current) - set(p)))\n","idx_current = sorted(list(set(idx_current) - set(idx_failed)))"]},{"cell_type":"markdown","id":"9d9a18aa-00fe-47af-94b2-1d45fdd9970e","metadata":{"id":"9d9a18aa-00fe-47af-94b2-1d45fdd9970e"},"source":["#### 6.6.4 Regression Test"]},{"cell_type":"code","execution_count":null,"id":"ba32b45a-c40e-4ada-925e-69acb82d39b7","metadata":{"id":"ba32b45a-c40e-4ada-925e-69acb82d39b7","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"]},{"cell_type":"markdown","id":"c8bd7763-94eb-4cc3-a8e2-247eb012e950","metadata":{"id":"c8bd7763-94eb-4cc3-a8e2-247eb012e950"},"source":["### 6.7 Iteration 5"]},{"cell_type":"markdown","id":"441deff4-7730-41c5-9edb-cdfa5f61aa98","metadata":{"id":"441deff4-7730-41c5-9edb-cdfa5f61aa98"},"source":["#### 6.7.1 Implement Rule5"]},{"cell_type":"markdown","id":"affb458b-66c8-467d-8243-eca3b6200482","metadata":{"id":"affb458b-66c8-467d-8243-eca3b6200482"},"source":["Rule5 says that when there are two or more adjectives in front of the noun, only the first adjective takes the definite article, which could be short or long. In the example with rows 66 and 68 which were analyzed in the previous section, we see that the two phrases _–Ω–æ–≤–∏—è—Ç –±—è–ª –±–ª–æ–∫_ and _–≤–∏—Å–æ–∫–∏—è –±—è–ª –±–ª–æ–∫_ which are identical from grammatical standpoint, cannot be distinguished just by looking at their part of speech. We need to also analyze their relation to the entire sentence. The difference here is that in the first case Stanza correctly determined the noun _–±–ª–æ–∫_ as an indirect object, therefore requiring the short form of the definite article, and the same word in the second sentence as nominal subject, requiring full definite article."]},{"cell_type":"markdown","id":"7b55fd73-6791-4143-a0a7-22ae6f097806","metadata":{"id":"7b55fd73-6791-4143-a0a7-22ae6f097806"},"source":["<img src=\"images/rule7_pattern_new.png\" width=\"650\">"]},{"cell_type":"markdown","id":"a2bf7c6a-04c6-4192-b636-fd202cf038ca","metadata":{"id":"a2bf7c6a-04c6-4192-b636-fd202cf038ca"},"source":["Although we expressed the condition verbally as one rule, we need to create two sets of functions for the cases of short and long definite article."]},{"cell_type":"code","execution_count":null,"id":"e316a49b-5c42-45e7-a93f-cb862711546c","metadata":{"id":"e316a49b-5c42-45e7-a93f-cb862711546c","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# The adjectives, as well as the pronouns, the ordinal numerals etc., used as attributes in the sentence\n","# are usually placed in front of the nouns they qualify. In this case, the definite article, if needed,\n","# is joined to the _first_ attribute of the noun phrase. [4],[5]\n","def cond_rule5_helper(row_dict, i):\n","    \"\"\"\n","    POS: ADJ / ADJ / NOUN iobj,  all masc. singular -> first ADJ must have def. art. short form\n","    - or -\n","    POS: ADJ / ADJ / NOUN nsubj, all masc. singular -> first ADJ must have def. art. long form\n","    \"\"\"\n","    if i >= row_dict[\"num_tokens\"] - 2:\n","        return False\n","\n","    is_token1_masc_sg = is_masculine_singular(row_dict, i)\n","    is_token1_adj = nlp_get_pos(row_dict, i) == \"ADJ\"\n","\n","    is_token2_masc_sg = is_masculine_singular(row_dict, i + 1)\n","    is_token2_adj = nlp_get_pos(row_dict, i + 1) == \"ADJ\"\n","\n","    is_token3_masc_sg = is_masculine_singular(row_dict, i + 2)\n","    is_token3_noun = nlp_get_pos(row_dict, i + 2) == \"NOUN\"\n","\n","    if is_token1_masc_sg and is_token2_masc_sg and is_token3_masc_sg:\n","        if is_token1_adj and is_token2_adj and is_token3_noun:\n","            return True\n","\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"a596790c-ae3d-4097-965b-a7cce11ac7df","metadata":{"id":"a596790c-ae3d-4097-965b-a7cce11ac7df","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def cond_rule5_short(row_dict, i):\n","    if cond_rule5_helper(row_dict, i):\n","        noun_dep = nlp_get_dep(row_dict, i + 2)\n","        if noun_dep in (\"iobj\"):\n","            return True\n","\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"937162e9-19a2-448f-b6e8-34180d1eac97","metadata":{"id":"937162e9-19a2-448f-b6e8-34180d1eac97","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def cond_rule5_long(row_dict, i):\n","    if cond_rule5_helper(row_dict, i):\n","        noun_dep = nlp_get_dep(row_dict, i + 2)\n","        if noun_dep in (\"nsubj\"):\n","            return True\n","\n","    return False"]},{"cell_type":"code","execution_count":null,"id":"b3e3e8b9-5128-4bf5-80d9-d41c5f74a6db","metadata":{"id":"b3e3e8b9-5128-4bf5-80d9-d41c5f74a6db","executionInfo":{"status":"aborted","timestamp":1737273623438,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule5_short(token1, token2, token_idx):\n","    errors = []\n","\n","    # –ê–∑ –∂–∏–≤–µ—è –≤ –Ω–æ–≤–∏—è—Ç –±—è–ª –±–ª–æ–∫.\n","    if not token1.endswith((\"—è\")):  # –ø—ä—Ä–≤–æ—Ç–æ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª–Ω–æ –≤ –≥—Ä—É–ø–∞—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ —Å –Ω–µ–ø—ä–ª–µ–Ω —á–ª–µ–Ω\n","        errors.append(token1)\n","\n","    return errors"]},{"cell_type":"code","execution_count":null,"id":"f41f9005-a53e-4edb-b448-77ba560c7956","metadata":{"id":"f41f9005-a53e-4edb-b448-77ba560c7956","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["def rule5_long(token1, token2, token_idx):\n","    errors = []\n","\n","    # –í–∏—Å–æ–∫–∏—è –±—è–ª –±–ª–æ–∫ –µ –Ω–æ–≤.\n","    if not token1.endswith((\"—è—Ç\")):  # –ø—ä—Ä–≤–æ—Ç–æ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª–Ω–æ –≤ –≥—Ä—É–ø–∞—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ —Å –ø—ä–ª–µ–Ω —á–ª–µ–Ω\n","        errors.append(token1)\n","\n","    return errors"]},{"cell_type":"markdown","id":"cbbbe7b1-4118-413d-a1bd-fd3858c74f9f","metadata":{"id":"cbbbe7b1-4118-413d-a1bd-fd3858c74f9f"},"source":["#### 6.7.2 Test Rule5"]},{"cell_type":"code","execution_count":null,"id":"25787732-5233-40c0-b9bd-dbaf507438df","metadata":{"id":"25787732-5233-40c0-b9bd-dbaf507438df","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":27,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["conditions = [cond_rule1, cond_rule2, cond_rule3, cond_rule4, cond_rule5_short, cond_rule5_long]\n","rules = [rule1, rule2, rule3, rule4, rule5_short, rule5_long]\n","p, c = test_definite_article_all(test_set_1.loc[idx_current], conditions, rules)"]},{"cell_type":"markdown","id":"e37e9381-f131-48d7-b871-f6ef8134ceb7","metadata":{"id":"e37e9381-f131-48d7-b871-f6ef8134ceb7"},"source":["#### 6.7.3 Regression test"]},{"cell_type":"code","execution_count":null,"id":"c59c5021-73f3-4796-8675-05cc35093491","metadata":{"id":"c59c5021-73f3-4796-8675-05cc35093491","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["_ = test_definite_article_all(test_set_1.loc[idx_passed], conditions, rules, print_passed=False)"]},{"cell_type":"markdown","id":"115df14d-efba-4b5c-aac2-d803e5d950ae","metadata":{"id":"115df14d-efba-4b5c-aac2-d803e5d950ae"},"source":["#### 6.7.4 Final test with the whole set"]},{"cell_type":"code","execution_count":null,"id":"3a732e00-9683-4212-b2a6-dae09239d655","metadata":{"id":"3a732e00-9683-4212-b2a6-dae09239d655","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["_ = test_definite_article_all(test_set_1, conditions, rules)"]},{"cell_type":"markdown","id":"e13be08b-5515-4b1c-9b8c-5f6b8f0f8ae6","metadata":{"id":"e13be08b-5515-4b1c-9b8c-5f6b8f0f8ae6"},"source":["We didn't predict correctly the usage of the definite article in 13 out of the 78 sentences. In some cases it is due to the NLP tag being incorrect, for example the case where the gender of the noun was tagged wrongly by Stanza. In other case it was because we still haven't implemented Rule7."]},{"cell_type":"markdown","id":"36bf6623-44ee-4504-b851-7d313ec210f3","metadata":{"id":"36bf6623-44ee-4504-b851-7d313ec210f3"},"source":["## 7 Test with real data"]},{"cell_type":"markdown","id":"cbf148ad-a02c-4501-9aa6-c8d7290aa0a8","metadata":{"id":"cbf148ad-a02c-4501-9aa6-c8d7290aa0a8"},"source":["We will work with the dataset [bulgarian-grammar-mistakes](https://huggingface.co/datasets/thebogko/bulgarian-grammar-mistakes) from huggingface. The data was originally collected from articles from Bulgarian Wikipedia as well as rows from OSCAR's Bulgarian datasets."]},{"cell_type":"markdown","id":"99bcc32a-5f12-459a-ab59-ba2af4b805f6","metadata":{"id":"99bcc32a-5f12-459a-ab59-ba2af4b805f6"},"source":["### 7.1 Load and prepare the dataset"]},{"cell_type":"code","execution_count":null,"id":"c506fd73-d949-4abb-84dd-258304611a87","metadata":{"id":"c506fd73-d949-4abb-84dd-258304611a87","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors = pd.read_csv(\"https://raw.githubusercontent.com/MirkaIvanova/datasets/refs/heads/main/data_science_project/grammar_errors_original.csv\")"]},{"cell_type":"code","execution_count":null,"id":"60cac664-961b-4e3b-9245-1047c7d5492f","metadata":{"id":"60cac664-961b-4e3b-9245-1047c7d5492f","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"code","execution_count":null,"id":"50fece92-6419-4123-825d-41c01d42fbce","metadata":{"id":"50fece92-6419-4123-825d-41c01d42fbce","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.head(5)"]},{"cell_type":"markdown","id":"b92bf35e-7202-4a3c-9dd9-0928723ccd3b","metadata":{"id":"b92bf35e-7202-4a3c-9dd9-0928723ccd3b"},"source":["#### 7.1.1 Filter only errors related to article misuse:"]},{"cell_type":"code","execution_count":null,"id":"508388a9-0423-4788-ab69-c087c335ddd8","metadata":{"id":"508388a9-0423-4788-ab69-c087c335ddd8","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.error_type.unique()"]},{"cell_type":"code","execution_count":null,"id":"66545708-56f3-49c8-9b67-f3be2d742116","metadata":{"id":"66545708-56f3-49c8-9b67-f3be2d742116","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors = grammar_errors[grammar_errors[\"error_type\"] == \"article_misuse\"]"]},{"cell_type":"code","execution_count":null,"id":"ed80a4ce-9ec0-4631-ab93-06371816762d","metadata":{"id":"ed80a4ce-9ec0-4631-ab93-06371816762d","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"markdown","id":"adb65785-ac38-4ce3-aa8d-88fa1d0533b1","metadata":{"id":"adb65785-ac38-4ce3-aa8d-88fa1d0533b1"},"source":["#### 7.1.2 Rename column headings"]},{"cell_type":"code","execution_count":null,"id":"b1988e29-233e-47dc-b926-6c83b7787fbc","metadata":{"id":"b1988e29-233e-47dc-b926-6c83b7787fbc","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":26,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors = grammar_errors.rename(columns={\"erroneous\": \"incorrect\"})"]},{"cell_type":"markdown","id":"983486ad-493d-4400-a528-9cd09ee26a4b","metadata":{"id":"983486ad-493d-4400-a528-9cd09ee26a4b"},"source":["#### 7.1.3 Add a column with differing words"]},{"cell_type":"code","execution_count":null,"id":"0e5d2126-4078-454f-9fec-f32d9aa2e139","metadata":{"id":"0e5d2126-4078-454f-9fec-f32d9aa2e139","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors[['incorrect', 'correct']] = grammar_errors[['incorrect', 'correct']].map(str.strip)\n","grammar_errors[[\"correct_words\", \"incorrect_words\"]] = grammar_errors.apply(get_differing_words, axis=1, result_type=\"expand\")"]},{"cell_type":"code","execution_count":null,"id":"9c907237-7370-454b-bde5-c02ee2bc98d8","metadata":{"id":"9c907237-7370-454b-bde5-c02ee2bc98d8","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.head(3)"]},{"cell_type":"markdown","id":"9dd393de-73e8-464f-a7eb-2043d09c619a","metadata":{"id":"9dd393de-73e8-464f-a7eb-2043d09c619a"},"source":["#### 7.1.4 Melt the dataset and sort pairs of correct/incorrect sentences to be together"]},{"cell_type":"code","execution_count":null,"id":"7eb07c3b-6aa5-425a-89c4-ea092e741e44","metadata":{"id":"7eb07c3b-6aa5-425a-89c4-ea092e741e44","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"code","execution_count":null,"id":"fbbb9be4-95d2-4343-94af-37e92e9e693a","metadata":{"id":"fbbb9be4-95d2-4343-94af-37e92e9e693a","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors = melt_and_sort_sentences(grammar_errors)"]},{"cell_type":"code","execution_count":null,"id":"07bd8c5d-043c-4ffd-b54c-399aa5e3bdfe","metadata":{"id":"07bd8c5d-043c-4ffd-b54c-399aa5e3bdfe","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"code","execution_count":null,"id":"81c25413-fece-437c-b3b8-cfc9197adf3b","metadata":{"id":"81c25413-fece-437c-b3b8-cfc9197adf3b","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.head(4)"]},{"cell_type":"markdown","id":"577393bc-0932-4268-b1b9-65460a81eb1b","metadata":{"id":"577393bc-0932-4268-b1b9-65460a81eb1b"},"source":["#### 7.1.5 Add NLP tags"]},{"cell_type":"markdown","id":"3509ef8d-b6be-44e8-b904-68468896560d","metadata":{"id":"3509ef8d-b6be-44e8-b904-68468896560d"},"source":["<div style=\"background-color:bisque\">‚ö†Ô∏èNote that calculating the features using Stanza takes around 1 hour on a laptop with average specs, therefore here we are loading a pre-saved file."]},{"cell_type":"code","source":["from copy import deepcopy"],"metadata":{"id":"TWXhi_MtgzF1","executionInfo":{"status":"aborted","timestamp":1737273623439,"user_tz":-120,"elapsed":25,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"TWXhi_MtgzF1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["grammar_errors.columns"],"metadata":{"id":"jg1l4ITxeVQv","executionInfo":{"status":"aborted","timestamp":1737273623444,"user_tz":-120,"elapsed":30,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"jg1l4ITxeVQv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["grammar_errors_10 = deepcopy(grammar_errors.iloc[0:100])\n","grammar_errors.shape, grammar_errors_10.shape"],"metadata":{"id":"QqZeIkQCgUif","executionInfo":{"status":"aborted","timestamp":1737273623444,"user_tz":-120,"elapsed":15513,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"QqZeIkQCgUif","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"589959b4-463d-490d-a0ba-9c318ae77fe3","metadata":{"id":"589959b4-463d-490d-a0ba-9c318ae77fe3","executionInfo":{"status":"aborted","timestamp":1737273623691,"user_tz":-120,"elapsed":7,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["start_time = time.time()\n","\n","feature_columns_st = [\"pos\", \"tag\", \"dep\", \"morph\", \"lemmas\", \"left_edge\", \"right_edge\", \"num_tokens\"]\n","grammar_errors_10[feature_columns_st] = grammar_errors_10.apply(lambda r: extract_features(nlp_st, r, \"text\"), axis=1, result_type=\"expand\")\n","grammar_errors_10.to_csv(\"data/grammar_errors_10.csv\", index=None)\n","\n","end_time = time.time()\n","execution_time_st = end_time - start_time\n","print(f\"Execution time (stanza): {execution_time_st} seconds\")"]},{"cell_type":"code","source":["grammar_errors_10"],"metadata":{"id":"2CF6iFX3qnfs","executionInfo":{"status":"aborted","timestamp":1737273623691,"user_tz":-120,"elapsed":7,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"id":"2CF6iFX3qnfs","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"6ff9d292-af53-4166-bb96-a291da742be5","metadata":{"id":"6ff9d292-af53-4166-bb96-a291da742be5"},"source":["#### 7.1.6 Filter only rows with 1 sentence, no quotes and other special characters"]},{"cell_type":"markdown","id":"6069d5c9-16f9-4fed-bcba-23a395d3a8b5","metadata":{"id":"6069d5c9-16f9-4fed-bcba-23a395d3a8b5"},"source":["We need to filter out such texts since our rules can't deal with quoted text inside a sentence. Special characters also cause issues."]},{"cell_type":"code","execution_count":null,"id":"83de9b24-569c-499b-a43c-1958ea7c4286","metadata":{"id":"83de9b24-569c-499b-a43c-1958ea7c4286","executionInfo":{"status":"aborted","timestamp":1737273623691,"user_tz":-120,"elapsed":7,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors = grammar_errors[grammar_errors[\"n_sents\"] == 1]"]},{"cell_type":"code","execution_count":null,"id":"b91e10c6-425d-4e59-a1dc-fd7aac1ec83c","metadata":{"id":"b91e10c6-425d-4e59-a1dc-fd7aac1ec83c","executionInfo":{"status":"aborted","timestamp":1737273623691,"user_tz":-120,"elapsed":6,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["pattern = r\"[\\'\\\"‚Äò‚Äô‚Äú‚Äù¬∞/‚âà\\:]\"\n","grammar_errors = grammar_errors[~grammar_errors['text'].str.contains(pattern)]"]},{"cell_type":"code","execution_count":null,"id":"8738b042-550f-46eb-9379-f08b708f5eb3","metadata":{"id":"8738b042-550f-46eb-9379-f08b708f5eb3","executionInfo":{"status":"aborted","timestamp":1737273623693,"user_tz":-120,"elapsed":8,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"markdown","id":"fc3b1d83-24d2-4ed1-b0f1-580480ab7913","metadata":{"id":"fc3b1d83-24d2-4ed1-b0f1-580480ab7913"},"source":["### 7.2 Test with small subset of the real data"]},{"cell_type":"code","execution_count":null,"id":"39a53b1c-5c27-44ea-a9eb-ea06ac17828e","metadata":{"id":"39a53b1c-5c27-44ea-a9eb-ea06ac17828e","executionInfo":{"status":"aborted","timestamp":1737273623693,"user_tz":-120,"elapsed":8,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors_10tokens = grammar_errors[grammar_errors[\"num_tokens\"] < 10]"]},{"cell_type":"code","execution_count":null,"id":"48a375b2-c8f5-4b39-b05d-93fe15fd84c2","metadata":{"id":"48a375b2-c8f5-4b39-b05d-93fe15fd84c2","executionInfo":{"status":"aborted","timestamp":1737273623693,"user_tz":-120,"elapsed":8,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["# execution will take 30 sec\n","passed, failed = test_definite_article_all(grammar_errors_10tokens, conditions, rules, print_passed=False, print_failed=True)"]},{"cell_type":"markdown","id":"b38e8622-cd5c-4501-a6fa-6e69b96ae543","metadata":{"id":"b38e8622-cd5c-4501-a6fa-6e69b96ae543"},"source":["Let's review the outcomes.\n","\n","**To begin with**, the rules failed to detect errors in nearly a quarter (24%) of the tests.\n","However, upon closer inspection of the failures, a pattern emerges. Upon closer look, it is evident that most of the failed tests have even-numbered indices. This suggests that while correctly formed sentences were accurately identified, not all erroneous sentences were successfully detected.\n","\n","Let's take a closer look at the instances where the tests failed for sentences that were initially correct:"]},{"cell_type":"code","execution_count":null,"id":"87cdc332-0891-44fd-aca3-da2df60884ce","metadata":{"id":"87cdc332-0891-44fd-aca3-da2df60884ce","executionInfo":{"status":"aborted","timestamp":1737273623694,"user_tz":-120,"elapsed":9,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.loc[[338, 339, 2022, 2023, 3396, 3397, 3942, 3943 ]][['text', 'is_correct', 'incorrect_words', 'correct_words']]"]},{"cell_type":"markdown","id":"e5b0bd2b-2d8e-4253-b528-578e2599e078","metadata":{"id":"e5b0bd2b-2d8e-4253-b528-578e2599e078"},"source":["The sentence _–î–∞, —Ç–æ–≤–∞ –µ –£—á–∏—Ç–µ–ª—è—Ç_ is listed as both correct and incorrect.\n","\n","The sentence _–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –Ω–∞ —Ñ–æ—Ä—É–º–∞ —Ç–∞–∫–∞ –µ —Ä–µ—à–∏–ª_ is listed as correct, but in fact it is not.\n","\n","The sentence _–¢–æ–≤–∞ –µ —É—Å–ø–æ–∫–æ–∏—Ç–µ–ª–Ω–∏—è —Ö–∞–ø –∑–∞ —Å—ä–≤–µ—Å—Ç—Ç–∞ –º—É_ is also listed as correct, but in fact it is incorrect.\n","\n","Therefore, in at least these 3 examples, the rules correctly identified the error, but the expected result was wrong bcause the original data in the dataset was wrong.\n","\n","The assumption about the original wrong data is, that the data was scraped from various sources and considered \"correct\", then errors were automatically introduced to produce the incorrect version. However, it's important to note that the source material itself may not always be grammatically accurate. For exmaple, the sentence _–¢–æ–≤–∞ –µ —É—Å–ø–æ–∫–æ–∏—Ç–µ–ª–Ω–∏—è —Ö–∞–ø –∑–∞ —Å—ä–≤–µ—Å—Ç—Ç–∞ –º—É_ can be found [in a blog comment from 2010](https://petdoshkov.blog.bg/drugi/2010/05/10/vyzzivnoto-reshenie-za-nakazanieto-zabelejka.542411). This example demonstrates that even the original text contained grammatical errors, challenging the assumption that the initial data was entirely correct before deliberate mistakes were added.\n","\n","\n"]},{"cell_type":"markdown","id":"83e6e2d3-eb68-4651-a094-cd6391e08fad","metadata":{"id":"83e6e2d3-eb68-4651-a094-cd6391e08fad"},"source":["**Another reason** of the many failures is that we still haven't implemented all rules listed in the Grammas section. Additionally, we tested on a small set of 39 pairs of simple sentences so we didn't verify our \"model\" with enough data. Another explanation is that in the NLP features we extracted there are two still unused ones - left edge and right edge."]},{"cell_type":"markdown","id":"22819899-bcfd-4ce1-8f1b-6cc21cdc3070","metadata":{"id":"22819899-bcfd-4ce1-8f1b-6cc21cdc3070"},"source":["### 7.3 Test with the whole dataset"]},{"cell_type":"code","execution_count":null,"id":"08bc0c40-1ab1-4a6f-9f5a-168b0fb5642e","metadata":{"id":"08bc0c40-1ab1-4a6f-9f5a-168b0fb5642e","executionInfo":{"status":"aborted","timestamp":1737273623694,"user_tz":-120,"elapsed":9,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["grammar_errors.shape"]},{"cell_type":"markdown","id":"3ef08480-abab-4652-8b2d-9ae260951eb6","metadata":{"id":"3ef08480-abab-4652-8b2d-9ae260951eb6"},"source":["<div style=\"background-color:Bisque\">\n","\n","‚ö†Ô∏èThe below test will take ~ 18 minutes. As an alternative to executing it you may take a look at the screenshot."]},{"cell_type":"code","execution_count":null,"id":"68ee147a-d38b-4162-8012-568185691cbf","metadata":{"id":"68ee147a-d38b-4162-8012-568185691cbf","executionInfo":{"status":"aborted","timestamp":1737273623694,"user_tz":-120,"elapsed":9,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":["if False:\n","    start_time = time.time()\n","\n","    passed, failed = test_definite_article_all(grammar_errors, conditions, rules, print_passed=False, print_failed=False)\n","\n","    end_time = time.time()\n","    execution_time_st = end_time - start_time\n","    print(f\"Execution time (stanza): {execution_time_st} seconds\")"]},{"cell_type":"markdown","id":"68588f7c-de57-4021-ae8d-bced38631a98","metadata":{"id":"68588f7c-de57-4021-ae8d-bced38631a98"},"source":["Screenshot of the result:\n","\n","<img src=\"images/whole_dataset_result.png\">"]},{"cell_type":"markdown","id":"bdb232d5-6a7b-4a5c-9134-355b9dd972e9","metadata":{"id":"bdb232d5-6a7b-4a5c-9134-355b9dd972e9"},"source":["Testing with the whole dataset we see that one third of the tests failed. Certainly there is room for improvement!"]},{"cell_type":"markdown","id":"964ecbd8-e0cf-4be2-a2f6-b6fabbb32056","metadata":{"id":"964ecbd8-e0cf-4be2-a2f6-b6fabbb32056"},"source":["## Summary and insights gained"]},{"cell_type":"markdown","id":"8f673fcc-1dd8-4ab3-a0e3-002660e97a5d","metadata":{"id":"8f673fcc-1dd8-4ab3-a0e3-002660e97a5d"},"source":["Although the results of the final test were not as encouraging as hoped, the project still yielded valuable insights.\n","\n","Initially, selecting the appropriate NLP library was a challenging task. While UDPipe offered good performance, it lacked accuracy, and although Stanza delivered better results, it was much slower. This experience highlighted the importance of carefully balancing accuracy and performance when choosing tools for linguistic analysis.\n","\n","Another key realization was the unexpected complexity of Bulgarian grammar, particularly the rules surrounding the use of the definite article. This complexity necessitated a deeper investigation into the language's linguistic structures.\n","\n","Parsing text to detect incorrect definite articles also proved to be more complicated than expected. The development of effective rules for this task was hindered by the diversity of sentence structures encountered.\n","\n","Additionally, the testing dataset posed its own challenges, as it contained inaccuracies that affected the validation process. This emphasized the crucial need for high-quality, accurate datasets.\n","\n","Despite these obstacles, the implementation of rule-based methods produced promising results, especially in identifying errors in shorter sentences. This success demonstrated that even in the face of linguistic complexity, well-designed rules are essential for achieving accurate outcomes.\n","\n","The insights gained from this effort will undoubtedly contribute to the broader field of computational linguistics and inspire more accurate and efficient solutions for grammatical analysis in Bulgarian. As we continue to refine our approach and expand our rule set, we are confident in our ability to develop a robust and reliable tool for checking the correctness of definite articles in Bulgarian texts."]},{"cell_type":"markdown","id":"ab702264-ac2f-4fe8-b244-7e0bd6f9f529","metadata":{"id":"ab702264-ac2f-4fe8-b244-7e0bd6f9f529"},"source":["**References**\n","\n","<div id=\"ref1\">[1] Astoria Academy, <a href=\"https://astoria-academy.com/the-definite-articles-of-bulgarian/\">The Definite articles of Bulgarian,</a> 2023</div>\n","\n","<div id=\"ref2\">[2] CoLanguage <a href=\"https://www.colanguage.com/definite-article-bulgarian-nouns\">Definite article of the Bulgarian nouns</a></div>\n","\n","<div id=\"ref3\">[3] –≤. ‚Äû–ê–∑ –ë—É–∫–∏‚Äú –±—Ä. 16 <a href=\"https://ibl.bas.bg/ezikovi_spravki/otnovo-za-palniya-i-kratkiya-tchlen/\">–û—Ç–Ω–æ–≤–æ –∑–∞ –ø—ä–ª–Ω–∏—è –∏ –∫—Ä–∞—Ç–∫–∏—è —á–ª–µ–Ω</a></div>\n","\n","<div id=\"ref4\">[4] Raquel Jacob <a href=\"https://help.unbabel.com/hc/en-us/articles/360022878854-Language-Guidelines-Bulgarian\">Language Guidelines ‚Äì Bulgarian</a></div>\n","\n","<div id=\"ref5\">[5] Andonova, Sabeva, Zagorova <a href=\"https://caritas.bg/cms/wp-content/uploads/2015/04/A1-English.pdf?x10535\">Bulgarian for Refugees,</a> 2014</div>\n","\n","<div id=\"ref6\">[6] John Leafgren <a href=\"http://www.seelrc.org:8080/grammar/pdf/stand_alone_bulgarian.pdf\">A Concise Bulgarian\n","Grammar</a></div>\n","\n","<div id=\"ref7\">[7] G. Popova <a href=\"https://www.english-linguistics.de/archives/clark/SIMOV/CM/popova.pdf\">Towards an HPSG Account of the\n","Bulgarian Definite Article</a></div>\n","\n","<div id=\"ref8\">[8] K. Bontcheva <a href=\"https://theswissbay.ch/pdf/Books/Linguistics/Mega%20linguistics%20pack/Indo-European/Balto-Slavic/Bulgarian%20Grammar%2C%20Elementary%20%28Bontcheva%29.pdf\">Bulgarian Language - Grammar</a></div>"]},{"cell_type":"code","execution_count":null,"id":"d228196e-4193-4c5c-86ae-e9ac57b8051d","metadata":{"id":"d228196e-4193-4c5c-86ae-e9ac57b8051d","executionInfo":{"status":"aborted","timestamp":1737273623694,"user_tz":-120,"elapsed":8,"user":{"displayName":"Miroslava Ivanova","userId":"04041431527474936486"}}},"outputs":[],"source":[]}],"metadata":{"jpcodetoc-showcode":false,"jpcodetoc-showmarkdowntxt":false,"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"collapsed_sections":["11b9f655-d5ac-44f6-869a-559ce8bef07c","6c5876a5-24fd-458e-9863-dc29e362648b","cedf4369-b8bf-4a7c-b5bd-fc91d293836f","5da7bacc-3f9f-4646-bb36-e6d82d40e935","b10c7efd-bcc3-4a9d-aecf-c27b4b80d5c4","c8bd7763-94eb-4cc3-a8e2-247eb012e950","36bf6623-44ee-4504-b851-7d313ec210f3","b92bf35e-7202-4a3c-9dd9-0928723ccd3b","adb65785-ac38-4ce3-aa8d-88fa1d0533b1","983486ad-493d-4400-a528-9cd09ee26a4b","9dd393de-73e8-464f-a7eb-2043d09c619a","fc3b1d83-24d2-4ed1-b0f1-580480ab7913","22819899-bcfd-4ce1-8f1b-6cc21cdc3070","964ecbd8-e0cf-4be2-a2f6-b6fabbb32056"],"toc_visible":true,"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}