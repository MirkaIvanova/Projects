{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e20da0-2687-40f3-bc70-0ade766dc9f4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# !pip install category_encoders\n",
    "# !pip install colorama\n",
    "# !pip install imbalanced-learn\n",
    "# !pip install hyperopt\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ed8416-2696-4a02-9dbd-1709a99ed523",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression,\n",
    "    PassiveAggressiveClassifier,\n",
    "    Perceptron,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from src import custom_dataframe\n",
    "from src.chainable_plt import ChainablePlt\n",
    "from src.clean_categorical_columns import (\n",
    "    clean_field_of_study,\n",
    "    clean_location,\n",
    "    clean_university_names,\n",
    ")\n",
    "from src.create_evaluate_pipeline import (\n",
    "    display_top_models,\n",
    "    evaluate_parameter_grid,\n",
    "    predict_and_score,\n",
    "    print_scores,\n",
    ")\n",
    "from src.custom_metrics import calculate_fbeta_score\n",
    "from src.feature_engineering import add_partner_columns, create_equality_features\n",
    "from src.feature_selection import (\n",
    "    recursive_feature_elimination,\n",
    "    select_from_model,\n",
    "    select_k_best,\n",
    "    select_percentile,\n",
    ")\n",
    "from src.helpers import load_model_params\n",
    "from src.imputers import impute_columns_by_gender, questionnaire_impute_0\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a58946-265f-4c40-9b35-593db5108d58",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500) \n",
    "pd.set_option('display.max_info_columns', 500) \n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c57304-b417-4d38-9ba8-254934f6a84e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cplt = ChainablePlt(plt)\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b92f3a-ba65-4b0f-a3db-af23ea11938d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "# Predicting Dating Match Success Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7d550-15d6-4231-b902-98532d248242",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## Abstract:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2df71-51fa-43d4-a193-d96586850b0c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This project explores how machine learning can predict potential matches in a dating app, using data from a speed-dating experiment. The dataset includes a wide range of features, such as demographics, interests, self-perceptions, and partner preferences, collected from surveys and participant interactions. The goal was to build a predictive model capable of recommending matches based on user profiles, even before they meet in person. By employing extensive data preprocessing - including handling missing values, normalizing data, and engineering features—the dataset was prepared for binary classification. A custom evaluation metric was designed to prioritize precision, ensuring fewer mismatches while still fostering inclusivity. The project showcases the potential of personalized matchmaking systems while addressing the complexities of working with human preference data in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e208a-233b-456f-ade7-9f2af426e503",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 1. Purpose of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cf6574-bc46-428d-b4e4-20c4feda2644",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The goal of this project is to create a machine learning model for a dating application that can predict with which users a newly registered user will be a good match. When users sign up for the dating app, they will complete a survey answering questions about their demographics, location, interests, and what they value in a potential partner. The machine learning model developed using this speed dating dataset will then be able to analyze the user's survey responses and predict which other users on the app would be a good match for them. By uncovering the key factors that influence successful matches from the speed dating experiment data, the model can be applied to provide personalized match recommendations for users of the dating application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4ec92-310d-483d-a12b-54c66f7d7485",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 2. Load the data and a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8072b9-ed73-4e29-8c81-2dda044057d5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dating_data/02_Speed Dating Data.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9441645f-e183-4d9d-80a9-d79b61203a5a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 195)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be1e6c-0b66-4aaf-bd51-93a8684e1485",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "A quick look st the features in alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c596877a-de08-40b1-9584-2857cd4b1325",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 195 columns):\n",
      " #    Column    Non-Null Count  Dtype  \n",
      "---   ------    --------------  -----  \n",
      " 0    age       8283 non-null   float64\n",
      " 1    age_o     8274 non-null   float64\n",
      " 2    amb       7666 non-null   float64\n",
      " 3    amb1_1    8279 non-null   float64\n",
      " 4    amb1_2    7463 non-null   float64\n",
      " 5    amb1_3    3974 non-null   float64\n",
      " 6    amb1_s    4096 non-null   float64\n",
      " 7    amb2_1    8289 non-null   float64\n",
      " 8    amb2_2    5775 non-null   float64\n",
      " 9    amb2_3    2959 non-null   float64\n",
      " 10   amb3_1    8273 non-null   float64\n",
      " 11   amb3_2    7463 non-null   float64\n",
      " 12   amb3_3    3974 non-null   float64\n",
      " 13   amb3_s    4000 non-null   float64\n",
      " 14   amb4_1    6489 non-null   float64\n",
      " 15   amb4_2    5775 non-null   float64\n",
      " 16   amb4_3    2959 non-null   float64\n",
      " 17   amb5_1    4906 non-null   float64\n",
      " 18   amb5_2    4377 non-null   float64\n",
      " 19   amb5_3    2016 non-null   float64\n",
      " 20   amb7_2    1955 non-null   float64\n",
      " 21   amb7_3    2016 non-null   float64\n",
      " 22   amb_o     7656 non-null   float64\n",
      " 23   art       8299 non-null   float64\n",
      " 24   attr      8176 non-null   float64\n",
      " 25   attr1_1   8299 non-null   float64\n",
      " 26   attr1_2   7445 non-null   float64\n",
      " 27   attr1_3   3974 non-null   float64\n",
      " 28   attr1_s   4096 non-null   float64\n",
      " 29   attr2_1   8299 non-null   float64\n",
      " 30   attr2_2   5775 non-null   float64\n",
      " 31   attr2_3   2959 non-null   float64\n",
      " 32   attr3_1   8273 non-null   float64\n",
      " 33   attr3_2   7463 non-null   float64\n",
      " 34   attr3_3   3974 non-null   float64\n",
      " 35   attr3_s   4000 non-null   float64\n",
      " 36   attr4_1   6489 non-null   float64\n",
      " 37   attr4_2   5775 non-null   float64\n",
      " 38   attr4_3   2959 non-null   float64\n",
      " 39   attr5_1   4906 non-null   float64\n",
      " 40   attr5_2   4377 non-null   float64\n",
      " 41   attr5_3   2016 non-null   float64\n",
      " 42   attr7_2   1984 non-null   float64\n",
      " 43   attr7_3   2016 non-null   float64\n",
      " 44   attr_o    8166 non-null   float64\n",
      " 45   career    8289 non-null   object \n",
      " 46   career_c  8240 non-null   float64\n",
      " 47   clubbing  8299 non-null   float64\n",
      " 48   concerts  8299 non-null   float64\n",
      " 49   condtn    8378 non-null   int64  \n",
      " 50   date      8281 non-null   float64\n",
      " 51   date_3    3974 non-null   float64\n",
      " 52   dec       8378 non-null   int64  \n",
      " 53   dec_o     8378 non-null   int64  \n",
      " 54   dining    8299 non-null   float64\n",
      " 55   exercise  8299 non-null   float64\n",
      " 56   exphappy  8277 non-null   float64\n",
      " 57   expnum    1800 non-null   float64\n",
      " 58   field     8315 non-null   object \n",
      " 59   field_cd  8296 non-null   float64\n",
      " 60   from      8299 non-null   object \n",
      " 61   fun       8028 non-null   float64\n",
      " 62   fun1_1    8289 non-null   float64\n",
      " 63   fun1_2    7463 non-null   float64\n",
      " 64   fun1_3    3974 non-null   float64\n",
      " 65   fun1_s    4096 non-null   float64\n",
      " 66   fun2_1    8299 non-null   float64\n",
      " 67   fun2_2    5775 non-null   float64\n",
      " 68   fun2_3    2959 non-null   float64\n",
      " 69   fun3_1    8273 non-null   float64\n",
      " 70   fun3_2    7463 non-null   float64\n",
      " 71   fun3_3    3974 non-null   float64\n",
      " 72   fun3_s    4000 non-null   float64\n",
      " 73   fun4_1    6489 non-null   float64\n",
      " 74   fun4_2    5775 non-null   float64\n",
      " 75   fun4_3    2959 non-null   float64\n",
      " 76   fun5_1    4906 non-null   float64\n",
      " 77   fun5_2    4377 non-null   float64\n",
      " 78   fun5_3    2016 non-null   float64\n",
      " 79   fun7_2    1984 non-null   float64\n",
      " 80   fun7_3    2016 non-null   float64\n",
      " 81   fun_o     8018 non-null   float64\n",
      " 82   gaming    8299 non-null   float64\n",
      " 83   gender    8378 non-null   int64  \n",
      " 84   go_out    8299 non-null   float64\n",
      " 85   goal      8299 non-null   float64\n",
      " 86   hiking    8299 non-null   float64\n",
      " 87   id        8377 non-null   float64\n",
      " 88   idg       8378 non-null   int64  \n",
      " 89   iid       8378 non-null   int64  \n",
      " 90   imprace   8299 non-null   float64\n",
      " 91   imprelig  8299 non-null   float64\n",
      " 92   income    4279 non-null   object \n",
      " 93   int_corr  8220 non-null   float64\n",
      " 94   intel     8082 non-null   float64\n",
      " 95   intel1_1  8299 non-null   float64\n",
      " 96   intel1_2  7463 non-null   float64\n",
      " 97   intel1_3  3974 non-null   float64\n",
      " 98   intel1_s  4096 non-null   float64\n",
      " 99   intel2_1  8299 non-null   float64\n",
      " 100  intel2_2  5775 non-null   float64\n",
      " 101  intel2_3  2959 non-null   float64\n",
      " 102  intel3_1  8273 non-null   float64\n",
      " 103  intel3_2  7463 non-null   float64\n",
      " 104  intel3_3  3974 non-null   float64\n",
      " 105  intel3_s  4000 non-null   float64\n",
      " 106  intel4_1  6489 non-null   float64\n",
      " 107  intel4_2  5775 non-null   float64\n",
      " 108  intel4_3  2959 non-null   float64\n",
      " 109  intel5_1  4906 non-null   float64\n",
      " 110  intel5_2  4377 non-null   float64\n",
      " 111  intel5_3  2016 non-null   float64\n",
      " 112  intel7_2  1984 non-null   float64\n",
      " 113  intel7_3  2016 non-null   float64\n",
      " 114  intel_o   8072 non-null   float64\n",
      " 115  length    7463 non-null   float64\n",
      " 116  like      8138 non-null   float64\n",
      " 117  like_o    8128 non-null   float64\n",
      " 118  match     8378 non-null   int64  \n",
      " 119  match_es  7205 non-null   float64\n",
      " 120  met       8003 non-null   float64\n",
      " 121  met_o     7993 non-null   float64\n",
      " 122  mn_sat    3133 non-null   object \n",
      " 123  movies    8299 non-null   float64\n",
      " 124  museums   8299 non-null   float64\n",
      " 125  music     8299 non-null   float64\n",
      " 126  num_in_3  668 non-null    float64\n",
      " 127  numdat_2  7433 non-null   float64\n",
      " 128  numdat_3  1496 non-null   float64\n",
      " 129  order     8378 non-null   int64  \n",
      " 130  partner   8378 non-null   int64  \n",
      " 131  pf_o_amb  8271 non-null   float64\n",
      " 132  pf_o_att  8289 non-null   float64\n",
      " 133  pf_o_fun  8280 non-null   float64\n",
      " 134  pf_o_int  8289 non-null   float64\n",
      " 135  pf_o_sha  8249 non-null   float64\n",
      " 136  pf_o_sin  8289 non-null   float64\n",
      " 137  pid       8368 non-null   float64\n",
      " 138  positin1  6532 non-null   float64\n",
      " 139  position  8378 non-null   int64  \n",
      " 140  prob      8069 non-null   float64\n",
      " 141  prob_o    8060 non-null   float64\n",
      " 142  race      8315 non-null   float64\n",
      " 143  race_o    8305 non-null   float64\n",
      " 144  reading   8299 non-null   float64\n",
      " 145  round     8378 non-null   int64  \n",
      " 146  samerace  8378 non-null   int64  \n",
      " 147  satis_2   7463 non-null   float64\n",
      " 148  shar      7311 non-null   float64\n",
      " 149  shar1_1   8257 non-null   float64\n",
      " 150  shar1_2   7463 non-null   float64\n",
      " 151  shar1_3   3974 non-null   float64\n",
      " 152  shar1_s   4096 non-null   float64\n",
      " 153  shar2_1   8289 non-null   float64\n",
      " 154  shar2_2   5775 non-null   float64\n",
      " 155  shar2_3   2016 non-null   float64\n",
      " 156  shar4_1   6467 non-null   float64\n",
      " 157  shar4_2   5775 non-null   float64\n",
      " 158  shar4_3   2959 non-null   float64\n",
      " 159  shar7_2   1974 non-null   float64\n",
      " 160  shar7_3   2016 non-null   float64\n",
      " 161  shar_o    7302 non-null   float64\n",
      " 162  shopping  8299 non-null   float64\n",
      " 163  sinc      8101 non-null   float64\n",
      " 164  sinc1_1   8299 non-null   float64\n",
      " 165  sinc1_2   7463 non-null   float64\n",
      " 166  sinc1_3   3974 non-null   float64\n",
      " 167  sinc1_s   4096 non-null   float64\n",
      " 168  sinc2_1   8299 non-null   float64\n",
      " 169  sinc2_2   5775 non-null   float64\n",
      " 170  sinc2_3   2959 non-null   float64\n",
      " 171  sinc3_1   8273 non-null   float64\n",
      " 172  sinc3_2   7463 non-null   float64\n",
      " 173  sinc3_3   3974 non-null   float64\n",
      " 174  sinc3_s   4000 non-null   float64\n",
      " 175  sinc4_1   6489 non-null   float64\n",
      " 176  sinc4_2   5775 non-null   float64\n",
      " 177  sinc4_3   2959 non-null   float64\n",
      " 178  sinc5_1   4906 non-null   float64\n",
      " 179  sinc5_2   4377 non-null   float64\n",
      " 180  sinc5_3   2016 non-null   float64\n",
      " 181  sinc7_2   1955 non-null   float64\n",
      " 182  sinc7_3   2016 non-null   float64\n",
      " 183  sinc_o    8091 non-null   float64\n",
      " 184  sports    8299 non-null   float64\n",
      " 185  theater   8299 non-null   float64\n",
      " 186  them_cal  3974 non-null   float64\n",
      " 187  tuition   3583 non-null   object \n",
      " 188  tv        8299 non-null   float64\n",
      " 189  tvsports  8299 non-null   float64\n",
      " 190  undergra  4914 non-null   object \n",
      " 191  wave      8378 non-null   int64  \n",
      " 192  yoga      8299 non-null   float64\n",
      " 193  you_call  3974 non-null   float64\n",
      " 194  zipcode   7314 non-null   object \n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.custom.sinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2852c89-2817-42ed-9be9-d30f3ca90a51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Which columns have missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f124704-6811-4040-8e3b-59259e024718",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_in_3    7710\n",
       "numdat_3    6882\n",
       "expnum      6578\n",
       "sinc7_2     6423\n",
       "amb7_2      6423\n",
       "shar7_2     6404\n",
       "attr7_2     6394\n",
       "intel7_2    6394\n",
       "fun7_2      6394\n",
       "amb5_3      6362\n",
       "attr7_3     6362\n",
       "sinc7_3     6362\n",
       "intel7_3    6362\n",
       "fun7_3      6362\n",
       "amb7_3      6362\n",
       "shar7_3     6362\n",
       "shar2_3     6362\n",
       "attr5_3     6362\n",
       "sinc5_3     6362\n",
       "intel5_3    6362\n",
       "fun5_3      6362\n",
       "attr4_3     5419\n",
       "sinc4_3     5419\n",
       "intel4_3    5419\n",
       "fun4_3      5419\n",
       "amb4_3      5419\n",
       "shar4_3     5419\n",
       "attr2_3     5419\n",
       "sinc2_3     5419\n",
       "fun2_3      5419\n",
       "intel2_3    5419\n",
       "amb2_3      5419\n",
       "mn_sat      5245\n",
       "tuition     4795\n",
       "you_call    4404\n",
       "shar1_3     4404\n",
       "date_3      4404\n",
       "attr1_3     4404\n",
       "sinc1_3     4404\n",
       "intel1_3    4404\n",
       "fun1_3      4404\n",
       "amb1_3      4404\n",
       "attr3_3     4404\n",
       "sinc3_3     4404\n",
       "intel3_3    4404\n",
       "fun3_3      4404\n",
       "amb3_3      4404\n",
       "them_cal    4404\n",
       "fun3_s      4378\n",
       "intel3_s    4378\n",
       "sinc3_s     4378\n",
       "amb3_s      4378\n",
       "attr3_s     4378\n",
       "fun1_s      4282\n",
       "intel1_s    4282\n",
       "amb1_s      4282\n",
       "attr1_s     4282\n",
       "sinc1_s     4282\n",
       "shar1_s     4282\n",
       "income      4099\n",
       "attr5_2     4001\n",
       "sinc5_2     4001\n",
       "fun5_2      4001\n",
       "intel5_2    4001\n",
       "amb5_2      4001\n",
       "amb5_1      3472\n",
       "fun5_1      3472\n",
       "intel5_1    3472\n",
       "sinc5_1     3472\n",
       "attr5_1     3472\n",
       "undergra    3464\n",
       "sinc4_2     2603\n",
       "attr4_2     2603\n",
       "intel4_2    2603\n",
       "fun4_2      2603\n",
       "amb4_2      2603\n",
       "shar2_2     2603\n",
       "amb2_2      2603\n",
       "fun2_2      2603\n",
       "intel2_2    2603\n",
       "attr2_2     2603\n",
       "shar4_2     2603\n",
       "sinc2_2     2603\n",
       "shar4_1     1911\n",
       "sinc4_1     1889\n",
       "intel4_1    1889\n",
       "attr4_1     1889\n",
       "amb4_1      1889\n",
       "fun4_1      1889\n",
       "positin1    1846\n",
       "match_es    1173\n",
       "shar_o      1076\n",
       "shar        1067\n",
       "zipcode     1064\n",
       "numdat_2     945\n",
       "attr1_2      933\n",
       "fun1_2       915\n",
       "sinc3_2      915\n",
       "intel3_2     915\n",
       "fun3_2       915\n",
       "amb3_2       915\n",
       "attr3_2      915\n",
       "satis_2      915\n",
       "intel1_2     915\n",
       "length       915\n",
       "shar1_2      915\n",
       "amb1_2       915\n",
       "sinc1_2      915\n",
       "amb_o        722\n",
       "amb          712\n",
       "met_o        385\n",
       "met          375\n",
       "fun_o        360\n",
       "fun          350\n",
       "prob_o       318\n",
       "prob         309\n",
       "intel_o      306\n",
       "intel        296\n",
       "sinc_o       287\n",
       "sinc         277\n",
       "like_o       250\n",
       "like         240\n",
       "attr_o       212\n",
       "attr         202\n",
       "int_corr     158\n",
       "career_c     138\n",
       "pf_o_sha     129\n",
       "shar1_1      121\n",
       "pf_o_amb     107\n",
       "amb3_1       105\n",
       "attr3_1      105\n",
       "sinc3_1      105\n",
       "intel3_1     105\n",
       "fun3_1       105\n",
       "age_o        104\n",
       "exphappy     101\n",
       "amb1_1        99\n",
       "pf_o_fun      98\n",
       "date          97\n",
       "age           95\n",
       "fun1_1        89\n",
       "amb2_1        89\n",
       "shar2_1       89\n",
       "pf_o_att      89\n",
       "pf_o_int      89\n",
       "career        89\n",
       "pf_o_sin      89\n",
       "field_cd      82\n",
       "go_out        79\n",
       "fun2_1        79\n",
       "goal          79\n",
       "from          79\n",
       "tvsports      79\n",
       "imprelig      79\n",
       "imprace       79\n",
       "sports        79\n",
       "exercise      79\n",
       "intel2_1      79\n",
       "concerts      79\n",
       "sinc2_1       79\n",
       "attr2_1       79\n",
       "intel1_1      79\n",
       "sinc1_1       79\n",
       "attr1_1       79\n",
       "yoga          79\n",
       "dining        79\n",
       "music         79\n",
       "shopping      79\n",
       "movies        79\n",
       "theater       79\n",
       "reading       79\n",
       "clubbing      79\n",
       "gaming        79\n",
       "hiking        79\n",
       "art           79\n",
       "museums       79\n",
       "tv            79\n",
       "race_o        73\n",
       "race          63\n",
       "field         63\n",
       "pid           10\n",
       "id             1\n",
       "iid            0\n",
       "dec_o          0\n",
       "samerace       0\n",
       "match          0\n",
       "partner        0\n",
       "order          0\n",
       "position       0\n",
       "round          0\n",
       "wave           0\n",
       "condtn         0\n",
       "idg            0\n",
       "gender         0\n",
       "dec            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 200)\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f796d279-6997-4fce-9307-ef6d39452af5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42353214-2428-4b74-9f69-225e3a8b693c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 2.1 The data at a glance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c643aa-7ed3-4090-a311-c2397e3fb43b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We have a dataset of 8378 rows, 195 columns. Most of the features are numerical but there are some of type object.\n",
    "\n",
    "Some feature names are self explanatory but most have some nomenclature that needs investigation.\n",
    "\n",
    "There are features with 75% missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45077b-cd34-4afb-b302-a2035597b1fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 3. Description of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab886b85-d8cf-4f11-b483-f1d7feb314fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 3.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fb250-3ca7-4937-8dc7-5f38cfabf565",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This dataset was compiled by Columbia Business School professors Ray Fisman and Sheena Iyengar between 2002-2004 for their research paper [\"Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment\"](http://www.stat.columbia.edu/~gelman/stuff_for_blog/sheena.pdf) (published in The Quarterly Journal of Economics, 2006 <a href=\"#ref1\">[1]</a>. The experiment provides unique insights into modern dating behavior and mate selection preferences. The dataset and its companion key file live [here](http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/) <a href=\"#ref2\">[2]</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713683d5-3607-4f11-8c01-115442b83c7b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 3.2 Data Collection Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a840e5-8b2f-4ff2-a71d-ade20976b47f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The participants attended experimental speed dating events where they had four-minute \"first dates\" with other participants of the opposite sex. After each date, participants indicated whether they would like to see their date again. Participants rated their dates on six key attributes:\n",
    "  1. Attractiveness\n",
    "  2. Sincerity\n",
    "  3. Intelligence\n",
    "  4. Fun\n",
    "  5. Ambition\n",
    "  6. Shared Interests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96c77b-4181-490f-a34e-5d06d672143e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 3.3 Dataset Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12338c44-1bf1-418d-8a75-a2c97c95f003",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The dataset contains 195 features, including:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3f99c-dfb8-456c-8170-ae40cd999a54",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Demographic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8ffcc-268b-4cb6-81ff-518aa72e63e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "- Age-related features (age, age_o, d_age)\n",
    "- Field of study/work\n",
    "- Race and racial preferences\n",
    "- Wave (event identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fef4bd-a106-4313-a0ec-e766f8c59c2d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Personal Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3441a-74c0-4ff8-a4a7-bdd9f36f583b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "- Self-perception ratings\n",
    "- Dating habits\n",
    "- Lifestyle information\n",
    "- Interest-related features (shopping, music, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5eca6e-acf4-4b62-a243-9ebf0076df1b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Partner Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeda28a-9c9e-4685-b315-14acc0d3d158",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "- Expected partner attributes\n",
    "- Partner ratings\n",
    "- Importance weights for different characteristics\n",
    "- Match decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7759b-4345-40ae-b34d-1ee275344e77",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 3.4 Dataset values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50252f2a-1124-460f-a37d-a919b60146e8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Most of the features are numerical, capturing preferences on a scale from 1 to 10. Additionally, some preferences were recorded by asking participants to allocate 100 points among different options. A few features are categorical, for example:\n",
    "\n",
    "**Race:**\n",
    "- 1: Black/African American  \n",
    "- 2: European/Caucasian-American  \n",
    "- 3: Latino/Hispanic American  \n",
    "- 4: Asian/Pacific Islander/Asian-American  \n",
    "- 5: Native American  \n",
    "- 6: Other  \n",
    "\n",
    "**How frequently do you go on dates?**\n",
    "- 1: Several times a week  \n",
    "- 2: Twice a week  \n",
    "- 3: Once a week  \n",
    "- 4: Twice a month  \n",
    "- 5: Once a month  \n",
    "- 6: Several times a year  \n",
    "- 7: Almost never    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663381dc-3d14-49b9-a8a5-4b46a4ebf806",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 4. Getting to know the feature names and what they represent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28df59-72c0-420a-b740-b557e8a14cf8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The data key file explains that the data was collected at different time points. First, the participants completed an initial survey (at Time 1). Then, during the event, they filled out a scorecard (with features ending in \"_s\"). After the event, they completed two additional surveys (at Time 2 and Time 3). \n",
    "\n",
    "For this project, we only need the data that was collected at Time 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7102019-d106-4070-b94e-7b2598de36f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 4.1 Features describing the event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f660f75c-0d40-4131-8466-f9f42f54ff71",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<table border=\"1\" style=\"float: left;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>pertains to the subject</th>\n",
    "            <th>pertains to the partner</th>\n",
    "            <th>meaning of the feature</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>iid</td>\n",
    "            <td>pid</td>\n",
    "            <td>Unique identifier of subject/partner</td>\n",
    "        </tr>\n",
    "        <tr><td>id</td><td></td><td>subject number within wave</td></tr>\n",
    "        <tr><td>gender</td><td></td><td>Female=0, Male=1</td></tr>\n",
    "        <tr><td>idg</td><td></td><td>subject number within gender, group(id gender)</td></tr>\n",
    "        <tr><td>condtn</td><td></td><td>1=limited choice, 2=extensive choice</td></tr>\n",
    "        <tr><td>wave</td><td></td><td>see additional info</td></tr>\n",
    "        <tr><td>round</td><td></td><td>number of people that met in wave</td></tr>\n",
    "        <tr><td>position</td><td></td><td>station number where met partner</td></tr>\n",
    "        <tr><td>positin1</td><td></td><td>station number where started</td></tr>\n",
    "        <tr><td>order</td><td></td><td>the number of date that night when met partner</td></tr>\n",
    "        <tr><td></td><td>partner</td><td>partner’s id number the night of event (check whether exists)</td></tr>\n",
    "        <tr><td>match</td><td></td><td>1=yes, 0=no</td></tr>\n",
    "        <tr><td>int_corr</td><td></td><td>correlation between participant’s and partner’s ratings of interests in Time 1</td></tr>\n",
    "        <tr><td>samerace</td><td></td><td>participant and the partner were the same race. 1=yes, 0=no</td></tr>\n",
    "        <tr><td>exphappy</td><td></td><td>How happy do you expect to be with the people you meet during the speed-dating event? (1-10)</td></tr>\n",
    "        <tr><td>expnum</td><td></td><td>Out of the 20 people you will meet, how many do you expect will be interested in dating you?</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d2b4b-11b1-4752-93c2-42ca429b56b1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 4.2 Signup survey (Time 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bb743-1632-4364-8998-1bb4d4184a62",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<table border=\"1\" style=\"float: left;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>pertains to the subject</th>\n",
    "            <th>pertains to the partner</th>\n",
    "            <th>meaning of the feature</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "<tr><td></td><td></td><td><b><br>Bio</b>                                                                                      </td></tr>\n",
    "<tr><td>age        </td><td>age_o</td><td>Age of participant                                                                       </td></tr>    \n",
    "<tr><td>race       </td><td>race_o</td><td>Race (category 1-6)                                                                      </td></tr>                                  \n",
    "<tr><td>field\t   </td><td></td><td>Field of study                                                                           </td></tr>       \n",
    "<tr><td>field_cd   </td><td></td><td>field coded (1-18, see details)                                                          </td></tr>                                           \n",
    "<tr><td>undergra   </td><td></td><td>school attended for undergraduate degree                                                 </td></tr>                                            \n",
    "<tr><td>mn_sat \t   </td><td></td><td>Median SAT score for the undergraduate institution where attended.                       </td></tr>                  \n",
    "<tr><td>tuition    </td><td></td><td>Tuition listed for each response to undergrad                                            </td></tr>                                       \n",
    "<tr><td>imprace    </td><td></td><td>How important is it to you that your date be of the same racial/ethnic background? (1-10)</td></tr>\n",
    "<tr><td>imprelig   </td><td></td><td>How important is it to you that your date be of the same religious background? (1-10)    </td></tr>  \n",
    "<tr><td>from       </td><td></td><td>Where are you from originally?                             </td></tr>                             \n",
    "<tr><td>zipcode    </td><td></td><td>What was the zip code of the area where you grew up?       </td></tr>                                   \n",
    "<tr><td>income     </td><td></td><td>Median household income based on zipcode                   </td></tr>                                              \n",
    "<tr><td>goal       </td><td></td><td>What is your primary goal in participating in this event?  </td></tr>                             \n",
    "<tr><td>date       </td><td></td><td>In general, how frequently do you go on dates?             </td></tr>                                      \n",
    "<tr><td>go_out     </td><td></td><td>How often do you go out (not necessarily on dates)?        </td></tr>                                 \n",
    "<tr><td>career     </td><td></td><td>What is your intended career?                              </td></tr>                                                       \n",
    "<tr><td>career_c   </td><td></td><td>Intended career coded                                      </td></tr>                                                                  \n",
    "<tr><td></td><td></td><td><b><br>How interested are you in this? (1-10)?</b></td></tr>\n",
    "<tr><td>sports     </td><td></td><td>Playing sports/ athletics   </td></tr>                                 \n",
    "<tr><td>tvsports   </td><td></td><td>Watching sports             </td></tr>                                          \n",
    "<tr><td>exercise   </td><td></td><td>Body building/exercising    </td></tr>                                \n",
    "<tr><td>dining     </td><td></td><td>Dining out                  </td></tr>                                  \n",
    "<tr><td>museums    </td><td></td><td>Museums/galleries           </td></tr>                                  \n",
    "<tr><td>art        </td><td></td><td>Art                         </td></tr>                                  \n",
    "<tr><td>hiking     </td><td></td><td>Hiking/camping              </td></tr>                                  \n",
    "<tr><td>gaming     </td><td></td><td>Gaming                      </td></tr>                                     \n",
    "<tr><td>clubbing   </td><td></td><td>Dancing/clubbing            </td></tr>                                   \n",
    "<tr><td>reading    </td><td></td><td>Reading                     </td></tr>                                    \n",
    "<tr><td>tv         </td><td></td><td>Watching TV                 </td></tr>                                          \n",
    "<tr><td>theater    </td><td></td><td>Theater                     </td></tr>                                           \n",
    "<tr><td>movies     </td><td></td><td>Movies                      </td></tr>                                         \n",
    "<tr><td>concerts   </td><td></td><td>Going to concerts           </td></tr>                                        \n",
    "<tr><td>music      </td><td></td><td>Music                       </td></tr>                                        \n",
    "<tr><td>shopping   </td><td></td><td>Shopping                    </td></tr>                                       \n",
    "<tr><td>yoga       </td><td></td><td>Yoga/meditation             </td></tr>                                        \n",
    "<tr><td></td><td></td><td><b><br>What you look for in the opposite sex (by waves)?</b></td></tr>\n",
    "<tr><td>attr1_1    </td><td></td><td>Attractive    </td></tr>                   \n",
    "<tr><td>sinc1_1    </td><td></td><td>Sincere       </td></tr>                   \n",
    "<tr><td>intel1_1   </td><td></td><td>Intelligent   </td></tr>                  \n",
    "<tr><td>fun1_1     </td><td></td><td>Fun           </td></tr>                   \n",
    "<tr><td>amb1_1     </td><td></td><td>Ambitious     </td></tr>                   \n",
    "<tr><td>shar1_1    </td><td></td><td>Has shared interests/hobbies </td></tr>   \n",
    "<tr><td></td><td></td><td><b><br>What do you think the opposite sex looks for in a date (by waves)?</b></td></tr>\n",
    "<tr><td>attr2_1    </td><td></td><td>Attractive     </td></tr>                    \n",
    "<tr><td>sinc2_1    </td><td></td><td>Sincere        </td></tr>                     \n",
    "<tr><td>intel2_1   </td><td></td><td>Intelligent    </td></tr>                    \n",
    "<tr><td>fun2_1     </td><td></td><td>Fun            </td></tr>                    \n",
    "<tr><td>amb2_1     </td><td></td><td>Ambitious      </td></tr>                    \n",
    "<tr><td>shar2_1    </td><td></td><td>Has shared interests/hobbies </td></tr>     \n",
    "<tr><td></td><td></td><td><b><br>How do you think you measure up? (1-10)</b></td></tr>\t\n",
    "<tr><td>attr3_1    </td><td></td><td>Attractive     </td></tr>                     \n",
    "<tr><td>sinc3_1    </td><td></td><td>Sincere        </td></tr>                                           \n",
    "<tr><td>intel3_1   </td><td></td><td>Intelligent    </td></tr>                                             \n",
    "<tr><td>fun3_1     </td><td></td><td>Fun            </td></tr>                                       \n",
    "<tr><td>amb3_1     </td><td></td><td>Ambitious      </td></tr>                       \n",
    "<tr><td></td><td></td><td><b><br>What you think MOST of others look for in a date (by waves)?</b></td></tr>\n",
    "<tr><td>attr4_1    </td><td></td><td>Attractive    </td></tr>                    \n",
    "<tr><td>sinc4_1    </td><td></td><td>Sincere       </td></tr>                    \n",
    "<tr><td>intel4_1   </td><td></td><td>Intelligent   </td></tr>                    \n",
    "<tr><td>fun4_1     </td><td></td><td>Fun           </td></tr>                    \n",
    "<tr><td>amb4_1     </td><td></td><td>Ambitious     </td></tr>                   \n",
    "<tr><td>shar4_1    </td><td></td><td>Shared Interests/Hobbies </td></tr>        \n",
    "<tr><td></td><td></td><td><b><br>How do you think others perceive you? (1-10)?</b></td></tr>\n",
    "<tr><td>attr5_1    </td><td></td><td>Attractive   </td></tr>                            \n",
    "<tr><td>sinc5_1    </td><td></td><td>Sincere      </td></tr>                         \n",
    "<tr><td>intel5_1   </td><td></td><td>Intelligent  </td></tr>                           \n",
    "<tr><td>fun5_1     </td><td></td><td>Fun          </td></tr>                    \n",
    "<tr><td>amb5_1     </td><td></td><td>Ambitious    </td></tr>     \n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58354ad2-337b-4699-8442-783046648e05",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 4.3 Scorecard (filled during the event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3cb83f-8048-42c9-a8ce-8be5a43d16cb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<table border=\"1\" style=\"float: left;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>pertains to the subject</th>\n",
    "            <th>pertains to the partner</th>\n",
    "            <th>meaning of the feature</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>dec</td>\n",
    "            <td>dec_o</td>\n",
    "            <td>Decision per date id 1=yes 0=no</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td><b><br>Rating by partner the night of the event: (1-10):</b></td>\n",
    "        </tr>\n",
    "        <tr><td>attr</td><td>attr_o</td><td>Attractive</td></tr>\n",
    "        <tr><td>sinc</td><td>sinc_o</td><td>Sincere</td></tr>\n",
    "        <tr><td>intel</td><td>intel_o</td><td>Intelligent</td></tr>\n",
    "        <tr><td>fun</td><td>fun_o</td><td>Fun</td></tr>\n",
    "        <tr><td>amb</td><td>amb_o</td><td>Ambitious</td></tr>\n",
    "        <tr><td>shar</td><td>shar_o</td><td>Shared Interests</td></tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td><b><br>Survey during the event:</b></td>\n",
    "        </tr>\n",
    "        <tr><td>like</td><td>like_o</td><td>How much do you like this person? (1-10)</td></tr>\n",
    "        <tr><td>prob</td><td>prob_o</td><td>How probable do you think it is that this person will say yes for you? (1-10)</td></tr>\n",
    "        <tr><td>met</td><td>met_o</td><td>Have you met this person before? 1=yes, 2=no</td></tr>\n",
    "        <tr><td>match_es</td><td></td><td>How many matches do you estimate you will get (both check Yes to decision)</td></tr>\n",
    "        <tr>\n",
    "            <td></td>\n",
    "            <td></td>\n",
    "            <td><b><br>Rate the importance of this attribute in a potential date (1-10):</b></td>\n",
    "        </tr>\n",
    "        <tr><td>attr1_s</td><td>pf_o_att</td><td>Attractive</td></tr>\n",
    "        <tr><td>sinc1_s</td><td>pf_o_sin</td><td>Sincere</td></tr>\n",
    "        <tr><td>intel1_s</td><td>pf_o_int</td><td>Intelligent</td></tr>\n",
    "        <tr><td>fun1_s</td><td>pf_o_fun</td><td>Fun</td></tr>\n",
    "        <tr><td>amb1_s</td><td>pf_o_amb</td><td>Ambitious</td></tr>\n",
    "        <tr><td>shar1_s</td><td>pf_o_sha</td><td>Shared Interests</td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>Rate your opinion of your own attributes (1-10):</b></td></tr>\n",
    "        <tr><td>attr3_s</td> <td></td><td>Attractive</td></tr>\n",
    "        <tr><td>sinc3_s</td> <td></td><td>Sincere</td></tr>\n",
    "        <tr><td>intel3_s</td><td></td><td>Intelligent</td></tr>\n",
    "        <tr><td>fun3_s</td>  <td></td><td>Fun</td></tr>\n",
    "        <tr><td>amb3_s</td>  <td></td><td>Ambitious</td></tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521ff01-0e13-47c1-a3c0-98d62c07a51b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 4.4 First followup survey (Time 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685c4dd-d5a0-4a9a-890c-581df268cc39",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<table border=\"1\" style=\"float: left;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>pertains to the subject</th>\n",
    "            <th>pertains to the partner</th>\n",
    "            <th>meaning of the feature</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr><td></td><td></td><td><b><br>General questions:</b></td></tr>\n",
    "        <tr><td>satis_2  </td><td></td><td>How satisfied were you with the people you met? (1-10)                      </td></tr> \n",
    "        <tr><td>length   </td><td></td><td>Four minutes is: Too little=1, Too much=2, Just Right=3                     </td></tr> \n",
    "        <tr><td>numdat_2 </td><td></td><td>The number of Speed Dates you had was: Too few=1, Too many=2, Just right=3  </td></tr> \n",
    "        <tr><td></td><td></td><td><b><br>What you look for in the opposite sex? (by waves)</b></td></tr>\t\n",
    "        <tr><td>attr1_2  </td><td></td><td>Attractive         </td></tr>  \n",
    "        <tr><td>sinc1_2  </td><td></td><td>Sincere            </td></tr>  \n",
    "        <tr><td>intel1_2 </td><td></td><td>Intelligent        </td></tr>  \n",
    "        <tr><td>fun1_2   </td><td></td><td>Fun                </td></tr>  \n",
    "        <tr><td>amb1_2   </td><td></td><td>Ambitious          </td></tr>  \n",
    "        <tr><td>shar1_2  </td><td></td><td>Shared interests   </td></tr>  \n",
    "        <tr><td></td><td></td><td><b><br>What do you think the opposite sex looks for in a date? (by waves)</b></td></tr>\n",
    "        <tr><td>attr2_2  </td><td></td><td>Attractive         </td></tr>  \n",
    "        <tr><td>sinc2_2  </td><td></td><td>Sincere            </td></tr>  \n",
    "        <tr><td>intel2_2 </td><td></td><td>Intelligent        </td></tr>  \n",
    "        <tr><td>fun2_2   </td><td></td><td>Fun                </td></tr>  \n",
    "        <tr><td>amb2_2   </td><td></td><td>Ambitious          </td></tr>  \n",
    "        <tr><td>shar2_2  </td><td></td><td>Shared interests   </td></tr>  \n",
    "        <tr><td></td><td></td><td><b><br>How do you think you measure up? (1-10)</b></td></tr>\t   \n",
    "        <tr><td>attr3_2  </td><td></td><td>Attractive   </td></tr>        \n",
    "        <tr><td>sinc3_2  </td><td></td><td>Sincere      </td></tr>        \n",
    "        <tr><td>intel3_2 </td><td></td><td>Intelligent  </td></tr>        \n",
    "        <tr><td>fun3_2   </td><td></td><td>Fun          </td></tr>        \n",
    "        <tr><td>amb3_2   </td><td></td><td>Ambitious    </td></tr>        \n",
    "        <tr><td></td><td></td><td><b><br>What you think MOST of others look for in a date? (distribute 100 points)\t</b></td></tr>\t\n",
    "        <tr><td>attr4_2  </td><td></td><td>Attractive        </td></tr>   \n",
    "        <tr><td>sinc4_2  </td><td></td><td>Sincere           </td></tr>   \n",
    "        <tr><td>intel4_2 </td><td></td><td>Intelligent       </td></tr>   \n",
    "        <tr><td>fun4_2   </td><td></td><td>Fun               </td></tr>   \n",
    "        <tr><td>amb4_2   </td><td></td><td>Ambitious         </td></tr>   \n",
    "        <tr><td>shar4_2  </td><td></td><td>Shared Interests  </td></tr>   \n",
    "        <tr><td></td><td></td><td><b><br>How do you think others perceive you? (1-10)</b></td></tr>\t\t\n",
    "        <tr><td>attr5_2  </td><td></td><td>Attractive          </td></tr> \n",
    "        <tr><td>sinc5_2  </td><td></td><td>Sincere             </td></tr> \n",
    "        <tr><td>intel5_2 </td><td></td><td>Intelligent         </td></tr> \n",
    "        <tr><td>fun5_2   </td><td></td><td>Fun                 </td></tr> \n",
    "        <tr><td>amb5_2   </td><td></td><td>Ambitious           </td></tr> \n",
    "        <tr><td></td><td></td><td><b><br>What is the importance of these attributes in your decisions (distribute 100 points)</b></td></tr>\t\t\n",
    "        <tr><td>attr7_2  </td><td></td><td>Attractive          </td></tr> \n",
    "        <tr><td>sinc7_2  </td><td></td><td>Sincere             </td></tr> \n",
    "        <tr><td>intel7_2 </td><td></td><td>Intelligent         </td></tr> \n",
    "        <tr><td>fun7_2   </td><td></td><td>Fun                 </td></tr> \n",
    "        <tr><td>amb7_2   </td><td></td><td>Ambitious           </td></tr> \n",
    "        <tr><td>shar7_2  </td><td></td><td>Shared interests    </td></tr>     \n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1daf2-1b91-433f-a88c-345ca6ba1765",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 4.5 Second followup survey (Time 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27fe57c-ca6f-4117-9418-6ef1bab5faf8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<table border=\"1\" style=\"float: left;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>pertains to the subject</th>\n",
    "            <th>pertains to the partner</th>\n",
    "            <th>meaning of the feature</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr><td></td><td></td><td><b><br>General questions:</b></td></tr>\t\n",
    "        <tr><td>you_call   </td><td></td><td>Of the matches that you received how many have you contacted?                                       </td></tr>\n",
    "        <tr><td>them_cal   </td><td></td><td>Of the matches that you received how many have contacted you?                                       </td></tr>\n",
    "        <tr><td>date_3     </td><td></td><td>Have you been on a date with any of your matches? Yes=1 No=2                                        </td></tr>\n",
    "        <tr><td>numdat_3   </td><td></td><td>If you have been on at least one date how many of your matches have you been on a date with so far? </td></tr>\n",
    "        <tr><td>num_in_3   </td><td></td><td>???                                                                                                 </td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>What you look for in the opposite sex? (1-10)</b></td></tr>\t\n",
    "        <tr><td>attr1_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc1_3    </td><td></td><td>Sincere                  </td></tr>\n",
    "        <tr><td>intel1_3   </td><td></td><td>Intelligent              </td></tr> \n",
    "        <tr><td>fun1_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb1_3     </td><td></td><td>Ambitious                </td></tr>\n",
    "        <tr><td>shar1_3    </td><td></td><td>Shared interests         </td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>What do you think the opposite sex looks for in a date? (1-10)</b></td></tr>\t\n",
    "        <tr><td>attr2_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc2_3    </td><td></td><td>Sincere                  </td></tr>\n",
    "        <tr><td>intel2_3   </td><td></td><td>Intelligent              </td></tr>\n",
    "        <tr><td>fun2_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb2_3     </td><td></td><td>Ambitious                </td></tr> \n",
    "        <tr><td>shar2_3    </td><td></td><td>Shared interests         </td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>How do you think you measure up? (1-10)</b></td></tr>\t\t\n",
    "        <tr><td>attr3_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc3_3    </td><td></td><td>Sincere                  </td></tr>\n",
    "        <tr><td>intel3_3   </td><td></td><td>Intelligent              </td></tr>\n",
    "        <tr><td>fun3_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb3_3     </td><td></td><td>Ambitious                </td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>What you think MOST of others look for in a date? (distribute 100 points)</b></td></tr>\t\n",
    "        <tr><td>attr4_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc4_3    </td><td></td><td>Sincere                  </td></tr>   \n",
    "        <tr><td>intel4_3   </td><td></td><td>Intelligent              </td></tr>       \n",
    "        <tr><td>fun4_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb4_3     </td><td></td><td>Ambitious                </td></tr>     \n",
    "        <tr><td>shar4_3    </td><td></td><td>Shared interests         </td></tr>            \n",
    "        <tr><td></td><td></td><td><b><br>How do you think others perceive you? (1-10)</b></td></tr>\t\n",
    "        <tr><td>attr5_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc5_3    </td><td></td><td>Sincere                  </td></tr>\n",
    "        <tr><td>intel5_3   </td><td></td><td>Intelligent              </td></tr>\n",
    "        <tr><td>fun5_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb5_3     </td><td></td><td>Ambitious                </td></tr>\n",
    "        <tr><td></td><td></td><td><b><br>What is the importance of these attributes in your decisions (distribute 100 points)</b></td></tr>\t\t\n",
    "        <tr><td>attr7_3    </td><td></td><td>Attractive               </td></tr>\n",
    "        <tr><td>sinc7_3    </td><td></td><td>Sincere                  </td></tr>  \n",
    "        <tr><td>intel7_3   </td><td></td><td>Intelligent              </td></tr>   \n",
    "        <tr><td>fun7_3     </td><td></td><td>Fun                      </td></tr>\n",
    "        <tr><td>amb7_3     </td><td></td><td>Ambitious                </td></tr>    \n",
    "        <tr><td>shar7_3    </td><td></td><td>Shared interests         </td></tr>                       \n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80794938-561b-4b47-8b38-68097584c6f5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 5. Initial drop of columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a104446-7020-407b-b03d-e21345aaf287",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Since this speed dating dataset includes information gathered both from an initial questionnaire as well as the subsequent in-person speed dating events, certain features in the dataset are not directly applicable to the dating app use case. For the dating app, the goal is to predict compatible matches between users before they have actually met each other. As such, we will need to exclude any features from the dataset that pertain specifically to the details and outcomes of the speed dating interactions, as that would be considered \"future\" data that users of the dating app would not have access to when the model makes its predictions. By focusing the model only on the user profile information and preferences collected via the initial questionnaire, we can develop a matchmaking system that can provide relevant match recommendations to dating app users before they connect in person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ede396-5f7d-4bf1-a726-e71a26e025ac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 5.1 Remove columns representing future data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aa38d-0f4b-44b6-9aeb-364b8054c1a0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Future data refers to any data involving a physical meeting between two individuals. We'll exclude it from the dataset because our goal is for the model to make predictions based solely on users' questionnaire responses.\n",
    "\n",
    "First we need to remove columns that describe the event itself, or the participants' answers about the event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5068919f-50d7-4172-94a4-f6b1ba3e3611",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Event organizational details\n",
    "event_details    = [\"id\", \"idg\", \"round\", \"order\", \"condtn\", \"partner\", \"exphappy\", \"expnum\", \"match_es\", \"match\", 'positin1', 'position',]\n",
    "followup_time2   = ['satis_2', 'length', 'numdat_2']\n",
    "followup_time3   = ['you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3']\n",
    "partners_prefs_0 = [\"pf_o_att\", \"pf_o_sin\", \"pf_o_int\", \"pf_o_fun\", \"pf_o_amb\", \"pf_o_sha\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d52813-24a6-4e88-b020-341e07c99b63",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We will also remove the participants' ratings of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9237c83-2798-4502-8a3b-3d7636c52ca9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Rate each date's attributes on a scale of 1-10 (scorecard)\n",
    "attributes_per_date_s = ['attr', 'sinc', 'intel', 'fun', 'amb', 'shar']\n",
    "\n",
    "# Rating and decision by partner the night of the event (partner's answers on the scorecard)\n",
    "rating_by_partner_s = ['attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513e2dc-ed43-4594-845e-1c785bd71659",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Also remove answers from the scorecard which the participants filled after the event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8f6980-96a6-4911-9d5a-1d14f1e5878d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "date_likeability_s  = [\"like\", \"prob\", \"met\"]\n",
    "question1_scorecard = [\"amb1_s\", \"attr1_s\", \"sinc1_s\", \"fun1_s\", \"intel1_s\", \"shar1_s\"]\n",
    "question3_scorecard = [\"amb3_s\", \"attr3_s\", \"sinc3_s\", \"fun3_s\", \"intel3_s\"]\n",
    "subjects_likeability_to_date_2 = [\"like_o\", \"prob_o\", \"met_o\", \"dec_o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf028346-405a-4f9d-aa5e-728de9dba0ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "These are two questionnaires asked at time 2 and time 3, both after the event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5bda344-11ea-4625-85dd-ed984507af1d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# How much the subject likes the partner\n",
    "question1_time2 = [\"amb1_2\", \"attr1_2\", \"fun1_2\", \"intel1_2\", \"shar1_2\", \"sinc1_2\"]\n",
    "question2_time2 = [\"amb2_2\", \"attr2_2\", \"fun2_2\", \"intel2_2\", \"shar2_2\", \"sinc2_2\"]\n",
    "question3_time2 = [\"amb3_2\", \"attr3_2\", \"fun3_2\", \"intel3_2\", \"sinc3_2\"]\n",
    "question4_time2 = [\"amb4_2\", \"attr4_2\", \"fun4_2\", \"intel4_2\", \"sinc4_2\", \"shar4_2\"]\n",
    "question5_time2 = [\"amb5_2\", \"attr5_2\", \"fun5_2\", \"intel5_2\", \"sinc5_2\"]\n",
    "question7_time2 = [\"amb7_2\", \"attr7_2\", \"fun7_2\", \"intel7_2\", \"shar7_2\", \"sinc7_2\"]\n",
    "\n",
    "question1_time3 = [\"amb1_3\", \"attr1_3\", \"fun1_3\", \"intel1_3\", \"shar1_3\", \"sinc1_3\"]\n",
    "question2_time3 = [\"amb2_3\", \"attr2_3\", \"fun2_3\", \"intel2_3\", \"shar2_3\", \"sinc2_3\"]\n",
    "question3_time3 = [\"amb3_3\", \"attr3_3\", \"fun3_3\", \"intel3_3\", \"sinc3_3\"]\n",
    "question4_time3 = [\"amb4_3\", \"attr4_3\", \"fun4_3\", \"intel4_3\", \"sinc4_3\", \"shar4_3\"]\n",
    "question5_time3 = [\"amb5_3\", \"attr5_3\", \"fun5_3\", \"intel5_3\", \"sinc5_3\"]\n",
    "question7_time3 = [\"amb7_3\", \"attr7_3\", \"fun7_3\", \"intel7_3\", \"shar7_3\", \"sinc7_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77798754-5ff1-4ca6-a583-ca7240669ac0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "And some other non-relevant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df578f8f-86b8-4732-a516-adacd9577bae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "other = [\"race_o\", \"age_o\"]\n",
    "demographics = [\"career_c\", \"zipcode\", \"tuition\", \"mn_sat\", \"income\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669cbdb-f932-4086-b808-e8c7a72f5dd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Collect all features mentioned above in a single variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c75e7ba-ca89-4a46-9078-6bf0d2667222",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_future_data = event_details + demographics + date_likeability_s + subjects_likeability_to_date_2 + partners_prefs_0 + other\n",
    "cols_future_data = cols_future_data + followup_time2 + followup_time3 \n",
    "cols_future_data = cols_future_data + question1_time2 + question2_time2 + question3_time2 + question4_time2 + question5_time2 + question7_time2 \n",
    "cols_future_data = cols_future_data + question1_time3 + question2_time3 + question3_time3 + question4_time3 + question5_time3 + question7_time3\n",
    "cols_future_data = cols_future_data + question1_scorecard + question3_scorecard + rating_by_partner_s + attributes_per_date_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f044943-ada1-44f8-a99c-8f3e059dcdd2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "And delete all the future data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0b2a29-45b3-4e7a-9fc7-2407c83d7231",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "features_before = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8a06a1-322c-4375-a9b7-a520a2f47e9a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(cols_future_data, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e998a6a2-130d-4cd6-a9ba-8f2e68d1af05",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 131 features with future data.\n"
     ]
    }
   ],
   "source": [
    "features_after = df.shape[1]\n",
    "print(f\"Removed {features_before - features_after} features with future data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa5204-8bb8-46c0-ba5a-aed9796d391d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 5.2 Drop rows where _pid_ is NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92920a3-f192-4138-bed6-6051949611f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The features _iid_ and _pid_ uniquely identify the subject and their partner, respectively. Furthermore, each partner's _pid_ is also present in the dataset as an _iid_. This means that for each date, there are two rows of data - one for the subject and one for their partner. It's crucial that if a _pid_ (partner) is referenced on one row, that _pid_ must exist as an _iid_ on another row. This ensures we have the complete data for a date between two people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60ab6326-e9dd-4bc9-b9b5-a799aa72aa5e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>pid</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  pid  wave  gender\n",
       "1755  122  NaN     5       1\n",
       "1765  123  NaN     5       1\n",
       "1775  124  NaN     5       1\n",
       "1785  125  NaN     5       1\n",
       "1795  126  NaN     5       1\n",
       "1805  127  NaN     5       1\n",
       "1815  128  NaN     5       1\n",
       "1825  129  NaN     5       1\n",
       "1835  130  NaN     5       1\n",
       "1845  131  NaN     5       1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pid.isna()][['iid', 'pid', 'wave', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55977793-1bcd-4730-bf42-64c790cc91ff",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We see 10 missing _pids_ and all of them are in wave 5. The dataset's documentation states that in each wave there were equal number of men and women. (Actually, the dates in this experiment were only between men and women). \n",
    "\n",
    "If we check the ratio of men/women in wave 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dbe19fc-867c-424a-8607-7ee208836b09",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "1    100\n",
       "0     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.wave == 5].gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e15cc4-9a1f-45dd-a49b-bd96b3a2d7ed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "...we see a mismatch of exactly 10 pids (partners). If we delete the 10 rows with missing pids we will get an equal distribution of men and women in wave 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f7d0c-d002-4c16-bf49-9a73cc720cc3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Furthermore, we can try to make an educated guess which was the partner of these 10 subjects if we inspect all _iids_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a55444c-9f8c-4385-8c82-43e06e154b7a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
       "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
       "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
       "       275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
       "       288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
       "       301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
       "       314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
       "       327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
       "       340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
       "       353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "       366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "       379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
       "       405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
       "       418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430,\n",
       "       431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,\n",
       "       444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
       "       457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
       "       470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
       "       483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
       "       496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508,\n",
       "       509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521,\n",
       "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
       "       535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547,\n",
       "       548, 549, 550, 551, 552], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iid.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c45b9-8b92-4ea2-973f-2ab02b798c7b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The _iids_ appear to be sequential with no missing values, except for iid 118. This suggests that the partner of the 10 subjects with a missing _pid_ was likely the person with _iid_ 118."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594ee928-380b-46f7-a4fb-d2ae4cd5d2ea",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# delete the rows where pid is NaN to make the data consistent\n",
    "df = df.dropna(subset=['pid'])\n",
    "df['pid'] = df['pid'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d45f0d-57fa-4a0c-8595-b66c04a8b4b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "🤔 Separately, and unrelated to the model implemented in this project, our personal speculation is that the surveys were originally conducted on printed paper forms, as this was during the 2002-2004 timeframe, and the form for person with _iid_ 118 was misplaced before the data was digitized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eab7bd-0b33-49cc-89ac-e125b6d74da8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 5.3 Drop rows with unanswered interests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217d449-7d44-4d60-8c96-58a2ce6d095f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Let's check the missing values in the columns representing the subject's interests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279f05aa-267c-445b-a1e4-d3fee756104c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_interests = ['music', 'exercise', 'dining', 'tv', 'tvsports', 'sports', 'shopping', 'yoga', 'gaming', \n",
    "                  'reading', 'theater', 'hiking', 'art', 'museums', 'clubbing', 'concerts', 'movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abe5b958-7399-4311-90f6-412c8ac29110",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "music       79\n",
       "exercise    79\n",
       "dining      79\n",
       "tv          79\n",
       "tvsports    79\n",
       "sports      79\n",
       "shopping    79\n",
       "yoga        79\n",
       "gaming      79\n",
       "reading     79\n",
       "theater     79\n",
       "hiking      79\n",
       "art         79\n",
       "museums     79\n",
       "clubbing    79\n",
       "concerts    79\n",
       "movies      79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_interests].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9e0b4-f935-4da7-8b97-947fa6749c1b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "There are 79 rows with missing values for interests, and what’s really interesting is that the same questions are missing in all of them. It looks like these people skipped the entire section. But we need to keep in mind, 79 rows doesn’t equate to 79 different people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c8253db-b8fc-4d35-8644-4f2c7bed91f7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 participants did not fill the interests questions.\n"
     ]
    }
   ],
   "source": [
    "# how many people did not answer the interests questions\n",
    "question_dodgers = df[df.yoga.isna()][['iid'] + cols_interests].iid.unique()\n",
    "print(f\"{len(question_dodgers)} participants did not fill the interests questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096feec4-e346-4014-a4b8-89c9403bf8f2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Seven individuals (each with a unique _iid_), didn’t respond to those questions for some reason. It’s worth checking to see if there are other questions they left unanswered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9985ec5b-de2a-4b98-bf37-843e842e119c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 individuals left [54 58] questions out of 64 unanswered.\n"
     ]
    }
   ],
   "source": [
    "# count how many values per row are NA\n",
    "df_interests = df[df.yoga.isna()].copy()\n",
    "df_interests['na_count'] = df_interests.isna().sum(axis=1)\n",
    "\n",
    "print(f\"7 individuals left {df_interests['na_count'].unique()} questions out of {df.shape[1]} unanswered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5d39c-863e-4b6a-94a3-aaea4b37c99b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Proceed with removing the rows with high percentage of missing values. Additionally, ensure the removal of rows corresponding to the partners of these participants, even if their data is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaa1fe49-8e41-450e-a49e-3638955d0caa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "rows_before = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52ff6879-488b-46f7-89b9-5a2626b427df",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "rows_to_delete = df[df[cols_interests].isna().all(axis=1)][['iid', 'pid']].apply(tuple, axis=1).tolist()\n",
    "partner_rows_to_delete = [(pid, iid) for iid, pid in rows_to_delete]           # Identify the partner rows to delete (where 'iid' and 'pid' are swapped)\n",
    "\n",
    "df = df[~df[['iid', 'pid']].apply(tuple, axis=1).isin(rows_to_delete)]         # Delete these rows\n",
    "df = df[~df[['iid', 'pid']].apply(tuple, axis=1).isin(partner_rows_to_delete)] # Delete the partner rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e10fd0-faaf-4252-8fcf-f937873c8d85",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 158 rows with high percentage of missing data.\n"
     ]
    }
   ],
   "source": [
    "rows_after = df.shape[0]\n",
    "print(f\"Deleted {rows_before - rows_after} rows with high percentage of missing data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6583b3-efdc-4626-a77b-67eeb1280702",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 6. Clean categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda266b-1ddb-43ee-9a10-48a96af9d13a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "How many categorical columns are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac7d373d-2be0-4459-9a05-4bcb095aafab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['field', 'undergra', 'from', 'career']\n"
     ]
    }
   ],
   "source": [
    "cols_categorical = df.select_dtypes(include='object').columns.to_list()\n",
    "print(\"Categorical columns: \" + str(cols_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "362a4892-77b5-4025-9b99-ec3e5c99becd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "def create_table_unique_sorted_columns(df, cols_categorical):\n",
    "    # Determine the maximum number of unique non-NA values across all categorical columns\n",
    "    max_unique_length = max(len(df[col].unique()) for col in cols_categorical)\n",
    "    \n",
    "    # Create a DataFrame containing unique values (excluding NA) sorted for each categorical column individually\n",
    "    unique_sorted_table = pd.DataFrame(\n",
    "        {\n",
    "            col: sorted([x for x in df[col].unique() if pd.notna(x)])\n",
    "            + [pd.NA] * (max_unique_length - len([x for x in df[col].unique() if pd.notna(x)]))\n",
    "            for col in cols_categorical\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Display the first 100 rows, no need to view more\n",
    "    return unique_sorted_table.head(min(100, max_unique_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d787bd4-7657-4f33-9a45-c411f7b6cda7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<div style=\"background-color:moccasin\">\n",
    "    \n",
    "⚠️ The following is not an actual dataframe, but a table where each column contains unique values and has been sorted individually for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12dbc042-9012-4ae9-95e2-adc753a7a19f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>undergra</th>\n",
       "      <th>from</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acting</td>\n",
       "      <td>American University</td>\n",
       "      <td>94115</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African-American Studies/History</td>\n",
       "      <td>Amherst College</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Studies</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>Albania</td>\n",
       "      <td>ASIC Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Studies (Masters)</td>\n",
       "      <td>Ateneo de Manila University - Philippines</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Academia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>Augustana College</td>\n",
       "      <td>Ann Arbor</td>\n",
       "      <td>Academia or UN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anthropology/Education</td>\n",
       "      <td>Barnard College</td>\n",
       "      <td>Ann Arbor, MI</td>\n",
       "      <td>Academia, Research, Banking, Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Applied Maths/Econs</td>\n",
       "      <td>Beijing University</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Academia; Research; Teaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Applied Physiology &amp; Nutrition</td>\n",
       "      <td>Bennington College</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Architecture</td>\n",
       "      <td>Berklee College Of Music</td>\n",
       "      <td>Asia, Singapore</td>\n",
       "      <td>Academic (Law)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Art Education</td>\n",
       "      <td>Binghamton University</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Academic Physician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Art History</td>\n",
       "      <td>Biological Sciences</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Academic Work, Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Art History/medicine</td>\n",
       "      <td>Bocconi University Milan</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Academic or Research staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arts Administration</td>\n",
       "      <td>Bombay, India</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Academic/ Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BUSINESS CONSULTING</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Acting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bilingual Education</td>\n",
       "      <td>Bowdoin College</td>\n",
       "      <td>BEIJING, CHINA</td>\n",
       "      <td>Actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Biochemistry</td>\n",
       "      <td>Brandeis University</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Am not sure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Biochemistry &amp; Molecular Biophysics</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Architecture and design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biology</td>\n",
       "      <td>Brown University</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Art Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Biology PhD</td>\n",
       "      <td>Bucharest University</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>Art educator and Artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Biomedical Engineering</td>\n",
       "      <td>Bucknell University</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>Artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Biomedical Informatics</td>\n",
       "      <td>COOPER UNION</td>\n",
       "      <td>Bogota, Colombia</td>\n",
       "      <td>Asset Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Biomedical engineering</td>\n",
       "      <td>CSUN</td>\n",
       "      <td>Bombay, India</td>\n",
       "      <td>Assistant District Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>Cagliari - Italy</td>\n",
       "      <td>Born in Iran</td>\n",
       "      <td>Banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Business</td>\n",
       "      <td>Cal Berkeley</td>\n",
       "      <td>Born in Montana, raised in South Jersey (nr. Philadelphia)</td>\n",
       "      <td>Bilingual Elementary School Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Business &amp; International Affairs</td>\n",
       "      <td>Cal State Univ., Long Beach</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Biostatistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Business (Finance &amp; Marketing)</td>\n",
       "      <td>California State University Los Angeles</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Biotech/business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Business (MBA)</td>\n",
       "      <td>Cambridge University</td>\n",
       "      <td>Boston, Ma</td>\n",
       "      <td>Brand Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Business Administration</td>\n",
       "      <td>Case Western Reserve University</td>\n",
       "      <td>Boulder, Colorado</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Business School</td>\n",
       "      <td>China</td>\n",
       "      <td>Bowdoin College</td>\n",
       "      <td>Business - Investment Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Business and International Affairs (MBA/MIA Dual Degree)</td>\n",
       "      <td>ChungShenMedicalUniversity(Taiwan)</td>\n",
       "      <td>Brandeis University</td>\n",
       "      <td>Business Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Business, Media</td>\n",
       "      <td>Colgate University</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Business Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Business, marketing</td>\n",
       "      <td>Colorado State</td>\n",
       "      <td>Bronx Science</td>\n",
       "      <td>Business Management and Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Business- MBA</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Business/Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Business/ Finance/ Real Estate</td>\n",
       "      <td>Columbia Business School</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Business/Law</td>\n",
       "      <td>Columbia College</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>CEO in For Profit Biomedical Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Cell Biology</td>\n",
       "      <td>Columbia College, CU</td>\n",
       "      <td>Buffalo, NY</td>\n",
       "      <td>CONSULTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Capital Markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Classics</td>\n",
       "      <td>ColumbiaU</td>\n",
       "      <td>Burlington, Vermont</td>\n",
       "      <td>Cardiologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Climate Dynamics</td>\n",
       "      <td>Connecticut College</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>Child Rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Climate-Earth and Environ. Science</td>\n",
       "      <td>Conneticut College</td>\n",
       "      <td>CT, FL, TN</td>\n",
       "      <td>Civil Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Clinical Psychology</td>\n",
       "      <td>Cooper Union, Bard college, and SUNY Purchase</td>\n",
       "      <td>California</td>\n",
       "      <td>Clidren's TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cognitive Studies in Education</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>California (West Coast)</td>\n",
       "      <td>Clinic Trial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Communications</td>\n",
       "      <td>Cornell University</td>\n",
       "      <td>California and New York</td>\n",
       "      <td>Clinical Psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Communications in Education</td>\n",
       "      <td>Dartmouth College</td>\n",
       "      <td>California, New Jersey</td>\n",
       "      <td>Clinical Psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Comparative Literature</td>\n",
       "      <td>Delhi University</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>Clinical Social Worker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Computational Biochemsistry</td>\n",
       "      <td>Duquesne University</td>\n",
       "      <td>Cambridge, Massachusetts</td>\n",
       "      <td>College Professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Ecole Normale Suprieure, Paris</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Congresswoman, and comedian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Conservation biology</td>\n",
       "      <td>Ecole Polytechnique (France)</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Conservation training and education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Consulting</td>\n",
       "      <td>Ecole Superieure d'Electricite</td>\n",
       "      <td>Cherry Hill, NJ</td>\n",
       "      <td>Consultin \\ Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Counseling Psychology</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Chile</td>\n",
       "      <td>Consulting, later Arts or Non-Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Creative Writing (Nonfiction)</td>\n",
       "      <td>Florida International University</td>\n",
       "      <td>China</td>\n",
       "      <td>Corporate Finance, Asset Management/ Hedge Funds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Creative Writing - Nonfiction</td>\n",
       "      <td>Fordham University</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>Corporate Lawyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Curriculum and Teaching/Giftedness</td>\n",
       "      <td>Fu Jen Catholic University, Taiwan</td>\n",
       "      <td>Cincinnati, Ohio</td>\n",
       "      <td>Corporate attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>Fudan</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Corporate law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ELECTRICAL ENGINEERING</td>\n",
       "      <td>Fudan University, Shanghai, China</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Counseling Adolescents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Early Childhood Education</td>\n",
       "      <td>GA Tech</td>\n",
       "      <td>Colombia, South America</td>\n",
       "      <td>Country Analysis/Research/Credit Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Earth and Environmental Science</td>\n",
       "      <td>GW</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Development work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Ecology</td>\n",
       "      <td>George Mason University</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Development work on field in the middle of nowhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Economics</td>\n",
       "      <td>George Washington University</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Economics and Political Science</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>DC</td>\n",
       "      <td>Diplomat / Int'l civil servant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Economics, English</td>\n",
       "      <td>Georgetown University</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>Diplomat/Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Economics, Sociology</td>\n",
       "      <td>HEC FRance</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>Director of Admissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Ed.D. in higher education policy at TC</td>\n",
       "      <td>HOWARD UNIVERSITY</td>\n",
       "      <td>Detroit suburbs</td>\n",
       "      <td>Director of Training and Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Education</td>\n",
       "      <td>Hamilton College</td>\n",
       "      <td>Detroit, Michigan, USA</td>\n",
       "      <td>Doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Education Administration</td>\n",
       "      <td>Hampshire College</td>\n",
       "      <td>England</td>\n",
       "      <td>EDUCATION ADMINISTRATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Education Leadership - Public School Administration</td>\n",
       "      <td>Harbin Medical University, China</td>\n",
       "      <td>Erie, PA</td>\n",
       "      <td>Early Childhood Ed. - College/univ. faculity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Education Policy</td>\n",
       "      <td>Harcourt Butler Technological Institute</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Economic Policy Advisor on Latin America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Education- Literacy Specialist</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Economic research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Educational Psychology</td>\n",
       "      <td>Harvard College</td>\n",
       "      <td>Florida and Virginia</td>\n",
       "      <td>Economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Electrical Engg.</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>France</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>Harvey Mudd College (Physics)</td>\n",
       "      <td>France  / New York</td>\n",
       "      <td>Education Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Elementary Education</td>\n",
       "      <td>Hebrew University</td>\n",
       "      <td>Genova, Italy</td>\n",
       "      <td>Education Policy Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Elementary Education - Preservice</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>Georgia, USA</td>\n",
       "      <td>Educational Policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Elementary/Childhood Education (MA)</td>\n",
       "      <td>Holy Cross College</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Educator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Great Neck, NY</td>\n",
       "      <td>Elementary Education Teaching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>English</td>\n",
       "      <td>Jesus and Mary College,Delhi</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Elementary school teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>English Education</td>\n",
       "      <td>John Hopkins</td>\n",
       "      <td>Greece/Germany</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>English and Comp Lit</td>\n",
       "      <td>Kettering University / GMI</td>\n",
       "      <td>Greenwich, CT</td>\n",
       "      <td>Energy Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Environmental Engineering</td>\n",
       "      <td>Kunitachi College of Music (in Japan)</td>\n",
       "      <td>HKG</td>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Epidemiology</td>\n",
       "      <td>LUISS, Rome</td>\n",
       "      <td>Hastings-on-Hudson, NY</td>\n",
       "      <td>Engineer or iBanker or consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Film</td>\n",
       "      <td>Lafayette College</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Finanace</td>\n",
       "      <td>Loyola College</td>\n",
       "      <td>Hawaii and Los Angeles</td>\n",
       "      <td>English Teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Finance</td>\n",
       "      <td>Loyola College in Maryland</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>English teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Finance&amp;Economics</td>\n",
       "      <td>MIT</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Entertainment/Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Finance/Economics</td>\n",
       "      <td>MSU, Russia</td>\n",
       "      <td>I am from NYC</td>\n",
       "      <td>Entertainment/Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Financial Engineering</td>\n",
       "      <td>Mary Baldwin College</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>Entrepreneur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Fundraising Management</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>India</td>\n",
       "      <td>Entrepreneurship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GS Postbacc PreMed</td>\n",
       "      <td>Miami University</td>\n",
       "      <td>India and NJ</td>\n",
       "      <td>Epidemiologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>GSAS</td>\n",
       "      <td>Middlebury College</td>\n",
       "      <td>India, Holland</td>\n",
       "      <td>Exec. Director of social service non-profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>General management/finance</td>\n",
       "      <td>Monash University - Australia</td>\n",
       "      <td>India/Venezuela</td>\n",
       "      <td>Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Genetics</td>\n",
       "      <td>NUS</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Film/Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Genetics &amp; Development</td>\n",
       "      <td>NYU</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Filmmaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>German Literature</td>\n",
       "      <td>Naples, Italy</td>\n",
       "      <td>International Student</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Health policy</td>\n",
       "      <td>National Taiwan University</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>Finance Related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Higher Ed. - M.A.</td>\n",
       "      <td>National University Of Singapore</td>\n",
       "      <td>Israel</td>\n",
       "      <td>Finance/Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>History</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Financial Mathematics-Investment Bank or Hedge Fund-Derivatives Quant Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>History (GSAS - PhD)</td>\n",
       "      <td>New York University</td>\n",
       "      <td>J.P. Morgan</td>\n",
       "      <td>Financial Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>History of Religion</td>\n",
       "      <td>Nirma Institute of Technology-India</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Fixed Income Sales &amp; Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Human Rights</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>Foreign Service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       field  \\\n",
       "0                                                     Acting   \n",
       "1                           African-American Studies/History   \n",
       "2                                           American Studies   \n",
       "3                                 American Studies (Masters)   \n",
       "4                                               Anthropology   \n",
       "5                                     Anthropology/Education   \n",
       "6                                        Applied Maths/Econs   \n",
       "7                             Applied Physiology & Nutrition   \n",
       "8                                               Architecture   \n",
       "9                                              Art Education   \n",
       "10                                               Art History   \n",
       "11                                      Art History/medicine   \n",
       "12                                       Arts Administration   \n",
       "13                                       BUSINESS CONSULTING   \n",
       "14                                       Bilingual Education   \n",
       "15                                              Biochemistry   \n",
       "16                       Biochemistry & Molecular Biophysics   \n",
       "17                                                   Biology   \n",
       "18                                               Biology PhD   \n",
       "19                                    Biomedical Engineering   \n",
       "20                                    Biomedical Informatics   \n",
       "21                                    Biomedical engineering   \n",
       "22                                             Biotechnology   \n",
       "23                                                  Business   \n",
       "24                          Business & International Affairs   \n",
       "25                            Business (Finance & Marketing)   \n",
       "26                                            Business (MBA)   \n",
       "27                                   Business Administration   \n",
       "28                                           Business School   \n",
       "29  Business and International Affairs (MBA/MIA Dual Degree)   \n",
       "30                                           Business, Media   \n",
       "31                                       Business, marketing   \n",
       "32                                             Business- MBA   \n",
       "33                            Business/ Finance/ Real Estate   \n",
       "34                                              Business/Law   \n",
       "35                                              Cell Biology   \n",
       "36                                                 Chemistry   \n",
       "37                                                  Classics   \n",
       "38                                          Climate Dynamics   \n",
       "39                        Climate-Earth and Environ. Science   \n",
       "40                                       Clinical Psychology   \n",
       "41                            Cognitive Studies in Education   \n",
       "42                                            Communications   \n",
       "43                               Communications in Education   \n",
       "44                                    Comparative Literature   \n",
       "45                               Computational Biochemsistry   \n",
       "46                                          Computer Science   \n",
       "47                                      Conservation biology   \n",
       "48                                                Consulting   \n",
       "49                                     Counseling Psychology   \n",
       "50                                          Creative Writing   \n",
       "51                             Creative Writing (Nonfiction)   \n",
       "52                             Creative Writing - Nonfiction   \n",
       "53                        Curriculum and Teaching/Giftedness   \n",
       "54                                                 EDUCATION   \n",
       "55                                    ELECTRICAL ENGINEERING   \n",
       "56                                 Early Childhood Education   \n",
       "57                           Earth and Environmental Science   \n",
       "58                                                   Ecology   \n",
       "59                                                 Economics   \n",
       "60                           Economics and Political Science   \n",
       "61                                        Economics, English   \n",
       "62                                      Economics, Sociology   \n",
       "63                    Ed.D. in higher education policy at TC   \n",
       "64                                                 Education   \n",
       "65                                  Education Administration   \n",
       "66       Education Leadership - Public School Administration   \n",
       "67                                          Education Policy   \n",
       "68                            Education- Literacy Specialist   \n",
       "69                                    Educational Psychology   \n",
       "70                                          Electrical Engg.   \n",
       "71                                    Electrical Engineering   \n",
       "72                                      Elementary Education   \n",
       "73                         Elementary Education - Preservice   \n",
       "74                       Elementary/Childhood Education (MA)   \n",
       "75                                               Engineering   \n",
       "76                                                   English   \n",
       "77                                         English Education   \n",
       "78                                      English and Comp Lit   \n",
       "79                                 Environmental Engineering   \n",
       "80                                              Epidemiology   \n",
       "81                                                      Film   \n",
       "82                                                  Finanace   \n",
       "83                                                   Finance   \n",
       "84                                         Finance&Economics   \n",
       "85                                         Finance/Economics   \n",
       "86                                     Financial Engineering   \n",
       "87                                    Fundraising Management   \n",
       "88                                        GS Postbacc PreMed   \n",
       "89                                                      GSAS   \n",
       "90                                General management/finance   \n",
       "91                                                  Genetics   \n",
       "92                                    Genetics & Development   \n",
       "93                                         German Literature   \n",
       "94                                             Health policy   \n",
       "95                                         Higher Ed. - M.A.   \n",
       "96                                                   History   \n",
       "97                                      History (GSAS - PhD)   \n",
       "98                                       History of Religion   \n",
       "99                                              Human Rights   \n",
       "\n",
       "                                         undergra  \\\n",
       "0                             American University   \n",
       "1                                 Amherst College   \n",
       "2                                   Arizona State   \n",
       "3       Ateneo de Manila University - Philippines   \n",
       "4                               Augustana College   \n",
       "5                                 Barnard College   \n",
       "6                              Beijing University   \n",
       "7                              Bennington College   \n",
       "8                        Berklee College Of Music   \n",
       "9                           Binghamton University   \n",
       "10                            Biological Sciences   \n",
       "11                       Bocconi University Milan   \n",
       "12                                  Bombay, India   \n",
       "13                                 Boston College   \n",
       "14                                Bowdoin College   \n",
       "15                            Brandeis University   \n",
       "16                                          Brown   \n",
       "17                               Brown University   \n",
       "18                           Bucharest University   \n",
       "19                            Bucknell University   \n",
       "20                                   COOPER UNION   \n",
       "21                                           CSUN   \n",
       "22                               Cagliari - Italy   \n",
       "23                                   Cal Berkeley   \n",
       "24                    Cal State Univ., Long Beach   \n",
       "25        California State University Los Angeles   \n",
       "26                           Cambridge University   \n",
       "27                Case Western Reserve University   \n",
       "28                                          China   \n",
       "29             ChungShenMedicalUniversity(Taiwan)   \n",
       "30                             Colgate University   \n",
       "31                                 Colorado State   \n",
       "32                                       Columbia   \n",
       "33                       Columbia Business School   \n",
       "34                               Columbia College   \n",
       "35                           Columbia College, CU   \n",
       "36                            Columbia University   \n",
       "37                                      ColumbiaU   \n",
       "38                            Connecticut College   \n",
       "39                             Conneticut College   \n",
       "40  Cooper Union, Bard college, and SUNY Purchase   \n",
       "41                                        Cornell   \n",
       "42                             Cornell University   \n",
       "43                              Dartmouth College   \n",
       "44                               Delhi University   \n",
       "45                            Duquesne University   \n",
       "46                Ecole Normale Suprieure, Paris   \n",
       "47                   Ecole Polytechnique (France)   \n",
       "48                 Ecole Superieure d'Electricite   \n",
       "49                               Emory University   \n",
       "50                                    Engineering   \n",
       "51               Florida International University   \n",
       "52                             Fordham University   \n",
       "53             Fu Jen Catholic University, Taiwan   \n",
       "54                                          Fudan   \n",
       "55              Fudan University, Shanghai, China   \n",
       "56                                        GA Tech   \n",
       "57                                             GW   \n",
       "58                        George Mason University   \n",
       "59                   George Washington University   \n",
       "60                                     Georgetown   \n",
       "61                          Georgetown University   \n",
       "62                                     HEC FRance   \n",
       "63                              HOWARD UNIVERSITY   \n",
       "64                               Hamilton College   \n",
       "65                              Hampshire College   \n",
       "66               Harbin Medical University, China   \n",
       "67        Harcourt Butler Technological Institute   \n",
       "68                                        Harvard   \n",
       "69                                Harvard College   \n",
       "70                             Harvard University   \n",
       "71                  Harvey Mudd College (Physics)   \n",
       "72                              Hebrew University   \n",
       "73                                     Holy Cross   \n",
       "74                             Holy Cross College   \n",
       "75                                       Illinois   \n",
       "76                   Jesus and Mary College,Delhi   \n",
       "77                                   John Hopkins   \n",
       "78                     Kettering University / GMI   \n",
       "79          Kunitachi College of Music (in Japan)   \n",
       "80                                    LUISS, Rome   \n",
       "81                              Lafayette College   \n",
       "82                                 Loyola College   \n",
       "83                     Loyola College in Maryland   \n",
       "84                                            MIT   \n",
       "85                                    MSU, Russia   \n",
       "86                           Mary Baldwin College   \n",
       "87                              McGill University   \n",
       "88                               Miami University   \n",
       "89                             Middlebury College   \n",
       "90                  Monash University - Australia   \n",
       "91                                            NUS   \n",
       "92                                            NYU   \n",
       "93                                  Naples, Italy   \n",
       "94                     National Taiwan University   \n",
       "95               National University Of Singapore   \n",
       "96               National University of Singapore   \n",
       "97                            New York University   \n",
       "98            Nirma Institute of Technology-India   \n",
       "99                        Northwestern University   \n",
       "\n",
       "                                                          from  \\\n",
       "0                                                        94115   \n",
       "1                                                      Alabama   \n",
       "2                                                      Albania   \n",
       "3                                              Albuquerque, NM   \n",
       "4                                                    Ann Arbor   \n",
       "5                                                Ann Arbor, MI   \n",
       "6                                                    Argentina   \n",
       "7                                                      Arizona   \n",
       "8                                              Asia, Singapore   \n",
       "9                                                      Atlanta   \n",
       "10                                                 Atlanta, GA   \n",
       "11                                                  Austin, TX   \n",
       "12                                                   Australia   \n",
       "13                                                  Azerbaijan   \n",
       "14                                              BEIJING, CHINA   \n",
       "15                                                   Baltimore   \n",
       "16                                                  Bangladesh   \n",
       "17                                                     Belgium   \n",
       "18                                                    Berkeley   \n",
       "19                                                Berkeley, CA   \n",
       "20                                            Bogota, Colombia   \n",
       "21                                               Bombay, India   \n",
       "22                                                Born in Iran   \n",
       "23  Born in Montana, raised in South Jersey (nr. Philadelphia)   \n",
       "24                                                      Boston   \n",
       "25                                                  Boston, MA   \n",
       "26                                                  Boston, Ma   \n",
       "27                                           Boulder, Colorado   \n",
       "28                                             Bowdoin College   \n",
       "29                                         Brandeis University   \n",
       "30                                                      Brazil   \n",
       "31                                               Bronx Science   \n",
       "32                                                    Brooklyn   \n",
       "33                                                Brooklyn, NY   \n",
       "34                                                    Budapest   \n",
       "35                                                 Buffalo, NY   \n",
       "36                                                    Bulgaria   \n",
       "37                                         Burlington, Vermont   \n",
       "38                                                  CALIFORNIA   \n",
       "39                                                  CT, FL, TN   \n",
       "40                                                  California   \n",
       "41                                     California (West Coast)   \n",
       "42                                     California and New York   \n",
       "43                                      California, New Jersey   \n",
       "44                                               Cambridge, MA   \n",
       "45                                    Cambridge, Massachusetts   \n",
       "46                                                    Cameroon   \n",
       "47                                                      Canada   \n",
       "48                                             Cherry Hill, NJ   \n",
       "49                                                     Chicago   \n",
       "50                                                       Chile   \n",
       "51                                                       China   \n",
       "52                                              Cincinnati, OH   \n",
       "53                                            Cincinnati, Ohio   \n",
       "54                                                   Cleveland   \n",
       "55                                                    Colombia   \n",
       "56                                     Colombia, South America   \n",
       "57                                                    Colorado   \n",
       "58                                                 Connecticut   \n",
       "59                                                  Costa Rica   \n",
       "60                                                          DC   \n",
       "61                                               Dallas, Texas   \n",
       "62                                                     Detroit   \n",
       "63                                             Detroit suburbs   \n",
       "64                                      Detroit, Michigan, USA   \n",
       "65                                                     England   \n",
       "66                                                    Erie, PA   \n",
       "67                                                      Europe   \n",
       "68                                                     Florida   \n",
       "69                                        Florida and Virginia   \n",
       "70                                                      France   \n",
       "71                                          France  / New York   \n",
       "72                                               Genova, Italy   \n",
       "73                                                Georgia, USA   \n",
       "74                                                     Germany   \n",
       "75                                              Great Neck, NY   \n",
       "76                                                      Greece   \n",
       "77                                              Greece/Germany   \n",
       "78                                               Greenwich, CT   \n",
       "79                                                         HKG   \n",
       "80                                      Hastings-on-Hudson, NY   \n",
       "81                                                      Hawaii   \n",
       "82                                      Hawaii and Los Angeles   \n",
       "83                                                   Hong Kong   \n",
       "84                                                     Houston   \n",
       "85                                               I am from NYC   \n",
       "86                                                     Iceland   \n",
       "87                                                       India   \n",
       "88                                                India and NJ   \n",
       "89                                              India, Holland   \n",
       "90                                             India/Venezuela   \n",
       "91                                                     Indiana   \n",
       "92                                                   Indonesia   \n",
       "93                                       International Student   \n",
       "94                                                        Iowa   \n",
       "95                                                      Israel   \n",
       "96                                                       Italy   \n",
       "97                                                 J.P. Morgan   \n",
       "98                                                       Japan   \n",
       "99                                                      Kansas   \n",
       "\n",
       "                                                                           career  \n",
       "0                                                                               ?  \n",
       "1                                                                              ??  \n",
       "2                                                                   ASIC Engineer  \n",
       "3                                                                        Academia  \n",
       "4                                                                  Academia or UN  \n",
       "5                                               Academia, Research, Banking, Life  \n",
       "6                                                    Academia; Research; Teaching  \n",
       "7                                                                        Academic  \n",
       "8                                                                  Academic (Law)  \n",
       "9                                                              Academic Physician  \n",
       "10                                                      Academic Work, Consultant  \n",
       "11                                                     Academic or Research staff  \n",
       "12                                                              Academic/ Finance  \n",
       "13                                                                         Acting  \n",
       "14                                                                        Actress  \n",
       "15                                                                    Am not sure  \n",
       "16                                                        Architecture and design  \n",
       "17                                                                 Art Management  \n",
       "18                                                        Art educator and Artist  \n",
       "19                                                                         Artist  \n",
       "20                                                               Asset Management  \n",
       "21                                                    Assistant District Attorney  \n",
       "22                                                                        Banking  \n",
       "23                                            Bilingual Elementary School Teacher  \n",
       "24                                                                  Biostatistics  \n",
       "25                                                               Biotech/business  \n",
       "26                                                               Brand Management  \n",
       "27                                                                       Business  \n",
       "28                                               Business - Investment Management  \n",
       "29                                                            Business Consulting  \n",
       "30                                                            Business Management  \n",
       "31                                 Business Management and Information Technology  \n",
       "32                                                                   Business/Law  \n",
       "33                                                                            CEO  \n",
       "34                                      CEO in For Profit Biomedical Organization  \n",
       "35                                                                     CONSULTING  \n",
       "36                                                                Capital Markets  \n",
       "37                                                                   Cardiologist  \n",
       "38                                                                   Child Rights  \n",
       "39                                                                 Civil Engineer  \n",
       "40                                                                   Clidren's TV  \n",
       "41                                                                   Clinic Trial  \n",
       "42                                                          Clinical Psychologist  \n",
       "43                                                            Clinical Psychology  \n",
       "44                                                         Clinical Social Worker  \n",
       "45                                                              College Professor  \n",
       "46                                                    Congresswoman, and comedian  \n",
       "47                                            Conservation training and education  \n",
       "48                                                         Consultin \\ Management  \n",
       "49                                                                     Consulting  \n",
       "50                                           Consulting, later Arts or Non-Profit  \n",
       "51                               Corporate Finance, Asset Management/ Hedge Funds  \n",
       "52                                                               Corporate Lawyer  \n",
       "53                                                             Corporate attorney  \n",
       "54                                                                  Corporate law  \n",
       "55                                                         Counseling Adolescents  \n",
       "56                                      Country Analysis/Research/Credit Analysis  \n",
       "57                                                               Development work  \n",
       "58                             Development work on field in the middle of nowhere  \n",
       "59                                                                       Diplomat  \n",
       "60                                                 Diplomat / Int'l civil servant  \n",
       "61                                                              Diplomat/Business  \n",
       "62                                                         Director of Admissions  \n",
       "63                                           Director of Training and Development  \n",
       "64                                                                         Doctor  \n",
       "65                                                       EDUCATION ADMINISTRATION  \n",
       "66                                   Early Childhood Ed. - College/univ. faculity  \n",
       "67                                       Economic Policy Advisor on Latin America  \n",
       "68                                                              Economic research  \n",
       "69                                                                      Economist  \n",
       "70                                                                      Education  \n",
       "71                                                       Education Administration  \n",
       "72                                                       Education Policy Analyst  \n",
       "73                                                             Educational Policy  \n",
       "74                                                                       Educator  \n",
       "75                                                  Elementary Education Teaching  \n",
       "76                                                      Elementary school teacher  \n",
       "77                                                                         Energy  \n",
       "78                                                              Energy Management  \n",
       "79                                                                       Engineer  \n",
       "80                                              Engineer or iBanker or consultant  \n",
       "81                                                                    Engineering  \n",
       "82                                                                English Teacher  \n",
       "83                                                                English teacher  \n",
       "84                                                            Entertainment/Media  \n",
       "85                                                           Entertainment/Sports  \n",
       "86                                                                   Entrepreneur  \n",
       "87                                                               Entrepreneurship  \n",
       "88                                                                 Epidemiologist  \n",
       "89                                    Exec. Director of social service non-profit  \n",
       "90                                                                           Film  \n",
       "91                                                                Film/Television  \n",
       "92                                                                      Filmmaker  \n",
       "93                                                                        Finance  \n",
       "94                                                                Finance Related  \n",
       "95                                                              Finance/Economics  \n",
       "96  Financial Mathematics-Investment Bank or Hedge Fund-Derivatives Quant Analyst  \n",
       "97                                                             Financial Services  \n",
       "98                                                   Fixed Income Sales & Trading  \n",
       "99                                                                Foreign Service  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_unique_sorted_columns(df, cols_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da5a18-33d8-4525-a49c-a08d321a7f9a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    " The features contain numerous variations and near-duplicates of similar strings, for example \"Genetics\"/\"Genetics & Development\",  \"Finance\"/\"Finance Related\", etc. Standardizing these values would enhance consistency and clarity. But first we need to fill the holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "824ebc4b-637a-485a-b912-689691a735cd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "field          0\n",
       "undergra    3334\n",
       "from           0\n",
       "career        10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_categorical].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d193713a-e99a-43a4-b0b5-540f37f250cb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df[cols_categorical] = df[cols_categorical].fillna(\"unknown\")\n",
    "df[cols_categorical] = df[cols_categorical].replace(\"?\", \"unknown\")\n",
    "df[cols_categorical] = df[cols_categorical].replace(\"??\", \"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3792ba-4746-4d10-a914-5b3416d322e3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 6.1 Decide which categorical features to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e04fecd3-d572-472c-a731-8c0cb1426a7c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "field          0\n",
       "undergra    3334\n",
       "from           0\n",
       "career        61\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols_categorical].apply(lambda x: (x == 'unknown').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6163637-dfc3-4301-bd43-806470790647",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "It appears that the column _career_ has a relatively small number of missing values. In contrast, _undergra_ has a significant number of missing values, making it a good candidate for removal. However, this column contains valuable information—not only about where a person studied but also potentially about their place of origin (assuming most people attended undergraduate institutions near their hometown).\n",
    "\n",
    "This information can be leveraged to enhance the _from_ column when data is missing. For instance, if _from_ is missing, the university name in _undergra_ might include a geographic clue, such as \"University of Michigan.\"\n",
    "\n",
    "Thus, we will keep the _undergra_ column to make it useful for feature engineering. However, it will not be directly included in the model's training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6a87f-9975-47f9-81ef-160cb8ab39b2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 6.2 Field of study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546869f0-b63f-42e3-831a-322ebc902e42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This feature indicates the participants' field of study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cbed1-6e79-4db1-aab1-2785ff4cfe77",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `clean_field_of_study` [defined in src/clean_origin_columns.py](src/clean_origin_columns.py) standardizes academic field entries by:\n",
    "* Converting text to lowercase\n",
    "* Removing text after separators (-, /, etc.)\n",
    "* Mapping related terms to consistent categories (e.g., \"cardiologist\" → \"medicine\", \"physician\"  → \"medicine\")\n",
    "* Removing degree-related phrases (\"master of\", etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6df085b-c0fb-4139-ade1-a8d2c62fe472",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = clean_field_of_study(df, 'field')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19922ff-8138-42cb-8370-bc2bf9da2fae",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 6.3 Where is the participant from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813a80c-da72-4da8-8d34-594ff358db89",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This function, `clean_location`, [defined in src/clean_origin_columns.py](src/clean_origin_columns.py):\n",
    "\n",
    "1. Defines mappings for U.S. states, countries with common aliases, and specific cities to states.\n",
    "2. Includes a set of predefined replacements for common location variations.\n",
    "3. Normalizes location strings by trimming, lowercasing, and mapping them to their standardized form (e.g., city or country).\n",
    "4. Extracts and separates the location into two new columns: `city` and `state_or_country`.\n",
    "5. Handles edge cases like combined locations (e.g., \"California/USA\") and uses city-to-state mappings or undergraduate data to infer missing locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b11b2231-4633-4bf3-b15d-c47dfd8a2dfe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = clean_location(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a7b27-f08a-4ab7-b6ca-8bea389a75a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 6.3 Participant's career"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e653e8-021d-408c-97c8-6b6ee4f82304",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We can use the same function as for cleaning the _field_ feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bbccd0f-522a-4fa2-957c-4df3f18315eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = clean_field_of_study(df, \"career\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46818445-39f8-4568-9dca-932194598ece",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 6.4 Final look at the cleaned categorical columns, including the new columns _city_ and _state_or_country_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96918c8-8ae5-4273-a620-bfe54952defc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<div style=\"background-color:moccasin\">\n",
    "    \n",
    "⚠️ We still need to keep in mind that this is not a dataframe but a side-by-side display of sorted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75a548f5-3bf1-4f16-a41a-fe829c5ae87e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state_or_country</th>\n",
       "      <th>field</th>\n",
       "      <th>undergra</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Akron, Oh</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>acting</td>\n",
       "      <td>American University</td>\n",
       "      <td>acadeic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>Albania</td>\n",
       "      <td>african</td>\n",
       "      <td>Amherst College</td>\n",
       "      <td>academics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann Arbor</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>american studies</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>acting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>anthropology</td>\n",
       "      <td>Ateneo de Manila University - Philippines</td>\n",
       "      <td>actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Australia</td>\n",
       "      <td>applied physiology</td>\n",
       "      <td>Augustana College</td>\n",
       "      <td>architecture and design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Austin</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>architecture</td>\n",
       "      <td>Barnard College</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>art</td>\n",
       "      <td>Beijing University</td>\n",
       "      <td>assistant the universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>business</td>\n",
       "      <td>Bennington College</td>\n",
       "      <td>banking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>classics</td>\n",
       "      <td>Berklee College Of Music</td>\n",
       "      <td>boxing champ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bogota</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>climate</td>\n",
       "      <td>Binghamton University</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bombay</td>\n",
       "      <td>California</td>\n",
       "      <td>communications</td>\n",
       "      <td>Biological Sciences</td>\n",
       "      <td>capital markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Born In Montana</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>consulting</td>\n",
       "      <td>Bocconi University Milan</td>\n",
       "      <td>ceo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Boston</td>\n",
       "      <td>Canada</td>\n",
       "      <td>ecology</td>\n",
       "      <td>Bombay, India</td>\n",
       "      <td>child rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Chile</td>\n",
       "      <td>economics</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>clidren's tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brandeis University</td>\n",
       "      <td>China</td>\n",
       "      <td>education</td>\n",
       "      <td>Bowdoin College</td>\n",
       "      <td>comedienne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>elementary</td>\n",
       "      <td>Brandeis University</td>\n",
       "      <td>congresswoman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>engineering</td>\n",
       "      <td>Brown</td>\n",
       "      <td>consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>english</td>\n",
       "      <td>Brown University</td>\n",
       "      <td>counseling adolescents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>epidemiology</td>\n",
       "      <td>Bucharest University</td>\n",
       "      <td>country analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Burlington</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>film</td>\n",
       "      <td>Bucknell University</td>\n",
       "      <td>curriculum developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>California At Santa Cruz</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>finance</td>\n",
       "      <td>COOPER UNION</td>\n",
       "      <td>development work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Florida</td>\n",
       "      <td>french</td>\n",
       "      <td>CSUN</td>\n",
       "      <td>development work on field in the middle of nowhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cherry Hill</td>\n",
       "      <td>France</td>\n",
       "      <td>genetics</td>\n",
       "      <td>Cagliari - Italy</td>\n",
       "      <td>dietician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>gs postbacc premed</td>\n",
       "      <td>Cal Berkeley</td>\n",
       "      <td>diplomat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Germany</td>\n",
       "      <td>gsas</td>\n",
       "      <td>Cal State Univ., Long Beach</td>\n",
       "      <td>director of admissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Greece</td>\n",
       "      <td>health</td>\n",
       "      <td>California State University Los Angeles</td>\n",
       "      <td>director of training and development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cologne, Germany</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>higher ed.</td>\n",
       "      <td>Cambridge University</td>\n",
       "      <td>early childhood ed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>history</td>\n",
       "      <td>Case Western Reserve University</td>\n",
       "      <td>economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>human rights</td>\n",
       "      <td>China</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>instructional media and technology</td>\n",
       "      <td>ChungShenMedicalUniversity(Taiwan)</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Erie</td>\n",
       "      <td>India</td>\n",
       "      <td>instructional tech</td>\n",
       "      <td>Colgate University</td>\n",
       "      <td>engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>international affairs</td>\n",
       "      <td>Colorado State</td>\n",
       "      <td>enterpreneur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Genova</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>international development</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Great Neck</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>international politics</td>\n",
       "      <td>Columbia Business School</td>\n",
       "      <td>entrepreneurship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>Iran</td>\n",
       "      <td>international relations</td>\n",
       "      <td>Columbia College</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hastings-on-hudson</td>\n",
       "      <td>Israel</td>\n",
       "      <td>international security policy</td>\n",
       "      <td>Columbia College, CU</td>\n",
       "      <td>finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Heidelberg</td>\n",
       "      <td>Italy</td>\n",
       "      <td>intrernational affairs</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>fixed income sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Japan</td>\n",
       "      <td>journalism</td>\n",
       "      <td>ColumbiaU</td>\n",
       "      <td>foreign service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>India And Nj</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>law</td>\n",
       "      <td>Connecticut College</td>\n",
       "      <td>fundraising for non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>ma in quantitative methods</td>\n",
       "      <td>Conneticut College</td>\n",
       "      <td>governor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Karlsruhe</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>management</td>\n",
       "      <td>Cooper Union, Bard college, and SUNY Purchase</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Katonah</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>marketing</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>hero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>Cornell University</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Lexington</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mba</td>\n",
       "      <td>Dartmouth College</td>\n",
       "      <td>humanitarian affairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>London</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>medicine</td>\n",
       "      <td>Delhi University</td>\n",
       "      <td>industry cto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Long Island</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>mfa</td>\n",
       "      <td>Duquesne University</td>\n",
       "      <td>informatics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>money</td>\n",
       "      <td>Ecole Normale Suprieure, Paris</td>\n",
       "      <td>international affairs related career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>museum anthropology</td>\n",
       "      <td>Ecole Polytechnique (France)</td>\n",
       "      <td>international development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Manila</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>nutrition</td>\n",
       "      <td>Ecole Superieure d'Electricite</td>\n",
       "      <td>international development work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Memphis</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>philosophy</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>intl development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Miami</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>polish</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Milan</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Florida International University</td>\n",
       "      <td>journalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Milano</td>\n",
       "      <td>New York</td>\n",
       "      <td>public administration</td>\n",
       "      <td>Fordham University</td>\n",
       "      <td>law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>public policy</td>\n",
       "      <td>Fu Jen Catholic University, Taiwan</td>\n",
       "      <td>literacy organization head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Minneapolis</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>qmss</td>\n",
       "      <td>Fudan</td>\n",
       "      <td>lobbyist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>religion</td>\n",
       "      <td>Fudan University, Shanghai, China</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Panama</td>\n",
       "      <td>research</td>\n",
       "      <td>GA Tech</td>\n",
       "      <td>make money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>New Hope</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>science</td>\n",
       "      <td>GW</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>New York Area</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>sipa</td>\n",
       "      <td>George Mason University</td>\n",
       "      <td>marketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>New York City</td>\n",
       "      <td>Poland</td>\n",
       "      <td>soa</td>\n",
       "      <td>George Washington University</td>\n",
       "      <td>mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Northern New Jersey</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>social</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>mba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Romania</td>\n",
       "      <td>sociology</td>\n",
       "      <td>Georgetown University</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Palm Springs</td>\n",
       "      <td>Russia</td>\n",
       "      <td>speech</td>\n",
       "      <td>HEC FRance</td>\n",
       "      <td>millionaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>statistics</td>\n",
       "      <td>HOWARD UNIVERSITY</td>\n",
       "      <td>museum work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Paris</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>stats</td>\n",
       "      <td>Hamilton College</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>tc</td>\n",
       "      <td>Hampshire College</td>\n",
       "      <td>naturalist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Spain</td>\n",
       "      <td>tesol</td>\n",
       "      <td>Harbin Medical University, China</td>\n",
       "      <td>nonprofit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Portland</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>theater</td>\n",
       "      <td>Harcourt Butler Technological Institute</td>\n",
       "      <td>novelist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Pougkeepsie</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>theory</td>\n",
       "      <td>Harvard</td>\n",
       "      <td>nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Queens</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>undergrad</td>\n",
       "      <td>Harvard College</td>\n",
       "      <td>pediatrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Reading, England</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>urban planning</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Rochester</td>\n",
       "      <td>Texas</td>\n",
       "      <td>working</td>\n",
       "      <td>Harvey Mudd College (Physics)</td>\n",
       "      <td>physicist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>UK</td>\n",
       "      <td>writing</td>\n",
       "      <td>Hebrew University</td>\n",
       "      <td>planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>Uk</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Holy Cross</td>\n",
       "      <td>political development in africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Holy Cross College</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>porn star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Saratoga</td>\n",
       "      <td>Usa</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Jesus and Mary College,Delhi</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Utah</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>John Hopkins</td>\n",
       "      <td>private practice dietician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Sf Bay Area</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Kettering University / GMI</td>\n",
       "      <td>pro beach volleyball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Shanghai</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Kunitachi College of Music (in Japan)</td>\n",
       "      <td>producer at a non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Siberia</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LUISS, Rome</td>\n",
       "      <td>professional career</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Washington</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Lafayette College</td>\n",
       "      <td>professional student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Loyola College</td>\n",
       "      <td>program development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Sofia</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Loyola College in Maryland</td>\n",
       "      <td>psychology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>South Orange</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MIT</td>\n",
       "      <td>public school principal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>St. Louis</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MSU, Russia</td>\n",
       "      <td>public service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>State College</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Mary Baldwin College</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Staten Island</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>McGill University</td>\n",
       "      <td>reorganizing society. no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Taipei</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Miami University</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>The Philippines</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Middlebury College</td>\n",
       "      <td>school counseling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Monash University - Australia</td>\n",
       "      <td>school leadership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NUS</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Torrance</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NYU</td>\n",
       "      <td>security policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Tuscaloosa</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Naples, Italy</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Uncc</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>National Taiwan University</td>\n",
       "      <td>sex therapist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>National University Of Singapore</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vestal</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>National University of Singapore</td>\n",
       "      <td>software engr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wa</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>New York University</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Warsaw</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Nirma Institute of Technology-India</td>\n",
       "      <td>tba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Westchester</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Northwestern University</td>\n",
       "      <td>tech professional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        city state_or_country  \\\n",
       "0                  Akron, Oh          Alabama   \n",
       "1                Albuquerque          Albania   \n",
       "2                  Ann Arbor        Argentina   \n",
       "3                       Asia          Arizona   \n",
       "4                    Atlanta        Australia   \n",
       "5                     Austin       Azerbaijan   \n",
       "6                  Baltimore       Bangladesh   \n",
       "7                    Beijing          Belgium   \n",
       "8                   Berkeley           Brazil   \n",
       "9                     Bogota         Bulgaria   \n",
       "10                    Bombay       California   \n",
       "11           Born In Montana         Cameroon   \n",
       "12                    Boston           Canada   \n",
       "13                   Boulder            Chile   \n",
       "14       Brandeis University            China   \n",
       "15                     Bronx         Colombia   \n",
       "16                  Brooklyn         Colorado   \n",
       "17                  Budapest      Connecticut   \n",
       "18                   Buffalo       Costa Rica   \n",
       "19                Burlington   Czech Republic   \n",
       "20  California At Santa Cruz         Delaware   \n",
       "21                 Cambridge          Florida   \n",
       "22               Cherry Hill           France   \n",
       "23                   Chicago          Georgia   \n",
       "24                Cincinnati          Germany   \n",
       "25                 Cleveland           Greece   \n",
       "26          Cologne, Germany           Hawaii   \n",
       "27                    Dallas        Hong Kong   \n",
       "28                     Delhi          Iceland   \n",
       "29                   Detroit         Illinois   \n",
       "30                      Erie            India   \n",
       "31                    Europe          Indiana   \n",
       "32                    Genova        Indonesia   \n",
       "33                Great Neck             Iowa   \n",
       "34                 Greenwich             Iran   \n",
       "35        Hastings-on-hudson           Israel   \n",
       "36                Heidelberg            Italy   \n",
       "37                   Houston            Japan   \n",
       "38              India And Nj           Kansas   \n",
       "39               Kansas City        Louisiana   \n",
       "40                 Karlsruhe         Malaysia   \n",
       "41                   Katonah         Maryland   \n",
       "42                 Las Vegas    Massachusetts   \n",
       "43                 Lexington           Mexico   \n",
       "44                    London         Michigan   \n",
       "45               Long Island        Minnesota   \n",
       "46               Los Angeles         Missouri   \n",
       "47                 Manhattan         Nebraska   \n",
       "48                    Manila            Nepal   \n",
       "49                   Memphis           Nevada   \n",
       "50                     Miami       New Jersey   \n",
       "51                     Milan       New Mexico   \n",
       "52                    Milano         New York   \n",
       "53                 Milwaukee   North Carolina   \n",
       "54               Minneapolis             Ohio   \n",
       "55                 Nashville           Oregon   \n",
       "56                 New Delhi           Panama   \n",
       "57                  New Hope     Pennsylvania   \n",
       "58             New York Area      Philippines   \n",
       "59             New York City           Poland   \n",
       "60       Northern New Jersey      Puerto Rico   \n",
       "61                    Ottawa          Romania   \n",
       "62              Palm Springs           Russia   \n",
       "63                 Palo Alto        Singapore   \n",
       "64                     Paris   South Carolina   \n",
       "65              Philadelphia      South Korea   \n",
       "66                Pittsburgh            Spain   \n",
       "67                  Portland           Sweden   \n",
       "68               Pougkeepsie      Switzerland   \n",
       "69                    Queens           Taiwan   \n",
       "70          Reading, England        Tennessee   \n",
       "71                 Rochester            Texas   \n",
       "72            Salt Lake City               UK   \n",
       "73                 San Diego               Uk   \n",
       "74             San Francisco          Unknown   \n",
       "75             Santa Barbara          Uruguay   \n",
       "76                  Saratoga              Usa   \n",
       "77                   Seattle             Utah   \n",
       "78               Sf Bay Area       Uzbekistan   \n",
       "79                  Shanghai          Vermont   \n",
       "80                   Siberia         Virginia   \n",
       "81             Silver Spring       Washington   \n",
       "82                 Singapore        Wisconsin   \n",
       "83                     Sofia             <NA>   \n",
       "84              South Orange             <NA>   \n",
       "85                 St. Louis             <NA>   \n",
       "86             State College             <NA>   \n",
       "87             Staten Island             <NA>   \n",
       "88                    Taipei             <NA>   \n",
       "89           The Philippines             <NA>   \n",
       "90                     Tokyo             <NA>   \n",
       "91                   Toronto             <NA>   \n",
       "92                  Torrance             <NA>   \n",
       "93                Tuscaloosa             <NA>   \n",
       "94                      Uncc             <NA>   \n",
       "95                   Unknown             <NA>   \n",
       "96                    Vestal             <NA>   \n",
       "97                        Wa             <NA>   \n",
       "98                    Warsaw             <NA>   \n",
       "99               Westchester             <NA>   \n",
       "\n",
       "                                 field  \\\n",
       "0                               acting   \n",
       "1                              african   \n",
       "2                     american studies   \n",
       "3                         anthropology   \n",
       "4                   applied physiology   \n",
       "5                         architecture   \n",
       "6                                  art   \n",
       "7                             business   \n",
       "8                             classics   \n",
       "9                              climate   \n",
       "10                      communications   \n",
       "11                          consulting   \n",
       "12                             ecology   \n",
       "13                           economics   \n",
       "14                           education   \n",
       "15                          elementary   \n",
       "16                         engineering   \n",
       "17                             english   \n",
       "18                        epidemiology   \n",
       "19                                film   \n",
       "20                             finance   \n",
       "21                              french   \n",
       "22                            genetics   \n",
       "23                  gs postbacc premed   \n",
       "24                                gsas   \n",
       "25                              health   \n",
       "26                          higher ed.   \n",
       "27                             history   \n",
       "28                        human rights   \n",
       "29  instructional media and technology   \n",
       "30                  instructional tech   \n",
       "31               international affairs   \n",
       "32           international development   \n",
       "33              international politics   \n",
       "34             international relations   \n",
       "35       international security policy   \n",
       "36              intrernational affairs   \n",
       "37                          journalism   \n",
       "38                                 law   \n",
       "39          ma in quantitative methods   \n",
       "40                          management   \n",
       "41                           marketing   \n",
       "42                         mathematics   \n",
       "43                                 mba   \n",
       "44                            medicine   \n",
       "45                                 mfa   \n",
       "46                               money   \n",
       "47                 museum anthropology   \n",
       "48                           nutrition   \n",
       "49                          philosophy   \n",
       "50                              polish   \n",
       "51                          psychology   \n",
       "52               public administration   \n",
       "53                       public policy   \n",
       "54                                qmss   \n",
       "55                            religion   \n",
       "56                            research   \n",
       "57                             science   \n",
       "58                                sipa   \n",
       "59                                 soa   \n",
       "60                              social   \n",
       "61                           sociology   \n",
       "62                              speech   \n",
       "63                          statistics   \n",
       "64                               stats   \n",
       "65                                  tc   \n",
       "66                               tesol   \n",
       "67                             theater   \n",
       "68                              theory   \n",
       "69                           undergrad   \n",
       "70                      urban planning   \n",
       "71                             working   \n",
       "72                             writing   \n",
       "73                                <NA>   \n",
       "74                                <NA>   \n",
       "75                                <NA>   \n",
       "76                                <NA>   \n",
       "77                                <NA>   \n",
       "78                                <NA>   \n",
       "79                                <NA>   \n",
       "80                                <NA>   \n",
       "81                                <NA>   \n",
       "82                                <NA>   \n",
       "83                                <NA>   \n",
       "84                                <NA>   \n",
       "85                                <NA>   \n",
       "86                                <NA>   \n",
       "87                                <NA>   \n",
       "88                                <NA>   \n",
       "89                                <NA>   \n",
       "90                                <NA>   \n",
       "91                                <NA>   \n",
       "92                                <NA>   \n",
       "93                                <NA>   \n",
       "94                                <NA>   \n",
       "95                                <NA>   \n",
       "96                                <NA>   \n",
       "97                                <NA>   \n",
       "98                                <NA>   \n",
       "99                                <NA>   \n",
       "\n",
       "                                         undergra  \\\n",
       "0                             American University   \n",
       "1                                 Amherst College   \n",
       "2                                   Arizona State   \n",
       "3       Ateneo de Manila University - Philippines   \n",
       "4                               Augustana College   \n",
       "5                                 Barnard College   \n",
       "6                              Beijing University   \n",
       "7                              Bennington College   \n",
       "8                        Berklee College Of Music   \n",
       "9                           Binghamton University   \n",
       "10                            Biological Sciences   \n",
       "11                       Bocconi University Milan   \n",
       "12                                  Bombay, India   \n",
       "13                                 Boston College   \n",
       "14                                Bowdoin College   \n",
       "15                            Brandeis University   \n",
       "16                                          Brown   \n",
       "17                               Brown University   \n",
       "18                           Bucharest University   \n",
       "19                            Bucknell University   \n",
       "20                                   COOPER UNION   \n",
       "21                                           CSUN   \n",
       "22                               Cagliari - Italy   \n",
       "23                                   Cal Berkeley   \n",
       "24                    Cal State Univ., Long Beach   \n",
       "25        California State University Los Angeles   \n",
       "26                           Cambridge University   \n",
       "27                Case Western Reserve University   \n",
       "28                                          China   \n",
       "29             ChungShenMedicalUniversity(Taiwan)   \n",
       "30                             Colgate University   \n",
       "31                                 Colorado State   \n",
       "32                                       Columbia   \n",
       "33                       Columbia Business School   \n",
       "34                               Columbia College   \n",
       "35                           Columbia College, CU   \n",
       "36                            Columbia University   \n",
       "37                                      ColumbiaU   \n",
       "38                            Connecticut College   \n",
       "39                             Conneticut College   \n",
       "40  Cooper Union, Bard college, and SUNY Purchase   \n",
       "41                                        Cornell   \n",
       "42                             Cornell University   \n",
       "43                              Dartmouth College   \n",
       "44                               Delhi University   \n",
       "45                            Duquesne University   \n",
       "46                Ecole Normale Suprieure, Paris   \n",
       "47                   Ecole Polytechnique (France)   \n",
       "48                 Ecole Superieure d'Electricite   \n",
       "49                               Emory University   \n",
       "50                                    Engineering   \n",
       "51               Florida International University   \n",
       "52                             Fordham University   \n",
       "53             Fu Jen Catholic University, Taiwan   \n",
       "54                                          Fudan   \n",
       "55              Fudan University, Shanghai, China   \n",
       "56                                        GA Tech   \n",
       "57                                             GW   \n",
       "58                        George Mason University   \n",
       "59                   George Washington University   \n",
       "60                                     Georgetown   \n",
       "61                          Georgetown University   \n",
       "62                                     HEC FRance   \n",
       "63                              HOWARD UNIVERSITY   \n",
       "64                               Hamilton College   \n",
       "65                              Hampshire College   \n",
       "66               Harbin Medical University, China   \n",
       "67        Harcourt Butler Technological Institute   \n",
       "68                                        Harvard   \n",
       "69                                Harvard College   \n",
       "70                             Harvard University   \n",
       "71                  Harvey Mudd College (Physics)   \n",
       "72                              Hebrew University   \n",
       "73                                     Holy Cross   \n",
       "74                             Holy Cross College   \n",
       "75                                       Illinois   \n",
       "76                   Jesus and Mary College,Delhi   \n",
       "77                                   John Hopkins   \n",
       "78                     Kettering University / GMI   \n",
       "79          Kunitachi College of Music (in Japan)   \n",
       "80                                    LUISS, Rome   \n",
       "81                              Lafayette College   \n",
       "82                                 Loyola College   \n",
       "83                     Loyola College in Maryland   \n",
       "84                                            MIT   \n",
       "85                                    MSU, Russia   \n",
       "86                           Mary Baldwin College   \n",
       "87                              McGill University   \n",
       "88                               Miami University   \n",
       "89                             Middlebury College   \n",
       "90                  Monash University - Australia   \n",
       "91                                            NUS   \n",
       "92                                            NYU   \n",
       "93                                  Naples, Italy   \n",
       "94                     National Taiwan University   \n",
       "95               National University Of Singapore   \n",
       "96               National University of Singapore   \n",
       "97                            New York University   \n",
       "98            Nirma Institute of Technology-India   \n",
       "99                        Northwestern University   \n",
       "\n",
       "                                                career  \n",
       "0                                              acadeic  \n",
       "1                                            academics  \n",
       "2                                               acting  \n",
       "3                                              actress  \n",
       "4                              architecture and design  \n",
       "5                                                  art  \n",
       "6                               assistant the universe  \n",
       "7                                              banking  \n",
       "8                                         boxing champ  \n",
       "9                                             business  \n",
       "10                                     capital markets  \n",
       "11                                                 ceo  \n",
       "12                                        child rights  \n",
       "13                                        clidren's tv  \n",
       "14                                          comedienne  \n",
       "15                                       congresswoman  \n",
       "16                                          consulting  \n",
       "17                              counseling adolescents  \n",
       "18                                    country analysis  \n",
       "19                                curriculum developer  \n",
       "20                                    development work  \n",
       "21  development work on field in the middle of nowhere  \n",
       "22                                           dietician  \n",
       "23                                            diplomat  \n",
       "24                              director of admissions  \n",
       "25                director of training and development  \n",
       "26                                 early childhood ed.  \n",
       "27                                           economics  \n",
       "28                                           education  \n",
       "29                                              energy  \n",
       "30                                         engineering  \n",
       "31                                        enterpreneur  \n",
       "32                                       entertainment  \n",
       "33                                    entrepreneurship  \n",
       "34                                                film  \n",
       "35                                             finance  \n",
       "36                                  fixed income sales  \n",
       "37                                     foreign service  \n",
       "38                                 fundraising for non  \n",
       "39                                            governor  \n",
       "40                                              health  \n",
       "41                                                hero  \n",
       "42                                             history  \n",
       "43                                humanitarian affairs  \n",
       "44                                        industry cto  \n",
       "45                                         informatics  \n",
       "46                international affairs related career  \n",
       "47                           international development  \n",
       "48                      international development work  \n",
       "49                                    intl development  \n",
       "50                                          investment  \n",
       "51                                          journalism  \n",
       "52                                                 law  \n",
       "53                          literacy organization head  \n",
       "54                                            lobbyist  \n",
       "55                                                   m  \n",
       "56                                          make money  \n",
       "57                                          management  \n",
       "58                                           marketing  \n",
       "59                                         mathematics  \n",
       "60                                                 mba  \n",
       "61                                            medicine  \n",
       "62                                         millionaire  \n",
       "63                                         museum work  \n",
       "64                                               music  \n",
       "65                                          naturalist  \n",
       "66                                           nonprofit  \n",
       "67                                            novelist  \n",
       "68                                           nutrition  \n",
       "69                                          pediatrics  \n",
       "70                                     pharmaceuticals  \n",
       "71                                           physicist  \n",
       "72                                            planning  \n",
       "73                     political development in africa  \n",
       "74                                            politics  \n",
       "75                                           porn star  \n",
       "76                                           president  \n",
       "77                          private practice dietician  \n",
       "78                                pro beach volleyball  \n",
       "79                                   producer at a non  \n",
       "80                                 professional career  \n",
       "81                                professional student  \n",
       "82                                 program development  \n",
       "83                                          psychology  \n",
       "84                             public school principal  \n",
       "85                                      public service  \n",
       "86                                         real estate  \n",
       "87                            reorganizing society. no  \n",
       "88                                            research  \n",
       "89                                   school counseling  \n",
       "90                                   school leadership  \n",
       "91                                             science  \n",
       "92                                     security policy  \n",
       "93                                                self  \n",
       "94                                       sex therapist  \n",
       "95                                              social  \n",
       "96                                       software engr  \n",
       "97                                              speech  \n",
       "98                                                 tba  \n",
       "99                                   tech professional  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_table_unique_sorted_columns(df, ['city', 'state_or_country', 'field', 'undergra', 'career'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc51de-beff-406e-b7d6-21cc5736bed7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 7. Feature engineering partner characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8784ce-b106-425e-bb15-448fcb4978b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The dataset captures speed dating meetings, with each date appearing twice – once from each participant's perspective. When person A meets B, there's one row with A as the primary participant (_iid_) and B as partner (_pid_), and another row vice versa. Each participant has various characteristics. To simplify analysis, we'll create new features with suffix '_o' for partner characteristics by matching _pid_ with _iid_, allowing us to analyze both participants' traits in a single row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fbe4b-2afe-4a26-85fd-f608648be14c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `add_partner_columns` is [defined in src/feature_engineering.py](src/feature_engineering.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "622e8cc2-b49b-4180-8b80-7ddd94661bec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_questionnaire1 = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "cols_questionnaire2 = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "cols_questionnaire3 = ['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']\n",
    "cols_questionnaire4 = ['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1']\n",
    "cols_questionnaire5 = ['attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1']\n",
    "cols_questionnaire = cols_questionnaire1 + cols_questionnaire2 + cols_questionnaire3 + cols_questionnaire4 + cols_questionnaire5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b3b9b67-cc6e-4aea-bcef-63025670f3b0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_other = ['race', 'gender', 'age', 'date', 'go_out', 'imprace', 'imprelig', 'dec', 'goal', 'field', 'city', 'state_or_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "147de66c-32b1-449c-acb2-6bbcd4ecd6dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_subject = cols_interests + cols_questionnaire + cols_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41855fdc-d094-435c-8bf9-21c9d3359456",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "num_features_before = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b3751cb-b694-4cea-8588-34b9c2555b02",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df = add_partner_columns(df, cols_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f37b39bc-dced-4fab-b233-6e230ba747a9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 57 partner features.\n"
     ]
    }
   ],
   "source": [
    "num_features_after = df.shape[1]\n",
    "print(f'Added {num_features_after - num_features_before} partner features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351b6f2-6ec0-4cf7-a9e0-c47c7022c317",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c846d5f6-cb4c-454c-b17b-ae687a4c9e9d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns now are: \n",
      "age, age_o, amb1_1, amb1_1_o, amb2_1, amb2_1_o, amb3_1, amb3_1_o, amb4_1, amb4_1_o, amb5_1, amb5_1_o, art, art_o, attr1_1, attr1_1_o, attr2_1, attr2_1_o, attr3_1, attr3_1_o, attr4_1, attr4_1_o, attr5_1, attr5_1_o, career, city, city_o, clubbing, clubbing_o, concerts, concerts_o, date, date_o, dec, dec_o, dining, dining_o, exercise, exercise_o, field, field_cd, field_o, from, fun1_1, fun1_1_o, fun2_1, fun2_1_o, fun3_1, fun3_1_o, fun4_1, fun4_1_o, fun5_1, fun5_1_o, gaming, gaming_o, gender, gender_o, go_out, go_out_o, goal, goal_o, hiking, hiking_o, iid, imprace, imprace_o, imprelig, imprelig_o, int_corr, intel1_1, intel1_1_o, intel2_1, intel2_1_o, intel3_1, intel3_1_o, intel4_1, intel4_1_o, intel5_1, intel5_1_o, movies, movies_o, museums, museums_o, music, music_o, pid, race, race_o, reading, reading_o, samerace, shar1_1, shar1_1_o, shar2_1, shar2_1_o, shar4_1, shar4_1_o, shopping, shopping_o, sinc1_1, sinc1_1_o, sinc2_1, sinc2_1_o, sinc3_1, sinc3_1_o, sinc4_1, sinc4_1_o, sinc5_1, sinc5_1_o, sports, sports_o, state_or_country, state_or_country_o, theater, theater_o, tv, tv_o, tvsports, tvsports_o, undergra, wave, yoga, yoga_o\n"
     ]
    }
   ],
   "source": [
    "print(\"The columns now are: \\n\" + \", \".join(sorted(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98cabb-e8a2-427a-b161-964f7bb0ea96",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Define partner columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85613ba3-f127-4107-aaa0-7c0dbb2f4bec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_questionnaire1_o = ['attr1_1_o', 'sinc1_1_o', 'intel1_1_o', 'fun1_1_o', 'amb1_1_o', 'shar1_1_o']\n",
    "cols_questionnaire2_o = ['attr2_1_o', 'sinc2_1_o', 'intel2_1_o', 'fun2_1_o', 'amb2_1_o', 'shar2_1_o']\n",
    "cols_questionnaire3_o = ['attr3_1_o', 'sinc3_1_o', 'intel3_1_o', 'fun3_1_o', 'amb3_1_o']\n",
    "cols_questionnaire4_o = ['attr4_1_o', 'sinc4_1_o', 'intel4_1_o', 'fun4_1_o', 'amb4_1_o', 'shar4_1_o']\n",
    "cols_questionnaire5_o = ['attr5_1_o', 'sinc5_1_o', 'intel5_1_o', 'fun5_1_o', 'amb5_1_o']\n",
    "cols_questionnaire_o = cols_questionnaire1_o + cols_questionnaire2_o + cols_questionnaire3_o + cols_questionnaire4_o + cols_questionnaire5_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ee5296d-4036-4d91-ab56-5405a1948c1f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_interests_o = ['music_o', 'exercise_o', 'dining_o', 'tv_o', 'tvsports_o', 'sports_o', 'shopping_o', 'yoga_o', \n",
    "                    'gaming_o', 'reading_o', 'theater_o', 'hiking_o', 'art_o', 'museums_o', 'clubbing_o', 'concerts_o', 'movies_o']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a6f0c1-39e6-40d3-bc31-c9ebc7fbf605",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 8. Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032de68d-6202-4440-9d86-4e92905f2924",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Inspect the distribution of the target label (_dec_) by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "620c04ed-b5db-4331-b728-db39f0acd915",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dec\n",
       "0    4762\n",
       "1    3448\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dec.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "415ee8f3-ee2b-4205-9ded-0067ab96df08",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "0    4105\n",
       "1    4105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b3bc04f-dcba-43bd-9680-445064aee7e0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_counts = df.groupby('gender')['dec'].value_counts().unstack(fill_value=0)\n",
    "\n",
    "ax = grouped_counts.plot(kind='bar', figsize=(8, 6), color=['skyblue', 'salmon'], width=0.2)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d', label_type='edge', fontsize=10)\n",
    "cplt.txylabel('Decisions by Gender', 'Gender (0=Women, 1=Men)', 'How many liked the partner')\n",
    "cplt.xticks(ticks=[0, 1], labels=['Women (0)', 'Men (1)'], rotation=0)\n",
    "cplt.legend(title='Decision (dec)', labels=['No (0)', 'Yes (1)']).tight_layout().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb93242-9d48-4978-bb6b-5182e83b83de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The data reveals that female respondents showed a higher proportion of negative responses ('No') and lower proportion of positive responses ('Yes') compared to their male partners. Based on this pattern, we'll perform stratified sampling across both _dec_ (decision) and _gender_ variables to ensure balanced representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3375ee3d-67d5-4907-9ca1-790c0d0a1664",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df['dec_by_gender'] = df[['dec', 'gender']].astype(str).agg('_'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55b1db0d-8fea-47c2-bad3-1bf1b90999de",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"dec\", \"dec_by_gender\"], axis=1)\n",
    "y = df[\"dec\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=df[\"dec_by_gender\"], random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26667a-f7ec-45d6-9f90-4666151192e9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 8.1 Forget `X`, `y` and the original `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8499d311-0add-4b95-bb0c-778225e5434c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Temporarily hide `X`, `y` and the original dataframe so we don't accidentally refer to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cad8c9db-afee-4c7d-b03c-8f19ad28565f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "df_forgetme, X_forgetme, y_forgetme = deepcopy(df), deepcopy(X), deepcopy(y)\n",
    "\n",
    "del df\n",
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be3af0-1434-49c5-8933-daf6ad680f7a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 9. Impute missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94e075-b8a4-446e-b564-a5fa5de2adba",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 9.1 Interests columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769f61b-f7d9-4113-a959-1139862a7c83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Inspect the number of missing values and the min-max range of the existing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "461ad2ae-4319-471c-88ee-b9ef4930766c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6568 entries, 4504 to 50\n",
      "Data columns (total 17 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   music     6568 non-null   float64\n",
      " 1   exercise  6568 non-null   float64\n",
      " 2   dining    6568 non-null   float64\n",
      " 3   tv        6568 non-null   float64\n",
      " 4   tvsports  6568 non-null   float64\n",
      " 5   sports    6568 non-null   float64\n",
      " 6   shopping  6568 non-null   float64\n",
      " 7   yoga      6568 non-null   float64\n",
      " 8   gaming    6568 non-null   float64\n",
      " 9   reading   6568 non-null   float64\n",
      " 10  theater   6568 non-null   float64\n",
      " 11  hiking    6568 non-null   float64\n",
      " 12  art       6568 non-null   float64\n",
      " 13  museums   6568 non-null   float64\n",
      " 14  clubbing  6568 non-null   float64\n",
      " 15  concerts  6568 non-null   float64\n",
      " 16  movies    6568 non-null   float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 923.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train[cols_interests].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee5d0b6d-ec8b-4394-a188-888ba38f1a93",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>tv</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>sports</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>theater</th>\n",
       "      <th>hiking</th>\n",
       "      <th>art</th>\n",
       "      <th>museums</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>concerts</th>\n",
       "      <th>movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.86</td>\n",
       "      <td>6.27</td>\n",
       "      <td>7.79</td>\n",
       "      <td>5.31</td>\n",
       "      <td>4.59</td>\n",
       "      <td>6.42</td>\n",
       "      <td>5.65</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7.67</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.84</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.79</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          music  exercise   dining       tv  tvsports   sports  shopping  \\\n",
       "count   6568.00   6568.00  6568.00  6568.00   6568.00  6568.00   6568.00   \n",
       "mean       7.86      6.27     7.79     5.31      4.59     6.42      5.65   \n",
       "std        1.79      2.42     1.76     2.53      2.81     2.63      2.61   \n",
       "min        1.00      1.00     1.00     1.00      1.00     1.00      1.00   \n",
       "max       10.00     10.00    10.00    10.00     10.00    10.00     10.00   \n",
       "median     8.00      7.00     8.00     6.00      4.00     7.00      6.00   \n",
       "\n",
       "           yoga   gaming  reading  theater   hiking      art  museums  \\\n",
       "count   6568.00  6568.00  6568.00  6568.00  6568.00  6568.00  6568.00   \n",
       "mean       4.35     3.89     7.67     6.80     5.74     6.72     7.00   \n",
       "std        2.72     2.64     2.01     2.24     2.56     2.27     2.05   \n",
       "min        0.00     0.00     1.00     0.00     0.00     0.00     0.00   \n",
       "max       10.00    14.00    13.00    10.00    10.00    10.00    10.00   \n",
       "median     4.00     3.00     8.00     7.00     6.00     7.00     7.00   \n",
       "\n",
       "        clubbing  concerts   movies  \n",
       "count    6568.00   6568.00  6568.00  \n",
       "mean        5.74      6.84     7.92  \n",
       "std         2.49      2.16     1.72  \n",
       "min         0.00      0.00     0.00  \n",
       "max        10.00     10.00    10.00  \n",
       "median      6.00      7.00     8.00  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cols_interests].custom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993a37b-285a-45ff-878d-7ae05d2e394d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Some features have values of 0, despite the key document specifying a range of 1-10. We need to determine whether this means respondents skipped these sections entirely or if they deliberately used 0 to express extremely low interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "10767e6c-f762-4d17-a775-cf46df6bb34c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>music</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>tv</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>sports</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>theater</th>\n",
       "      <th>hiking</th>\n",
       "      <th>art</th>\n",
       "      <th>museums</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>concerts</th>\n",
       "      <th>movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6384</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6379</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6377</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>413</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  music  exercise  dining   tv  tvsports  sports  shopping  yoga  \\\n",
       "6378  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6393  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6387  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6404  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6401  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6389  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6403  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6394  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6384  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6398  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6379  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6377  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6386  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6405  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6392  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6395  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6397  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6408  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6407  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6400  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6383  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6406  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6402  414    1.0       9.0     5.0  7.0       5.0    10.0       2.0   0.0   \n",
       "6388  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6391  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "6381  413    6.0       5.0     7.0  8.0       7.0     6.0       7.0   0.0   \n",
       "\n",
       "      gaming  reading  theater  hiking  art  museums  clubbing  concerts  \\\n",
       "6378     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6393     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6387     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6404     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6401     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6389     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6403     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6394     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6384     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6398     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6379     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6377     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6386     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6405     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6392     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6395     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6397     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6408     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6407     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6400     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6383     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6406     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6402     5.0      8.0      0.0     5.0  0.0      0.0       0.0       0.0   \n",
       "6388     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6391     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "6381     5.0      6.0      6.0     5.0  3.0      5.0       4.0       6.0   \n",
       "\n",
       "      movies  \n",
       "6378     9.0  \n",
       "6393     0.0  \n",
       "6387     9.0  \n",
       "6404     0.0  \n",
       "6401     0.0  \n",
       "6389     9.0  \n",
       "6403     0.0  \n",
       "6394     0.0  \n",
       "6384     9.0  \n",
       "6398     0.0  \n",
       "6379     9.0  \n",
       "6377     9.0  \n",
       "6386     9.0  \n",
       "6405     0.0  \n",
       "6392     0.0  \n",
       "6395     0.0  \n",
       "6397     0.0  \n",
       "6408     0.0  \n",
       "6407     0.0  \n",
       "6400     0.0  \n",
       "6383     9.0  \n",
       "6406     0.0  \n",
       "6402     0.0  \n",
       "6388     9.0  \n",
       "6391     9.0  \n",
       "6381     9.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[(X_train.yoga) == 0][['iid'] + cols_interests]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e1e28-b2b0-416a-a37b-b9ca8734244f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Seems like 0 is used to indicate a low interest, therefore we will replace the 0s with 1 (minimum interest) to maintain data consistency and avoiding skewing analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c6357eb-221d-43a9-b78b-459e929eb7a8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "X_train[cols_interests] = X_train[cols_interests].replace(0, 1)\n",
    "X_test[cols_interests]  = X_test[cols_interests].replace(0, 1)\n",
    "\n",
    "X_train[cols_interests_o] = X_train[cols_interests_o].replace(0, 1)\n",
    "X_test[cols_interests_o]  = X_test[cols_interests_o].replace(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb58261c-c920-4916-8f9f-663bb91ffb1f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 9.2 Age by gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bb021-9dfb-423c-9d8d-4fbea1f369ca",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Inspect number of missing values and the median age by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "924ddcbc-f192-4dff-a451-5729a7ead387",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6568 entries, 4504 to 50\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     6542 non-null   float64\n",
      " 1   age_o   6542 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 153.9 KB\n"
     ]
    }
   ],
   "source": [
    "cols_median_by_gender =  ['age', 'age_o']\n",
    "X_train[cols_median_by_gender].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a97fc2cf-e392-4093-a2c8-1a776b87d05f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age\n",
       "gender      \n",
       "0       26.0\n",
       "1       27.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby('gender')[['age']].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a323abd-ee7c-4e96-8297-07bca1f6c399",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Age values are imputed using gender-specific medians to preserves gender-specific age patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2fc96-d9ce-4f2d-88d8-d63013b16c7f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `impute_columns_by_gender`, [defined in src/imputers.py](src/imputers.py), imputes missing or specific placeholder values (defined by `old_value`) in multiple columns based on the gender of the individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13eea656-b500-4b2e-990b-2010889b663f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = impute_columns_by_gender(X_train, X_test, cols_median_by_gender, old_value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca38d42-32f5-400e-b2f0-23d7d47627c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 9.3 Race columns (How important is the race of your partner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79624c0b-f248-4ed4-8f52-da7c930a7938",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Inspect the number of missing values and the min-max range of the existing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21b6ad2c-341a-4e8f-9d38-8ae16d2a1140",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6568 entries, 4504 to 50\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   imprace    6568 non-null   float64\n",
      " 1   imprace_o  6568 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 153.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train[['imprace', 'imprace_o']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d88bba65-8890-4ea9-83fc-f0d96644ee42",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprace_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.78</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.84</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imprace  imprace_o\n",
       "count   6568.00    6568.00\n",
       "mean       3.78       3.77\n",
       "std        2.84       2.84\n",
       "min        0.00       0.00\n",
       "max       10.00      10.00\n",
       "median     3.00       3.00"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['imprace', 'imprace_o']].custom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2bb33-424f-4d1e-a848-aa8ccf73e833",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Since there are no missing values but the minimal value is 0, we will assume that the respondents answered with 0 to assign minimal importance on the partner's race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14b1af37-43d9-49d4-a8d7-d61635c6d4d2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols = ['imprace', 'imprace_o']\n",
    "for col in cols:\n",
    "    median = X_train[col].median()\n",
    "    X_train[col] = X_train[col].replace(0, median)\n",
    "    X_test[col] = X_test[col].replace(0, median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d0942-b81a-4b6f-b8db-a7045e730c35",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 9.4 Date columns (How often do you go out on a date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "608e7027-7595-4f65-833d-aa25dd7b7bd9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6568 entries, 4504 to 50\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    6557 non-null   float64\n",
      " 1   date_o  6552 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 153.9 KB\n"
     ]
    }
   ],
   "source": [
    "cols = ['date', 'date_o']\n",
    "X_train[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7f7ef5a-e219-445a-84f5-5a9c72478b2e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6557.00</td>\n",
       "      <td>6552.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.01</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.44</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   date_o\n",
       "count   6557.00  6552.00\n",
       "mean       5.01     5.00\n",
       "std        1.44     1.45\n",
       "min        1.00     1.00\n",
       "max        7.00     7.00\n",
       "median     5.00     5.00"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cols].custom.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4f255c1-4905-4c06-ae94-2365f9460549",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "columns =  ['date', 'date_o']\n",
    "for col in columns:\n",
    "    median_val = X_train[col].median()\n",
    "    X_train[col] = X_train[col].fillna(median_val) # Fill NA values\n",
    "    X_test[col] = X_test[col].fillna(median_val) # Fill NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed59f5-c7d8-4d37-a771-f7d2660a2954",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 9.5 Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40beaaaa-77c3-456a-93de-cd50ac60f1dd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Check remaining missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b74d1a95-86f9-4473-8c5c-fe879c27bc38",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "field_cd        16\n",
       "fun1_1           8\n",
       "amb1_1          16\n",
       "shar1_1         32\n",
       "attr4_1       1448\n",
       "sinc4_1       1448\n",
       "intel4_1      1448\n",
       "fun4_1        1448\n",
       "amb4_1        1448\n",
       "shar4_1       1464\n",
       "amb2_1           8\n",
       "shar2_1          8\n",
       "attr3_1         21\n",
       "sinc3_1         21\n",
       "fun3_1          21\n",
       "intel3_1        21\n",
       "amb3_1          21\n",
       "attr5_1       2697\n",
       "sinc5_1       2697\n",
       "intel5_1      2697\n",
       "fun5_1        2697\n",
       "amb5_1        2697\n",
       "fun1_1_o         9\n",
       "amb1_1_o        18\n",
       "shar1_1_o       37\n",
       "amb2_1_o         9\n",
       "shar2_1_o        9\n",
       "attr3_1_o       24\n",
       "sinc3_1_o       24\n",
       "intel3_1_o      24\n",
       "fun3_1_o        24\n",
       "amb3_1_o        24\n",
       "attr4_1_o     1448\n",
       "sinc4_1_o     1448\n",
       "intel4_1_o    1448\n",
       "fun4_1_o      1448\n",
       "amb4_1_o      1448\n",
       "shar4_1_o     1467\n",
       "attr5_1_o     2700\n",
       "sinc5_1_o     2700\n",
       "intel5_1_o    2700\n",
       "fun5_1_o      2700\n",
       "amb5_1_o      2700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()[X_train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54694bc9-e26d-4ffe-ae53-976a994143a0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "All remaining columns with missing data are the questionnaire columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "337f2d79-5fc4-4c3a-a386-60f434a81342",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6560.00</td>\n",
       "      <td>6552.00</td>\n",
       "      <td>6536.00</td>\n",
       "      <td>6547.00</td>\n",
       "      <td>6547.00</td>\n",
       "      <td>6547.00</td>\n",
       "      <td>6547.00</td>\n",
       "      <td>6547.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.60</td>\n",
       "      <td>17.34</td>\n",
       "      <td>20.28</td>\n",
       "      <td>17.42</td>\n",
       "      <td>10.69</td>\n",
       "      <td>11.82</td>\n",
       "      <td>7.09</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.41</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.63</td>\n",
       "      <td>7.03</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.11</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>20.00</td>\n",
       "      <td>18.18</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.64</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        attr1_1  sinc1_1  intel1_1   fun1_1   amb1_1  shar1_1  attr3_1  \\\n",
       "count   6568.00  6568.00   6568.00  6560.00  6552.00  6536.00  6547.00   \n",
       "mean      22.60    17.34     20.28    17.42    10.69    11.82     7.09   \n",
       "std       12.63     7.03      6.83     6.11     6.07     6.36     1.40   \n",
       "min        0.00     0.00      0.00     0.00     0.00     0.00     2.00   \n",
       "max      100.00    60.00     50.00    50.00    53.00    30.00    10.00   \n",
       "median    20.00    18.18     20.00    18.00    10.00    10.64     7.00   \n",
       "\n",
       "        sinc3_1  intel3_1   fun3_1   amb3_1  \n",
       "count   6547.00   6547.00  6547.00  6547.00  \n",
       "mean       8.29      8.41     7.70     7.58  \n",
       "std        1.42      1.08     1.57     1.79  \n",
       "min        2.00      3.00     2.00     2.00  \n",
       "max       10.00     10.00    10.00    10.00  \n",
       "median     8.00      8.00     8.00     8.00  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cols_questionnaire1 + cols_questionnaire3].custom.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ddff99c-afdb-4b37-b87c-81a0dec78593",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Inspecting the values we can see that some questions have a higher max and mean values. This happens because of a difference in the scale. Some wave of participants were asked to answer on a scale from 1 to 10. Other waves were asked to distribute 100 points among the questions.\n",
    "\n",
    "![questionnaire_max_values.png](images/questionnaire_max_values.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0128af-845f-461e-82f9-af91d2d07678",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Since each question group must total exactly 100 points, we can't simply fill in missing values with the median. Instead, we should calculate the missing value by subtracting the sum of known responses from 100. This ensures we maintain the required 100-point total for each group.\n",
    "\n",
    "To achieve this we will calculate the sum and count of missing values for each questionnaire group. When a group has between 1-5 missing values (because the number of question is 6, the 6th answer may contain 100 points) and the existing values sum to 100, it fills the missing values with zeros, effectively distributing the questionnaire responses while preserving the total sum constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d932525-f6b4-4e3a-bb41-05c5670a2ba0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `questionnaire_impute_0` is [defined in src/imputers.py](src/imputers.py). It imputes missing values with 0 in specified subject and partner columns based on conditions: the number of NaNs in a row falls within a range (0 to 5), and the sum of non-NaN values in the row equals a given 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c45e5f5a-0557-4380-8fe8-f926a8432053",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Impute 0 because so that the sum of all answers will be 100\n",
    "X_train, X_test = questionnaire_impute_0(X_train, X_test, cols_questionnaire1, cols_questionnaire1_o, 'quest1')\n",
    "X_train, X_test = questionnaire_impute_0(X_train, X_test, cols_questionnaire2, cols_questionnaire2_o, 'quest2')\n",
    "X_train, X_test = questionnaire_impute_0(X_train, X_test, cols_questionnaire3, cols_questionnaire3_o, 'quest3', max_nan=4)\n",
    "X_train, X_test = questionnaire_impute_0(X_train, X_test, cols_questionnaire4, cols_questionnaire4_o, 'quest4')\n",
    "X_train, X_test = questionnaire_impute_0(X_train, X_test, cols_questionnaire5, cols_questionnaire5_o, 'quest5', max_nan=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b3d73-788a-4201-af63-8fc6e6e59526",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Are there any remaining missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c79f7ed-b09b-46c7-aad8-3347134df509",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attr3_1       21\n",
       "sinc3_1       21\n",
       "intel3_1      21\n",
       "fun3_1        21\n",
       "amb3_1        21\n",
       "attr3_1_o     24\n",
       "sinc3_1_o     24\n",
       "intel3_1_o    24\n",
       "fun3_1_o      24\n",
       "amb3_1_o      24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cols_questionnaire3 + cols_questionnaire3_o].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1fb119-8976-4171-84f6-db502df93d92",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Yes, impute with the median value by gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76a5b793-e7e7-4f33-83df-dab0cb73ad9a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = impute_columns_by_gender(X_train, X_test, cols_questionnaire, old_value=None)\n",
    "X_train, X_test = impute_columns_by_gender(X_train, X_test, cols_questionnaire_o, old_value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cec661-95c1-4703-9707-fb48d37f809c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 10. Normalize values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de9624d-cf7f-4ec8-b95d-3b5d47d48773",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The following sections normalize various categorical and numerical variables to make them more suitable for analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5030241f-4f49-4e6f-93ef-b570e52de102",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 10.1 Interest columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2c32e59-d9bd-4f7f-a160-a09054aea72b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music</th>\n",
       "      <th>exercise</th>\n",
       "      <th>dining</th>\n",
       "      <th>tv</th>\n",
       "      <th>tvsports</th>\n",
       "      <th>sports</th>\n",
       "      <th>shopping</th>\n",
       "      <th>yoga</th>\n",
       "      <th>gaming</th>\n",
       "      <th>reading</th>\n",
       "      <th>theater</th>\n",
       "      <th>hiking</th>\n",
       "      <th>art</th>\n",
       "      <th>museums</th>\n",
       "      <th>clubbing</th>\n",
       "      <th>concerts</th>\n",
       "      <th>movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "      <td>6568.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.86</td>\n",
       "      <td>6.27</td>\n",
       "      <td>7.79</td>\n",
       "      <td>5.31</td>\n",
       "      <td>4.59</td>\n",
       "      <td>6.42</td>\n",
       "      <td>5.65</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.89</td>\n",
       "      <td>7.67</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.74</td>\n",
       "      <td>6.73</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.84</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.79</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          music  exercise   dining       tv  tvsports   sports  shopping  \\\n",
       "count   6568.00   6568.00  6568.00  6568.00   6568.00  6568.00   6568.00   \n",
       "mean       7.86      6.27     7.79     5.31      4.59     6.42      5.65   \n",
       "std        1.79      2.42     1.76     2.53      2.81     2.63      2.61   \n",
       "min        1.00      1.00     1.00     1.00      1.00     1.00      1.00   \n",
       "max       10.00     10.00    10.00    10.00     10.00    10.00     10.00   \n",
       "median     8.00      7.00     8.00     6.00      4.00     7.00      6.00   \n",
       "\n",
       "           yoga   gaming  reading  theater   hiking      art  museums  \\\n",
       "count   6568.00  6568.00  6568.00  6568.00  6568.00  6568.00  6568.00   \n",
       "mean       4.35     3.89     7.67     6.80     5.74     6.73     7.00   \n",
       "std        2.71     2.63     2.01     2.24     2.55     2.26     2.04   \n",
       "min        1.00     1.00     1.00     1.00     1.00     1.00     1.00   \n",
       "max       10.00    14.00    13.00    10.00    10.00    10.00    10.00   \n",
       "median     4.00     3.00     8.00     7.00     6.00     7.00     7.00   \n",
       "\n",
       "        clubbing  concerts   movies  \n",
       "count    6568.00   6568.00  6568.00  \n",
       "mean        5.75      6.84     7.93  \n",
       "std         2.49      2.15     1.71  \n",
       "min         1.00      1.00     1.00  \n",
       "max        10.00     10.00    10.00  \n",
       "median      6.00      7.00     8.00  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[cols_interests].custom.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26017bbd-7df4-4a5a-a629-fc1703497370",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Although the rating scale should ranged from 1 to 10, some participants entered values above 10. We interpret these responses as attempts to express extremely high interest. To maintain consistency with our scale's maximum value, we adjusted these responses down to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3dc5a8e3-1741-4407-b198-101b2df2ce33",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    1: 1, \n",
    "    2: 2, \n",
    "    3: 3, \n",
    "    4: 4, \n",
    "    5: 5, \n",
    "    6: 6, \n",
    "    7: 7, \n",
    "    8: 8, \n",
    "    9: 9, \n",
    "    10: 10,\n",
    "    13: 10,\n",
    "    14: 10}\n",
    "\n",
    "X_train[cols_interests + cols_interests_o] = X_train[cols_interests + cols_interests_o].apply(lambda col: col.map(replacement_dict))\n",
    "X_test[cols_interests + cols_interests_o]  = X_test[cols_interests + cols_interests_o].apply(lambda col: col.map(replacement_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b587d-2c9b-4ea3-9d1a-79fbcc5a3f94",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 10.2 Dating and going out frequency (_date_, _go_out_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a9e31-31fe-45fa-9f5b-22a59637e60f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This section normalizes columns related to dating frequency and going out frequency. \n",
    "\n",
    "The current values are:\n",
    "\n",
    "In general, how frequently do you go on dates? \n",
    "- Several times a week=1\n",
    "- Twice a week=2\n",
    "- Once a week=3\n",
    "- Twice a month=4\n",
    "- Once a month=5\n",
    "- Several times a year=6\n",
    "- Almost never=7\n",
    "\n",
    "We will map the values to represent approximate number of times per year:\n",
    "- 1 → 156 (≈3 times per week)\n",
    "- 2 → 104 (≈2 times per week)\n",
    "- 3 → 52 (weekly)\n",
    "- 4 → 24 (bi-weekly)\n",
    "- 5 → 12 (monthly)\n",
    "- 6 → 6 (bi-monthly)\n",
    "- 7 → 2 (rarely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9d348e9-c7be-4090-a82e-8f2a3ccd7dd0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    1: 156, \n",
    "    2: 104, \n",
    "    3: 52, \n",
    "    4: 24, \n",
    "    5: 12, \n",
    "    6: 6, \n",
    "    7: 2\n",
    "}\n",
    "\n",
    "cols = [\"date\", \"date_o\", \"go_out\", \"go_out_o\"]\n",
    "X_train[cols] = X_train[cols].apply(lambda col: col.map(replacement_dict))\n",
    "X_test[cols] = X_test[cols].apply(lambda col: col.map(replacement_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c31c3-593c-4277-83ad-f5adf344a99f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 10.3 Importance of race and religion (_imprace_, _imprelig_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3a98d-4035-4e9f-8661-3c3b7ca2a754",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This section groups the importance of race and religion ratings into three categories (1, 2, 3) instead of the original 1-10 scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d31e08e-cca7-430b-bd6e-a3f35bc05b0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    1: 1, 2: 1, 3: 1,  # Low importance\n",
    "    4: 2, 5: 2, 6: 2,  # Medium importance\n",
    "    7: 3, 8: 3, 9: 3, 10: 3  # High importance\n",
    "}\n",
    "\n",
    "cols = ['imprace', 'imprace_o', 'imprelig', 'imprelig_o']\n",
    "X_train[cols] = X_train[cols].apply(lambda col: col.map(replacement_dict))\n",
    "X_test[cols]  = X_test[cols].apply(lambda col: col.map(replacement_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdaf6ed-936b-47aa-ab41-6ac8014d3c1f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 10.4 Goal of participating (_goal_/_goal_o_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c5d38-0bef-47b3-89e4-07929cb1f0b4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The original values are:\n",
    "\n",
    "What is your primary goal in participating in this event? \n",
    "- Seemed like a fun night out=1\n",
    "- To meet new people=2\n",
    "- To get a date=3\n",
    "- Looking for a serious relationship=4\n",
    "- To say I did it=5\n",
    "- Other=6\n",
    "\n",
    "We will simplify dating goals into three main categories:\n",
    "- 1 - I just want to have fun\n",
    "- 2 - I'm serious about finding friends or a date \n",
    "- 6 - Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96800bbf-1233-4e40-98ae-cf5e83ce18c2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    1: 1,  # Category 1 (I just want to have fun)\n",
    "    2: 2, 3: 2, 4: 2,  # Category 2 (I'm serious about finding friends or a date )\n",
    "    5: 1,  # Category 1\n",
    "    6: 99  # Category 6 (Other - kept separate)\n",
    "}\n",
    "\n",
    "cols = ['goal', 'goal_o']\n",
    "X_train[cols] = X_train[cols].apply(lambda col: col.map(replacement_dict))\n",
    "X_test[cols]  = X_test[cols].apply(lambda col: col.map(replacement_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bad936-f307-4d2a-b750-c72e59b73477",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 11. Feature engineering - add equality/difference columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a07885-3764-44e9-8f35-2d16c6a12b06",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 11.1 Equality columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df12d88-7a37-42a5-b422-c42c9c622797",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Creates binary features (0/1) by comparing if values match between pairs of subject/partner characteristics. For example, if two users are from the same city, city_eq would be 1, otherwise 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae387806-7b89-4a1a-b5d8-e629f6cb89b8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `create_equality_features`, [defined in src/feature_engineering.py](src/feature_engineering.py), creates equality features for specified columns by comparing with their '_o' pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ed1e4ca-21b4-4ac9-ab01-2212839bf958",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols = ['goal'] + ['race', 'imprace', 'imprelig'] + ['field'] + ['city', 'state_or_country']\n",
    "X_train = create_equality_features(X_train, cols)\n",
    "X_test = create_equality_features(X_test, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0999dfc8-cb9f-4aa0-ae56-22d98e4fcfa6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 11.2 Difference columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f989a-113c-438b-826e-0d33bf0ebc8f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Create a new column with the numerical gap between 'goal' values for pairs by subtracting them (goal - goal_o). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3568e862-ebc5-474d-a575-84ad9d617c49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols = ['goal']\n",
    "\n",
    "for col in cols:\n",
    "    X_train[f'{col}_diff'] = (X_train[col] - X_train[f'{col}_o'])\n",
    "    X_test[f'{col}_diff']  = (X_test[col] - X_test[f'{col}_o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c29d2-8d49-43e9-97ef-01417d73db55",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 12. Delete columns/rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d7bb1-4552-43ee-bfc0-ae6a405d383f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 12.1 Drop columns for which we calculated equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89315977-3ce0-4ec0-bdd6-513075127956",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# do not delete career and career_o, try with encoding\n",
    "cols_to_drop = []\n",
    "cols_to_drop = cols_to_drop + ['field', 'field_o', \"career\", \"career_o\"]\n",
    "cols_to_drop = cols_to_drop + ['from', 'undergra', 'city', 'city_o', 'city_eq', 'state_or_country', 'state_or_country_o']\n",
    "\n",
    "X_train = X_train.drop(columns=cols_to_drop, axis=1, errors='ignore')\n",
    "X_test = X_test.drop(columns=cols_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a63e3-8958-4dd9-99f2-5ee2310aa515",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 12.2 Delete other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7803f07-4671-456b-b780-70340ae7fc6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['iid', 'pid', 'wave', 'field_cd', 'gender_o', 'dec_o', 'samerace']\n",
    "X_train = X_train.drop(columns=cols_to_drop, axis=1, errors='ignore')\n",
    "X_test = X_test.drop(columns=cols_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11af734-4246-4893-b812-d2f7089338cf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 13. Apply scaling of the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3cfaf971-41b5-4202-86c1-3e558c57d272",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), index = X_train.index, columns=X_train.columns)\n",
    "X_test  = pd.DataFrame(scaler.transform(X_test), index = X_test.index,  columns=X_test.columns)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccf131-5b46-4b53-ac5c-f095e1a0afde",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 14. Choose a metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b50505-3e19-4e31-a759-aa88a5e5ab07",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "In developing a machine learning model for a dating app, our goal is to accurately predict good matches between registered users based on their questionnaire responses. To ensure a positive user experience, we must prioritize **minimizing false positives**, where the model might suggest a match that isn't actually compatible. This approach aligns with maximizing **precision** - the proportion of predicted matches that are genuinely good matches. \n",
    "\n",
    "However, maximizing precision alone could result in very low recall, meaning we might overlook many potential good matches. To address this, we aim to establish a balanced approach that maintains high precision while retaining enough recall to avoid missing too many viable connections. To achieve this balance, we will implement a custom weighted metric that assigns 70% weight to precision and 30% to recall, guiding the model to focus on accurate match predictions while also allowing for a reasonable level of inclusivity in recommendations. This approach aligns with our objective of quality over quantity, but not at the expense of completely disregarding potentially good matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7d6b2-37ec-4508-a14a-49e4b0f48e4c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 14.1 Define a custom weighted metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43d97c-cd2d-4304-9926-afdd0d62b44d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The default F1 score assigns equal weights to precision and recall. In order to achieve our goal of having 70% weight on the precision, we will define a **weighted F1-score** (also called the $ F_{\\beta} $-score).\n",
    "\n",
    "To calculate it, we can use the following formula:\n",
    "\n",
    "$$\n",
    "F_{\\text{weighted}} = \\frac{(1 + \\beta^2) \\times \\text{Precision} \\times \\text{Recall}}{(\\beta^2 \\times \\text{Precision}) + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\beta $ is a parameter that represents the weight given to recall relative to precision. A smaller $ \\beta $ (less than 1) puts more weight on precision, while a larger $ \\beta $ (greater than 1) favors recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd8a4c-b985-4329-ac30-7162f657d2f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 14.2 Determine $ \\beta $ Based on the Precision-Recall Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a176881-d5f0-464f-ae0d-1227984b8686",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We need to calculate $ \\beta $ such that precision gets a weight of 0.7 and recall gets a weight of 0.3. We can achieve this using the formula:\n",
    "\n",
    "   $$\n",
    "   \\beta = \\sqrt{\\frac{1 - \\text{Precision weight}}{\\text{Precision weight}}} = \\sqrt{\\frac{1 - 0.7}{0.7}} \\approx 0.55\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a439b-687f-4ec1-ae53-1c5f0a59dcf6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 15. Choose a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ee927-420e-4f79-8fc6-8615a8298ed1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "First, we will train several base models using their default hyperparameters. The performance of these models will be evaluated using cross validation with the $F_{\\beta}$ score as the metric.\n",
    "\n",
    "Based on the $F_{\\beta}$ score from cross-validation, the top 5 models will be selected for further fine-tuning. These models will be trained with an expanded set of hyperparameters to improve their performance.\n",
    "\n",
    "Among the fine-tuned models, the one with the highest $F_{\\beta}$ score will be chosen as the final model. This model will then be used to make predictions (`y_pred`) on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6378b-4b40-4b51-acc6-c21695ef4b1e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 15.1 Train base models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68631ec1-3b4a-45ef-8580-5b32af6a7a00",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Define base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cdda8c3a-1c12-47aa-860e-b09defa78799",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "log_reg_param_grid = {\"model\": [LogisticRegression(random_state=RANDOM_STATE)], \"model__max_iter\": [1000]}\n",
    "hgbc_param_grid    = {\"model\": [HistGradientBoostingClassifier(random_state=RANDOM_STATE)]}\n",
    "rf_param_grid      = {\"model\": [RandomForestClassifier(random_state=RANDOM_STATE)]}\n",
    "svc_param_grid     = {\"model\": [SVC(random_state=RANDOM_STATE)]}\n",
    "knn_param_grid     = {\"model\": [KNeighborsClassifier()]}\n",
    "gb_param_grid      = {\"model\": [GradientBoostingClassifier(random_state=RANDOM_STATE)]}\n",
    "dt_param_grid      = {\"model\": [DecisionTreeClassifier(random_state=RANDOM_STATE)]}\n",
    "pac_param_grid     = {\"model\": [PassiveAggressiveClassifier(random_state=RANDOM_STATE)]}\n",
    "lda_param_grid     = {\"model\": [LinearDiscriminantAnalysis()]}\n",
    "xgb_param_grid     = {\"model\": [XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE)]}\n",
    "perceptron_param_grid = {\"model\": [Perceptron(random_state=RANDOM_STATE)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8a0fe-70b2-45bf-b4a7-7a38ab3b70f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Define base parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50c829a0-7e4f-4634-b0ab-454b8c0e6141",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "param_grid_base = [\n",
    "    {**log_reg_param_grid},\n",
    "    {**rf_param_grid},\n",
    "    {**xgb_param_grid},\n",
    "    {**hgbc_param_grid},\n",
    "    {**gb_param_grid},\n",
    "    {**svc_param_grid},\n",
    "    {**knn_param_grid},\n",
    "    {**dt_param_grid},\n",
    "    {**perceptron_param_grid},\n",
    "    {**pac_param_grid},\n",
    "    {**lda_param_grid},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cca379-8fe2-4a20-b2a8-450ecb12cab6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Evaluate base models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da442d-5229-4b2a-8634-cdbf3a1aa4f0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The function `evaluate_parameter_grid`, [defined in src/create_evaluate_pipeline.py](src/create_evaluate_pipeline.py), implements a caching system to optimize the evaluation of machine learning model parameters. When evaluating different parameter combinations (which can be computationally expensive and time-consuming), it stores previously computed results in a cache (file `params_cache.josn`) to avoid redundant computations on the next run of the notebook. For each parameter combination, it generates a unique hash (params_hash) that serves as a cache key. The cache stores two separate components: the evaluation scores in the json file, and the fitted model parameters in individual pickle files (folder `param_grid_pkl`). When the function encounters a parameter combination that has been previously evaluated (by checking its hash), it retrieves the cached scores directly, skipping the expensive training process. If the combination hasn't been cached, it proceeds with training the model, evaluating it, and then saves both the scores and model parameters to the cache for future use. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c089fc-b602-4ff7-a398-79bde6ae717e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The cache file looks like this:\n",
    "```json\n",
    "{\n",
    "    \"af99c4a36af029aa5413c8987d78d5b4\": {\n",
    "        \"scores\": {\n",
    "            \"weighted_fbeta\": \"0.5401\",\n",
    "            \"precision\": \"0.6171\",\n",
    "            \"recall\": \"0.6045\"\n",
    "        },\n",
    "        \"selected_featured\": null\n",
    "    },\n",
    "    \"524d96d1aa92eb64ae3bcf9803ebe31f\": {\n",
    "        \"scores\": {\n",
    "            \"weighted_fbeta\": \"0.6500\",\n",
    "            \"precision\": \"0.6987\",\n",
    "            \"recall\": \"0.6912\"\n",
    "        },\n",
    "        \"selected_featured\": null\n",
    "    },\n",
    "\n",
    "...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9381c7e-839a-4ad7-81a6-fded7ca0cf63",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<div style=\"background-color:moccasin\">\n",
    "\n",
    "⚠️\n",
    "**Note** that due to the large size (over 4GB in total), we've only included the .pkl files for the top 5 performing models. However, the entire notebook can be run very quickly because of the the pre-computed scores stored in `params_cache.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e89a41e0-e275-4843-8be1-85e2b68a0d8d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating several base models: \n",
      "Evaluating model 1, combination 1/1: Weighted fbeta score: 0.5401 (from cache af99c4a36af029aa5413c8987d78d5b4). Best score so far: 0.5401\n",
      "Evaluating model 2, combination 1/1: Weighted fbeta score: 0.6419 (from cache 0c698364e7d3b873fd124ac7cc7fdd0d). Best score so far: 0.6419\n",
      "Evaluating model 3, combination 1/1: Weighted fbeta score: 0.6500 (from cache 524d96d1aa92eb64ae3bcf9803ebe31f). Best score so far: 0.65\n",
      "Evaluating model 4, combination 1/1: Weighted fbeta score: 0.6564 (from cache 396b5d2c4b361f06330d6a7c9a4e8eb7). Best score so far: 0.6564\n",
      "Evaluating model 5, combination 1/1: Weighted fbeta score: 0.6248 (from cache 180869454fce5727450a365af6a2481a). Best score so far: 0.6564\n",
      "Evaluating model 6, combination 1/1: Weighted fbeta score: 0.5872 (from cache 581986bc09cafe0da4491a0a461edd90). Best score so far: 0.6564\n",
      "Evaluating model 7, combination 1/1: Weighted fbeta score: 0.5838 (from cache 349c15d5a9aee5616d05e96e791367ea). Best score so far: 0.6564\n",
      "Evaluating model 8, combination 1/1: Weighted fbeta score: 0.5443 (from cache c0cc3b4dc2a35a11d6ef5b840b702f05). Best score so far: 0.6564\n",
      "Evaluating model 9, combination 1/1: Weighted fbeta score: 0.3875 (from cache 0d74a43d730b306a6b2eb4169fc57fc8). Best score so far: 0.6564\n",
      "Evaluating model 10, combination 1/1: Weighted fbeta score: 0.2939 (from cache b2ab84bc692659e468183f4d08f2ea76). Best score so far: 0.6564\n",
      "Evaluating model 11, combination 1/1: Weighted fbeta score: 0.5376 (from cache 7faef113590a6eecd1821837ac7bdb5a). Best score so far: 0.6564\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating several base models: \")\n",
    "results_base = evaluate_parameter_grid(param_grid_base, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8d14d-da8a-4703-9be9-0af31daf4a88",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 15.2 Select and hypertune top 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879e79a0-1b3b-4471-8e6d-1ff52e10b3fd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Select top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "afa7ebcc-a2ac-4902-9843-ad553856ca13",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 base models: \n",
      "\u001b[35mRank 1/11 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6564, \u001b[0mPrecision: 0.7052, Recall: 0.6924\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: HistGradientBoostingClassifier, \n",
      "\u001b[36mcategorical_features\u001b[0m: warn, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mearly_stopping\u001b[0m: auto, \u001b[36minteraction_cst\u001b[0m: None, \u001b[36ml2_regularization\u001b[0m: 0.0, \u001b[36mlearning_rate\u001b[0m: 0.1, \u001b[36mloss\u001b[0m: log_loss, \u001b[36mmax_bins\u001b[0m: 255, \u001b[36mmax_depth\u001b[0m: None, \u001b[36mmax_features\u001b[0m: 1.0, \u001b[36mmax_iter\u001b[0m: 100, \u001b[36mmax_leaf_nodes\u001b[0m: 31, \u001b[36mmin_samples_leaf\u001b[0m: 20, \u001b[36mmonotonic_cst\u001b[0m: None, \u001b[36mn_iter_no_change\u001b[0m: 10, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mscoring\u001b[0m: loss, \u001b[36mtol\u001b[0m: 1e-07, \u001b[36mvalidation_fraction\u001b[0m: 0.1, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n",
      "\u001b[35mRank 2/11 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6500, \u001b[0mPrecision: 0.6987, Recall: 0.6912\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: XGBClassifier, \n",
      "\u001b[36mobjective\u001b[0m: binary:logistic, \u001b[36mbase_score\u001b[0m: None, \u001b[36mbooster\u001b[0m: None, \u001b[36mcallbacks\u001b[0m: None, \u001b[36mcolsample_bylevel\u001b[0m: None, \u001b[36mcolsample_bynode\u001b[0m: None, \u001b[36mcolsample_bytree\u001b[0m: None, \u001b[36mdevice\u001b[0m: None, \u001b[36mearly_stopping_rounds\u001b[0m: None, \u001b[36menable_categorical\u001b[0m: False, \u001b[36meval_metric\u001b[0m: None, \u001b[36mfeature_types\u001b[0m: None, \u001b[36mgamma\u001b[0m: None, \u001b[36mgrow_policy\u001b[0m: None, \u001b[36mimportance_type\u001b[0m: None, \u001b[36minteraction_constraints\u001b[0m: None, \u001b[36mlearning_rate\u001b[0m: None, \u001b[36mmax_bin\u001b[0m: None, \u001b[36mmax_cat_threshold\u001b[0m: None, \u001b[36mmax_cat_to_onehot\u001b[0m: None, \u001b[36mmax_delta_step\u001b[0m: None, \u001b[36mmax_depth\u001b[0m: None, \u001b[36mmax_leaves\u001b[0m: None, \u001b[36mmin_child_weight\u001b[0m: None, \u001b[36mmissing\u001b[0m: nan, \u001b[36mmonotone_constraints\u001b[0m: None, \u001b[36mmulti_strategy\u001b[0m: None, \u001b[36mn_estimators\u001b[0m: None, \u001b[36mn_jobs\u001b[0m: None, \u001b[36mnum_parallel_tree\u001b[0m: None, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mreg_alpha\u001b[0m: None, \u001b[36mreg_lambda\u001b[0m: None, \u001b[36msampling_method\u001b[0m: None, \u001b[36mscale_pos_weight\u001b[0m: None, \u001b[36msubsample\u001b[0m: None, \u001b[36mtree_method\u001b[0m: None, \u001b[36mvalidate_parameters\u001b[0m: None, \u001b[36mverbosity\u001b[0m: None, \n",
      "\n",
      "\u001b[35mRank 3/11 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6419, \u001b[0mPrecision: 0.7003, Recall: 0.6743\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: RandomForestClassifier, \n",
      "\u001b[36mbootstrap\u001b[0m: True, \u001b[36mccp_alpha\u001b[0m: 0.0, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mcriterion\u001b[0m: gini, \u001b[36mmax_depth\u001b[0m: None, \u001b[36mmax_features\u001b[0m: sqrt, \u001b[36mmax_leaf_nodes\u001b[0m: None, \u001b[36mmax_samples\u001b[0m: None, \u001b[36mmin_impurity_decrease\u001b[0m: 0.0, \u001b[36mmin_samples_leaf\u001b[0m: 1, \u001b[36mmin_samples_split\u001b[0m: 2, \u001b[36mmin_weight_fraction_leaf\u001b[0m: 0.0, \u001b[36mmonotonic_cst\u001b[0m: None, \u001b[36mn_estimators\u001b[0m: 100, \u001b[36mn_jobs\u001b[0m: None, \u001b[36moob_score\u001b[0m: False, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n",
      "\u001b[35mRank 4/11 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6248, \u001b[0mPrecision: 0.6892, Recall: 0.6610\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: GradientBoostingClassifier, \n",
      "\u001b[36mccp_alpha\u001b[0m: 0.0, \u001b[36mcriterion\u001b[0m: friedman_mse, \u001b[36minit\u001b[0m: None, \u001b[36mlearning_rate\u001b[0m: 0.1, \u001b[36mloss\u001b[0m: log_loss, \u001b[36mmax_depth\u001b[0m: 3, \u001b[36mmax_features\u001b[0m: None, \u001b[36mmax_leaf_nodes\u001b[0m: None, \u001b[36mmin_impurity_decrease\u001b[0m: 0.0, \u001b[36mmin_samples_leaf\u001b[0m: 1, \u001b[36mmin_samples_split\u001b[0m: 2, \u001b[36mmin_weight_fraction_leaf\u001b[0m: 0.0, \u001b[36mn_estimators\u001b[0m: 100, \u001b[36mn_iter_no_change\u001b[0m: None, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36msubsample\u001b[0m: 1.0, \u001b[36mtol\u001b[0m: 0.0001, \u001b[36mvalidation_fraction\u001b[0m: 0.1, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n",
      "\u001b[35mRank 5/11 - \u001b[0m\u001b[31mWeighted Fbeta: 0.5872, \u001b[0mPrecision: 0.6647, Recall: 0.6351\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: SVC, \n",
      "\u001b[36mC\u001b[0m: 1.0, \u001b[36mbreak_ties\u001b[0m: False, \u001b[36mcache_size\u001b[0m: 200, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mcoef0\u001b[0m: 0.0, \u001b[36mdecision_function_shape\u001b[0m: ovr, \u001b[36mdegree\u001b[0m: 3, \u001b[36mgamma\u001b[0m: scale, \u001b[36mkernel\u001b[0m: rbf, \u001b[36mmax_iter\u001b[0m: -1, \u001b[36mprobability\u001b[0m: False, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mshrinking\u001b[0m: True, \u001b[36mtol\u001b[0m: 0.001, \u001b[36mverbose\u001b[0m: False, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 base models: \")\n",
    "top_results_base = display_top_models(results_base, X_train.shape[1], top_k = 5, sort_by = 'weighted_fbeta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff70b30-4141-462c-9704-c08a1a3bf021",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Define the parameters to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c2338-efd0-41f3-af41-c3cb68c186db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Function `load_model_params`, [defined in src/helpers.py](src/helpers.py) loads a JSON file, removes comments, and returns the parsed JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87b09bd8-052c-4639-bd08-efafcd218d9d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Histogram-based Gradient Boosting Classifier\n",
    "hdbc_param_grid = {\n",
    "    \"model\": [HistGradientBoostingClassifier(random_state=RANDOM_STATE)],\n",
    "    **load_model_params(\"src/model_params/hist_gradient_boosting_cls_full.json\"),\n",
    "}\n",
    "\n",
    "# Extreme Gradient Boosting Classifier\n",
    "xgb_param_grid = {\n",
    "    \"model\": [XGBClassifier(objective=\"binary:logistic\", random_state=RANDOM_STATE)],\n",
    "    **load_model_params(\"src/model_params/xgb_cls_full.json\"),\n",
    "}\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_param_grid = {\n",
    "    \"model\": [RandomForestClassifier(random_state=RANDOM_STATE)],\n",
    "    **load_model_params(\"src/model_params/random_forest_clf_full.json\"),\n",
    "}\n",
    "\n",
    "# Gradient Boosting Classifier - slow\n",
    "gb_param_grid = {\n",
    "    \"model\": [GradientBoostingClassifier(random_state=RANDOM_STATE)],\n",
    "    **load_model_params(\"src/model_params/gradient_boosting_clf_full.json\"),\n",
    "}\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_param_grid = {\n",
    "    \"model\": [SVC(random_state=RANDOM_STATE)], \n",
    "    **load_model_params(\"src/model_params/svc_clf_full.json\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a83ec-3e60-4cac-a309-5566227fa566",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Define parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b86be1d-312c-49fd-ac14-4dc4d8ffe1c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "param_grid_top5 = [\n",
    "    {** hdbc_param_grid},\n",
    "    {** xgb_param_grid}, \n",
    "    {** rf_param_grid},\n",
    "    {** gb_param_grid},  \n",
    "    {** svc_param_grid},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f370232-075d-4d3a-96d8-dbddd31cb656",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Evaluate the top 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d0500de-aa1c-47b7-9278-75f8dca98766",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning and evaluating top 5 models: \n",
      "Evaluating model 1, combination 1/144: Weighted fbeta score: 0.6552 (from cache b7f4a657627f5d49f846aadc78260cc5). Best score so far: 0.6552\n",
      "Evaluating model 1, combination 2/144: Weighted fbeta score: 0.6530 (from cache 8a4240ea0990461c85f07b0c6a37d0c3). Best score so far: 0.6552\n",
      "Evaluating model 1, combination 3/144: Weighted fbeta score: 0.6580 (from cache dd4257bd740e929683ebfe508add217d). Best score so far: 0.658\n",
      "Evaluating model 1, combination 4/144: Weighted fbeta score: 0.5457 (from cache 4b7154d65fb64e68ebff4510dce86ccb). Best score so far: 0.658\n",
      "Evaluating model 1, combination 5/144: Weighted fbeta score: 0.5456 (from cache 7f0120d07835c96ee8c678c0ed0f69cf). Best score so far: 0.658\n",
      "Evaluating model 1, combination 6/144: Weighted fbeta score: 0.5449 (from cache f18e310dab8911fc9692fae6e507802f). Best score so far: 0.658\n",
      "Evaluating model 1, combination 7/144: Weighted fbeta score: 0.6514 (from cache bbb3e70ead9ee6ff878a4919cd7800b7). Best score so far: 0.658\n",
      "Evaluating model 1, combination 8/144: Weighted fbeta score: 0.6485 (from cache b9bb72865caddedbe15e2a7a79346a0d). Best score so far: 0.658\n",
      "Evaluating model 1, combination 9/144: Weighted fbeta score: 0.6480 (from cache 5fe4ca9e4df732d89a0425bec66cd6bd). Best score so far: 0.658\n",
      "Evaluating model 1, combination 10/144: Weighted fbeta score: 0.6595 (from cache 1248b6c17a6055fa956af6e9e80fefa8). Best score so far: 0.6595\n",
      "Evaluating model 1, combination 11/144: Weighted fbeta score: 0.6591 (from cache 720d8b2c556f1ff3f93329812be8614c). Best score so far: 0.6595\n",
      "Evaluating model 1, combination 12/144: Weighted fbeta score: 0.6606 (from cache 308f95882d9fab61b44f429a7dd85507). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 13/144: Weighted fbeta score: 0.6452 (from cache dc0abb5bd90eba61ccfcb8a5b27deeb6). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 14/144: Weighted fbeta score: 0.6526 (from cache fbcb978f9093cfdf61e5957ba1338fdf). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 15/144: Weighted fbeta score: 0.6529 (from cache af8cb4123bbe3931eda448eac7745aff). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 16/144: Weighted fbeta score: 0.5476 (from cache 98179bc1b1aabbf5351ecee154637c11). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 17/144: Weighted fbeta score: 0.5475 (from cache 3d1604fb35ce2c9a9c0c7fe7fadf747b). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 18/144: Weighted fbeta score: 0.5445 (from cache ddef4e4f9303ef8dfd03f1ba8575dbde). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 19/144: Weighted fbeta score: 0.6482 (from cache 5c155d1fd34f83b6a6d93f58d998110e). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 20/144: Weighted fbeta score: 0.6516 (from cache 1706cee0f1026c9fa2787566d324e241). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 21/144: Weighted fbeta score: 0.6539 (from cache 10e57d932fae18a45772f286a567734a). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 22/144: Weighted fbeta score: 0.6572 (from cache f8a01b73124201307071d1351daaf96d). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 23/144: Weighted fbeta score: 0.6563 (from cache 1507db81edd77ce36467a4d0f0977c50). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 24/144: Weighted fbeta score: 0.6543 (from cache 6b16f9ffbb57e8c4be6dcd48897ff16f). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 25/144: Weighted fbeta score: 0.6567 (from cache 974f35f85834f789451e2601f835feac). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 26/144: Weighted fbeta score: 0.6513 (from cache 9ed2ea0fafd558403898501911942bd9). Best score so far: 0.6606\n",
      "Evaluating model 1, combination 27/144: Weighted fbeta score: 0.6635 (from cache 99347643fbe32da8bd89afb597ac42b0). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 28/144: Weighted fbeta score: 0.5460 (from cache f8a4d2a5c4394d78d756f9a266c0bb28). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 29/144: Weighted fbeta score: 0.5460 (from cache 0b45e4823d01edd13fb138b89581daf9). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 30/144: Weighted fbeta score: 0.5455 (from cache b1facf8cc3ebc389620a833c6cb110b7). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 31/144: Weighted fbeta score: 0.6460 (from cache c51a1b0f9c09e35359b9904f222c092d). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 32/144: Weighted fbeta score: 0.6492 (from cache a4a30b96fb87491890f4125ba1f873a0). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 33/144: Weighted fbeta score: 0.6487 (from cache 1bee94119999cd03b82510e661fbd033). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 34/144: Weighted fbeta score: 0.6595 (from cache ce554dd41ae6d5cfb4813381842b269f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 35/144: Weighted fbeta score: 0.6610 (from cache 2d97b4e5d14b43530dcc01086300643a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 36/144: Weighted fbeta score: 0.6567 (from cache 79e3470d4f6b9aef414e3293b708f814). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 37/144: Weighted fbeta score: 0.6494 (from cache b4c0bf4e91824ddc67f5b4bffd9d711b). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 38/144: Weighted fbeta score: 0.6633 (from cache 1b548e62eafd24d0b74ffb3e8aa284ff). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 39/144: Weighted fbeta score: 0.6609 (from cache 62ea1e70d66dc8400eaff1a8a3163029). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 40/144: Weighted fbeta score: 0.5473 (from cache e5ea62379551051834f059b68cae8eeb). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 41/144: Weighted fbeta score: 0.5473 (from cache b6a0fc2c02712a92fe4e7c48028e5d28). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 42/144: Weighted fbeta score: 0.5459 (from cache 35c05464b22713de592b27de5fbdd1cd). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 43/144: Weighted fbeta score: 0.6448 (from cache d617a8f6b0234e110cf2c1f5a175e50b). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 44/144: Weighted fbeta score: 0.6525 (from cache 6fb2ae8c318d6c45b0b3b0244f99f345). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 45/144: Weighted fbeta score: 0.6483 (from cache 615b6c931188659dafba5d8fcd823db0). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 46/144: Weighted fbeta score: 0.6608 (from cache 9e3c2174e554f14fbb1e99a5dcc5160d). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 47/144: Weighted fbeta score: 0.6570 (from cache 341d293219be26db85a5c78b793a4c27). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 48/144: Weighted fbeta score: 0.6609 (from cache 7198cbf40e2a6ef5dd6a74ca61f32b3f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 49/144: Weighted fbeta score: 0.6583 (from cache bbf17db86219ebab6e7000f9826d1eaa). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 50/144: Weighted fbeta score: 0.6581 (from cache f81b0c9613472df2673f751a7e0d18de). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 51/144: Weighted fbeta score: 0.6589 (from cache c7ef2a47b569237d86fc2b7355ad9cdb). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 52/144: Weighted fbeta score: 0.5406 (from cache 632933bf0dbb85ea32bf7ba8f589e123). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 53/144: Weighted fbeta score: 0.5406 (from cache 898a00f0a3b464eb223d411428bb1d3c). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 54/144: Weighted fbeta score: 0.5406 (from cache d1a0a559756c9a99dac0d01076ee5ea6). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 55/144: Weighted fbeta score: 0.6483 (from cache 894b125f5dccdf2204cb52b0b421c0df). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 56/144: Weighted fbeta score: 0.6491 (from cache 1238847f6dea11ede8fab8de15f7465a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 57/144: Weighted fbeta score: 0.6448 (from cache cceb4eeb04ebfbec54c45e4dba3c1160). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 58/144: Weighted fbeta score: 0.6558 (from cache f95c9886c6eb071fadb634ffbad93e2a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 59/144: Weighted fbeta score: 0.6614 (from cache 90dc9b6dd40184ced82a88e400482e25). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 60/144: Weighted fbeta score: 0.6589 (from cache cab0b858fb716acb856434e34e0bd263). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 61/144: Weighted fbeta score: 0.6569 (from cache c88192197a1af4fda44e880cd2268bc6). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 62/144: Weighted fbeta score: 0.6571 (from cache ef5a533c34bb7856ec31e25ec30123b2). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 63/144: Weighted fbeta score: 0.6564 (from cache 149d7c4fff16540f2fcb823334bdb455). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 64/144: Weighted fbeta score: 0.5400 (from cache 98694aa16d6a68634ef793d28be3106e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 65/144: Weighted fbeta score: 0.5400 (from cache ce4dd3776b0f8652ea11f565dbb6b64e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 66/144: Weighted fbeta score: 0.5400 (from cache 46aacd6dedbe82a252481615ff74fa28). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 67/144: Weighted fbeta score: 0.6467 (from cache 8dc2b5bb9bf125cab6f983f225b96d4a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 68/144: Weighted fbeta score: 0.6515 (from cache e5de56ad4ce459cf1dda1e9c29aa3227). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 69/144: Weighted fbeta score: 0.6451 (from cache b35659b3b52d8296ab3e703a252a463f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 70/144: Weighted fbeta score: 0.6630 (from cache f945c56f21dec1530a4bca6f1dcc0a10). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 71/144: Weighted fbeta score: 0.6624 (from cache fb339d7a22c208936d8e5002a5c726c4). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 72/144: Weighted fbeta score: 0.6569 (from cache bbdb2f424974416c1d75b5642eb994aa). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 73/144: Weighted fbeta score: 0.6456 (from cache abbcbf24f13f4bfe027b3a9f6994deea). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 74/144: Weighted fbeta score: 0.6582 (from cache 72e779cc06a72a8ddd098e86509aa10e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 75/144: Weighted fbeta score: 0.6552 (from cache 0e4f77187dba8760c6dba9dc16cb436d). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 76/144: Weighted fbeta score: 0.5817 (from cache 38557eb07002c40a23889a421746f788). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 77/144: Weighted fbeta score: 0.5810 (from cache d75d72d32224e56c1b8fa8ba75f907cc). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 78/144: Weighted fbeta score: 0.5793 (from cache 1edab39ff120c038817ea3160c61eb39). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 79/144: Weighted fbeta score: 0.6437 (from cache 13d267719ae57991137f9ae2d0ba9b1f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 80/144: Weighted fbeta score: 0.6417 (from cache 636a0e76722933f369a929ac348139a2). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 81/144: Weighted fbeta score: 0.6485 (from cache 2919801889fad2a9856ece037afd88ec). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 82/144: Weighted fbeta score: 0.6529 (from cache 5780108dc4362ac13b6fc51dc9bffcc6). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 83/144: Weighted fbeta score: 0.6539 (from cache f46a2c695ae1965a0fd81353fb89d4b3). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 84/144: Weighted fbeta score: 0.6570 (from cache 64f10ae74e108e81128e45ae9ee2864b). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 85/144: Weighted fbeta score: 0.6480 (from cache ab59793348a78c97809f1f381299ab7e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 86/144: Weighted fbeta score: 0.6477 (from cache 53c5182be3109d4f15ee4b76504223eb). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 87/144: Weighted fbeta score: 0.6576 (from cache ab15f0ac9d59c9e24b5d24c7a559e616). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 88/144: Weighted fbeta score: 0.5819 (from cache 016a863c411474ddfc89ec6aab572271). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 89/144: Weighted fbeta score: 0.5812 (from cache 9eb531beaf6b583ddb0c017e3da6075f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 90/144: Weighted fbeta score: 0.5792 (from cache 7f4cbbe5503eda7783b3a258977a96ce). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 91/144: Weighted fbeta score: 0.6419 (from cache 32a7b7cfec3e02fc06682d76d03ea910). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 92/144: Weighted fbeta score: 0.6401 (from cache a69c13c0676aa9f3522a044d0e996c6e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 93/144: Weighted fbeta score: 0.6464 (from cache 81a365fe22413ab9e6ccf8e9eff7a04d). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 94/144: Weighted fbeta score: 0.6531 (from cache 08d0ff8b0fb04f67dc7f0ed57d8a05b5). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 95/144: Weighted fbeta score: 0.6594 (from cache b1443b9e5dec764d0edf38dfcb43a795). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 96/144: Weighted fbeta score: 0.6566 (from cache 97613605addfff51538ede5d1eb6366f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 97/144: Weighted fbeta score: 0.6579 (from cache 5995b145e6768231a22ae8f55a63149e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 98/144: Weighted fbeta score: 0.6565 (from cache ae5dbdd102574253f03ad10d5eb63879). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 99/144: Weighted fbeta score: 0.6552 (from cache 7ec34b4645478f46550a14a777a6b35a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 100/144: Weighted fbeta score: 0.5811 (from cache e69e34ac1100ff012749cd62f0185c7e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 101/144: Weighted fbeta score: 0.5811 (from cache eb9671cc135d9487bc60163423594193). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 102/144: Weighted fbeta score: 0.5807 (from cache ef4643d561fceebbeb4f6e0644dc7b90). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 103/144: Weighted fbeta score: 0.6342 (from cache 91ec93b5d5f420db576f004f3cdcf759). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 104/144: Weighted fbeta score: 0.6407 (from cache c90dcb56e736f92fa6ab7423dfb668a7). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 105/144: Weighted fbeta score: 0.6403 (from cache b7cb8ffd4e0615016bb5f2aebbecfe30). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 106/144: Weighted fbeta score: 0.6556 (from cache 9488f667853b7eb061dc3d63bb4228cc). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 107/144: Weighted fbeta score: 0.6595 (from cache eca564b85f607252cddeafdf51a7638b). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 108/144: Weighted fbeta score: 0.6559 (from cache d7e9c0a5649642da4d066f9546e834d0). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 109/144: Weighted fbeta score: 0.6537 (from cache 80b76d9d23a51c169025b1d3353aed27). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 110/144: Weighted fbeta score: 0.6606 (from cache 1e15cdb5088eeae2d180b045664d6861). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 111/144: Weighted fbeta score: 0.6560 (from cache 2d663723288eb33f1b498fc6a63ac92a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 112/144: Weighted fbeta score: 0.5822 (from cache b2879145b9d983860f0346cd94f9f705). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 113/144: Weighted fbeta score: 0.5822 (from cache ac353032dba0cd6f6497127fcbf4e388). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 114/144: Weighted fbeta score: 0.5810 (from cache 0857c78c9fdf749c5008a66f58761489). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 115/144: Weighted fbeta score: 0.6363 (from cache 8073408387be624d836dfe64e6df733b). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 116/144: Weighted fbeta score: 0.6410 (from cache 165e4494f9529cb270f4ae8e84182966). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 117/144: Weighted fbeta score: 0.6369 (from cache 1f5ca692f45b0e3b2f71c76cfffe3f63). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 118/144: Weighted fbeta score: 0.6605 (from cache c74fad369d1ffde751e9e039e5ab7363). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 119/144: Weighted fbeta score: 0.6602 (from cache f143441fe88d234e24682f8c31523f17). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 120/144: Weighted fbeta score: 0.6540 (from cache b7957d8ddb53ac7ce579967e447f50a3). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 121/144: Weighted fbeta score: 0.6542 (from cache f97c8226f2615b03ab34bcf26a2a848a). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 122/144: Weighted fbeta score: 0.6554 (from cache ab0308d38012a3d1d39e736ac41695c5). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 123/144: Weighted fbeta score: 0.6578 (from cache a699f17eea4e6f41aca631c4c17bf4fb). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 124/144: Weighted fbeta score: 0.5795 (from cache 8496d450e12a7e9bfd0230f01642d52c). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 125/144: Weighted fbeta score: 0.5795 (from cache f5807a9e4318fff76446afaa90f785de). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 126/144: Weighted fbeta score: 0.5795 (from cache 211f3e7e01becfefcd3b50d0411c7836). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 127/144: Weighted fbeta score: 0.6394 (from cache 6e48509c55af1c9912c0f61be8142879). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 128/144: Weighted fbeta score: 0.6386 (from cache 510b9b8544f7500cab4daa3ceead5f25). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 129/144: Weighted fbeta score: 0.6385 (from cache 0580bd50975bf838207d73c509b48edb). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 130/144: Weighted fbeta score: 0.6615 (from cache c9ad3f28f9abfdfa08e74e78afddc5a3). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 131/144: Weighted fbeta score: 0.6551 (from cache 5b4147b4f5091e35a39f7ff9fd96649c). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 132/144: Weighted fbeta score: 0.6547 (from cache ce18f71f524e26c111de9294521b0eec). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 133/144: Weighted fbeta score: 0.6529 (from cache 85d71227ba7632724a9bb32fa694e0a7). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 134/144: Weighted fbeta score: 0.6555 (from cache 458c6c2d0017ae91e26aed8a1ac49659). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 135/144: Weighted fbeta score: 0.6560 (from cache dd854d36fa8255a2a130f405aed3b85d). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 136/144: Weighted fbeta score: 0.5795 (from cache c205ae65f3ef2128160497deffaca009). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 137/144: Weighted fbeta score: 0.5795 (from cache 0bf37dd78aa75fc138ad5797e415695e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 138/144: Weighted fbeta score: 0.5795 (from cache 7d7367c29bb59d34d8b481a25997336f). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 139/144: Weighted fbeta score: 0.6375 (from cache 2aa7d4358f975cb3632f7174c3e9ca19). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 140/144: Weighted fbeta score: 0.6377 (from cache 61932394309a429a0a25397e6b60029e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 141/144: Weighted fbeta score: 0.6363 (from cache e505a782360c9269b3cfde31d2db2932). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 142/144: Weighted fbeta score: 0.6564 (from cache 3388f02bfbedcac413c33139908c92d6). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 143/144: Weighted fbeta score: 0.6548 (from cache 38e85e8b093f09471dffd7fdefa1bc5e). Best score so far: 0.6635\n",
      "Evaluating model 1, combination 144/144: Weighted fbeta score: 0.6542 (from cache d8ee34b7057ef15fc1f13c605ff14868). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 1/1200: Weighted fbeta score: 0.6484 (from cache e4beed9beea0d1ed34613910ef8846b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 2/1200: Weighted fbeta score: 0.6628 (from cache 6a919ffcbd47ffebd491308418cef72e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 3/1200: Weighted fbeta score: 0.6601 (from cache a560bd6492cdb7747d5cc5a49f14c4dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 4/1200: Weighted fbeta score: 0.6512 (from cache 340b5688da8b081f591902fe78e52df4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 5/1200: Weighted fbeta score: 0.6579 (from cache 8b52914c9cf6d4da9e235f7c6d08d316). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 6/1200: Weighted fbeta score: 0.6601 (from cache d2900ac48ba843080a99e25f4c8d51b6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 7/1200: Weighted fbeta score: 0.6489 (from cache 450e29faf86d10aa02abb8cf495b1d9e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 8/1200: Weighted fbeta score: 0.6569 (from cache 98cfa7d32036f5abe0f92cd0d277bbf3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 9/1200: Weighted fbeta score: 0.6571 (from cache 1e48715ed458d8dae9f079ce85ef3dfd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 10/1200: Weighted fbeta score: 0.6546 (from cache 72b18aa90020c6585a793a0de0a5f7d8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 11/1200: Weighted fbeta score: 0.6591 (from cache 25f265becf04078da859e6abc6340628). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 12/1200: Weighted fbeta score: 0.6617 (from cache 724c6cd2c9c3243ad6134b69f0ada40e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 13/1200: Weighted fbeta score: 0.6479 (from cache 0581a95253a7954a239ce5f7b5d62b2a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 14/1200: Weighted fbeta score: 0.6583 (from cache a6438f735d40447b4b0c13c2916979e8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 15/1200: Weighted fbeta score: 0.6544 (from cache 3aca2c2d6f75e6e157ed426aa5cd9157). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 16/1200: Weighted fbeta score: 0.6549 (from cache 3e3762ba5815dc246eb7ef4cc8fba57b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 17/1200: Weighted fbeta score: 0.6564 (from cache a78996d244b4bb553c07c39944b96e18). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 18/1200: Weighted fbeta score: 0.6577 (from cache ce0739e180a0ad4d668c192ce47922e1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 19/1200: Weighted fbeta score: 0.6546 (from cache b9cc623b82d06ba74dff56ff26c6a665). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 20/1200: Weighted fbeta score: 0.6572 (from cache 8365f2f03aefc2d57007fc93d72cb376). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 21/1200: Weighted fbeta score: 0.6570 (from cache 851a259c01c07f1faab9c6e1be1702d7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 22/1200: Weighted fbeta score: 0.6477 (from cache eec1422f81083be0b0d320646a32ee0e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 23/1200: Weighted fbeta score: 0.6476 (from cache 8ee19b45d108a9fde8c3c0da5b511cfc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 24/1200: Weighted fbeta score: 0.6448 (from cache 22bb894add57e86f039c657e5a3e1d68). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 25/1200: Weighted fbeta score: 0.6532 (from cache 630fb706265f5e5b84b7c480c26f5946). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 26/1200: Weighted fbeta score: 0.6553 (from cache 3434a113cf8ba10e02b9bb4f5c3a0dfd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 27/1200: Weighted fbeta score: 0.6564 (from cache 091441d9f9211fd37472970a5c195289). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 28/1200: Weighted fbeta score: 0.6527 (from cache ad6835aa1a5609ec9d387779b938cc40). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 29/1200: Weighted fbeta score: 0.6566 (from cache aa182d27c86a781291e52c9d84217de9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 30/1200: Weighted fbeta score: 0.6559 (from cache d65dd1773582f209801509ad9570c6c8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 31/1200: Weighted fbeta score: 0.6551 (from cache f3c891458c23f48758ed8c93a5b95096). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 32/1200: Weighted fbeta score: 0.6595 (from cache 9121479fba39e23feb06cb616305bbcf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 33/1200: Weighted fbeta score: 0.6593 (from cache be5da64840fe350a3dadc13f0f4ba8cb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 34/1200: Weighted fbeta score: 0.6539 (from cache 8e6b14223debc718623b474810acebe1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 35/1200: Weighted fbeta score: 0.6557 (from cache 335db41334073e514b6712c2b8da719f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 36/1200: Weighted fbeta score: 0.6567 (from cache c45ae2941c0f68f0d830c24a8e36c1cf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 37/1200: Weighted fbeta score: 0.6519 (from cache 5714d0f02191dd382b7dd9c519f0d135). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 38/1200: Weighted fbeta score: 0.6581 (from cache 9f88e0f64b685dbb51ac7bf549eb61be). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 39/1200: Weighted fbeta score: 0.6585 (from cache 45e269637d4428208d887058ba6cff77). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 40/1200: Weighted fbeta score: 0.6488 (from cache b6bd2c1394d0ae2ea5a710111b2582de). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 41/1200: Weighted fbeta score: 0.6552 (from cache 245c1fd20b09529f817ef655f2d5a02c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 42/1200: Weighted fbeta score: 0.6530 (from cache a8609b7ea4ac93d409a838c5f06686f2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 43/1200: Weighted fbeta score: 0.6560 (from cache ca046f718e31c75b86e143fa1494017b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 44/1200: Weighted fbeta score: 0.6617 (from cache 9d52258effbeb22f32f153ce7d7b69bb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 45/1200: Weighted fbeta score: 0.6593 (from cache bd2123b6bc0dc80d1871b13f8d81e2ce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 46/1200: Weighted fbeta score: 0.6524 (from cache 0e32381104578c37ff612d9aee7fc560). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 47/1200: Weighted fbeta score: 0.6504 (from cache 66ace5b4659bfb3b20b6254ab908c548). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 48/1200: Weighted fbeta score: 0.6515 (from cache 484a1d076802325f42ab49eb7c19fe60). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 49/1200: Weighted fbeta score: 0.6472 (from cache 6bed1845e560ff082255e92f5b3dcafa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 50/1200: Weighted fbeta score: 0.6530 (from cache 1efd26bc01aef72d2ff52539869f62f8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 51/1200: Weighted fbeta score: 0.6481 (from cache 61d3af693cc73216dab83dfadec2d238). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 52/1200: Weighted fbeta score: 0.6528 (from cache a5109c1ea4eaba158975be75d1b849f5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 53/1200: Weighted fbeta score: 0.6552 (from cache 1ca5187bf1e87150e593bca32b44bf0f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 54/1200: Weighted fbeta score: 0.6596 (from cache bd372b8eb825609e2d05b56cb32f62ca). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 55/1200: Weighted fbeta score: 0.6518 (from cache 2bf578aad061c27d3e1a1cb7d8ba8933). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 56/1200: Weighted fbeta score: 0.6534 (from cache 970185207c3241623f7143798b703abf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 57/1200: Weighted fbeta score: 0.6543 (from cache 7a1fb7b3a25c32c0aaebe30f5f8ab169). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 58/1200: Weighted fbeta score: 0.6534 (from cache 262bfcc9de6cefb9386586ca9dba0445). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 59/1200: Weighted fbeta score: 0.6559 (from cache 324e9b650e2e48ff06d3a276873b83dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 60/1200: Weighted fbeta score: 0.6529 (from cache 9fea1d00fcee7df3362404fd6b41d08e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 61/1200: Weighted fbeta score: 0.6538 (from cache c3222b415930c4f4a186fe09a161e4a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 62/1200: Weighted fbeta score: 0.6556 (from cache 33d012bc9d9c3513651f7f45972ddc3d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 63/1200: Weighted fbeta score: 0.6534 (from cache 46c1dedb4b45242b5a8644440acc7184). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 64/1200: Weighted fbeta score: 0.6516 (from cache 29022ab4697e167321d07359fcf6aa6b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 65/1200: Weighted fbeta score: 0.6563 (from cache bf48e1263bb9e871d75e79e190b2e1b0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 66/1200: Weighted fbeta score: 0.6531 (from cache 09bcc9985bd630a0fb1f5f189b629eb5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 67/1200: Weighted fbeta score: 0.6473 (from cache 7c88f145d9030f8f1f816bf8dae1e639). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 68/1200: Weighted fbeta score: 0.6552 (from cache 70fc1fa5cd996b4d5e400b75c69fee67). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 69/1200: Weighted fbeta score: 0.6586 (from cache f617c54c7c1ecc430d243145b46f6195). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 70/1200: Weighted fbeta score: 0.6511 (from cache a791bedc0d3eaeed23b9c0e9f6de209d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 71/1200: Weighted fbeta score: 0.6519 (from cache 251bdee4432e8044c26f90a7ba20726b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 72/1200: Weighted fbeta score: 0.6512 (from cache f2b64d04618c9056e599de524d68e9a6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 73/1200: Weighted fbeta score: 0.6496 (from cache 3045539f627373fbb8a15eb45acd4cea). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 74/1200: Weighted fbeta score: 0.6478 (from cache 173e86d1fef41c26ecba6dfb7ffebe1d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 75/1200: Weighted fbeta score: 0.6477 (from cache 4b5d76ef6e87aaef9585b117e987af33). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 76/1200: Weighted fbeta score: 0.6532 (from cache 9ebf37ea7fba09992410e43f94207df6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 77/1200: Weighted fbeta score: 0.6500 (from cache c875d88f3f313b118e657652e5648cfc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 78/1200: Weighted fbeta score: 0.6433 (from cache 3d228b60eda6672c74071e235a10d0b2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 79/1200: Weighted fbeta score: 0.6447 (from cache cc6745b8ebe3c6d0e9f55cf5c81c2a59). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 80/1200: Weighted fbeta score: 0.6506 (from cache bb16cbab2fa2138aa4c74109d9d9058e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 81/1200: Weighted fbeta score: 0.6521 (from cache 8beab155c9d009e6a81f2ce89de766dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 82/1200: Weighted fbeta score: 0.6524 (from cache 9678f4bbbf933b4a21efd5d59dc075f7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 83/1200: Weighted fbeta score: 0.6507 (from cache 16604bc360a6b1d804eb66201f0f168a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 84/1200: Weighted fbeta score: 0.6540 (from cache 63c5c648da9b9c4d4210c581945db00f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 85/1200: Weighted fbeta score: 0.6478 (from cache 78ca837af11123add8d33f720aa59442). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 86/1200: Weighted fbeta score: 0.6494 (from cache c5aa91b1ed324c6b7ea8d010272c4647). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 87/1200: Weighted fbeta score: 0.6529 (from cache c13724220f1ae6d07362368b60a4a418). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 88/1200: Weighted fbeta score: 0.6535 (from cache 2d5dc7cbb89cec8e0da3c5721780b994). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 89/1200: Weighted fbeta score: 0.6461 (from cache b23d1a9bfb958e5721a6ebe828ff13e4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 90/1200: Weighted fbeta score: 0.6455 (from cache 073c7a89b0af5956755b7b8ab05bc7d3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 91/1200: Weighted fbeta score: 0.6484 (from cache fc10c9286f7ef739757ce89a988189e9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 92/1200: Weighted fbeta score: 0.6558 (from cache 384a518f5d9e1aff8d8ae84f4160ed4c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 93/1200: Weighted fbeta score: 0.6541 (from cache 19db77648a62cb4ca99c93cbc32df6c0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 94/1200: Weighted fbeta score: 0.6555 (from cache 0239bc27d68f8b0479cca80c651306ce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 95/1200: Weighted fbeta score: 0.6521 (from cache 6487d62f87dfdfcbef287a52ce0a9884). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 96/1200: Weighted fbeta score: 0.6527 (from cache d2fe544ae62f5180f10590210e2fc2c4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 97/1200: Weighted fbeta score: 0.6398 (from cache cff2f67d7f56d4d3b94af924662a9a96). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 98/1200: Weighted fbeta score: 0.6485 (from cache d399cf80aec4ad6f432de7983ba705df). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 99/1200: Weighted fbeta score: 0.6470 (from cache 5f0aa62f61b3af8b30cd423ec1034090). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 100/1200: Weighted fbeta score: 0.6539 (from cache 13377d22eecbb39455caa0384e913948). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 101/1200: Weighted fbeta score: 0.6566 (from cache b548357effd9f3ab834cca9962527ae4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 102/1200: Weighted fbeta score: 0.6560 (from cache 309e0b1583420213f9ff939e64eacb38). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 103/1200: Weighted fbeta score: 0.6465 (from cache 59079d40a6a42e0bec73f54a16e760fe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 104/1200: Weighted fbeta score: 0.6478 (from cache 8944ef9f71ae77c65189aca98b79e4be). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 105/1200: Weighted fbeta score: 0.6442 (from cache 59639167c1fa51b647d49a180254ef42). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 106/1200: Weighted fbeta score: 0.6486 (from cache f0426836ea57520a6c8ea97897533148). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 107/1200: Weighted fbeta score: 0.6490 (from cache 1e799d52f3def1c3c9252ab667f0be17). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 108/1200: Weighted fbeta score: 0.6529 (from cache e5bc055f095f6110932c6420744fd39f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 109/1200: Weighted fbeta score: 0.6494 (from cache a1d9fb14632f4e6ac8d1be4bcae40afb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 110/1200: Weighted fbeta score: 0.6463 (from cache ac60019c8d1770ce371615a5d192f227). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 111/1200: Weighted fbeta score: 0.6455 (from cache 9744d779f680e9268ca8b3e9ef672f94). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 112/1200: Weighted fbeta score: 0.6499 (from cache c69a020bbea620c4b8f713f705653c1d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 113/1200: Weighted fbeta score: 0.6477 (from cache 805e4a23a680a03172e4e370f23c1560). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 114/1200: Weighted fbeta score: 0.6534 (from cache 5da0e0c607966a709f74fb2b802e47d5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 115/1200: Weighted fbeta score: 0.6493 (from cache b194e5d1f1c0852cceff9023ec3dad36). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 116/1200: Weighted fbeta score: 0.6471 (from cache b28ad07d52d297ffe5b61050eb59e5ed). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 117/1200: Weighted fbeta score: 0.6471 (from cache c3a38955fa5f1729be9a8fa8131d7885). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 118/1200: Weighted fbeta score: 0.6563 (from cache a7a3082c58f5617342ae2f3cf76d66a7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 119/1200: Weighted fbeta score: 0.6509 (from cache 9a6f8c86f87d07a7fbe170b2c748234e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 120/1200: Weighted fbeta score: 0.6541 (from cache 71d36456e4e3b41035a80d1882c93f8f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 121/1200: Weighted fbeta score: 0.6495 (from cache 2cd39f65eddef79df901db6caaab313d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 122/1200: Weighted fbeta score: 0.6507 (from cache d2c1cd5f8afd21d0d904595d11add4b0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 123/1200: Weighted fbeta score: 0.6483 (from cache 74673a4c87589f58f18747c4afc88a24). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 124/1200: Weighted fbeta score: 0.6477 (from cache 0e3af4a01a42f8718de99c90e6a6e5f5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 125/1200: Weighted fbeta score: 0.6417 (from cache 4825804a4f2ca9d73261bb735c818395). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 126/1200: Weighted fbeta score: 0.6454 (from cache afa6f56e3d3986e1c28fd8a22968ff7f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 127/1200: Weighted fbeta score: 0.6498 (from cache 2db87f1e28d77d07e550d6305a1cf1b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 128/1200: Weighted fbeta score: 0.6477 (from cache ae7ddcf554dc6d8ba1ed84bb18dec25b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 129/1200: Weighted fbeta score: 0.6560 (from cache 89e897177a431ad4e99f1a9d58b855bc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 130/1200: Weighted fbeta score: 0.6534 (from cache 75a59c573a82de5da9a5e04d2f70e5f3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 131/1200: Weighted fbeta score: 0.6492 (from cache 048d04dc5a903c5dacc15a3df6af09b7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 132/1200: Weighted fbeta score: 0.6497 (from cache 5bf616f922eeb81fcb0ea943e86bed97). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 133/1200: Weighted fbeta score: 0.6496 (from cache 3b22cf4c2de6b8acf52acf3faee390bf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 134/1200: Weighted fbeta score: 0.6525 (from cache 0c1cc8d31657649a3765702c01ba6009). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 135/1200: Weighted fbeta score: 0.6489 (from cache 1cc16eb4c810f977d94203b78697543e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 136/1200: Weighted fbeta score: 0.6452 (from cache 3329a00741133540ee683c161ac16fc4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 137/1200: Weighted fbeta score: 0.6519 (from cache 1769e02c275cf170d36bf2b1d4e243bf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 138/1200: Weighted fbeta score: 0.6508 (from cache 60345309646f6b5be4dda92db0610109). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 139/1200: Weighted fbeta score: 0.6460 (from cache a1ecc56626a33aedff2207854d81fd3f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 140/1200: Weighted fbeta score: 0.6506 (from cache 396260bba6cdc4b3613c5c7343adca5d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 141/1200: Weighted fbeta score: 0.6507 (from cache 4ff32ec9ae0fd28cd999e1812ab0aa78). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 142/1200: Weighted fbeta score: 0.6504 (from cache 597066d51a02a493b2b91782ee4f495e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 143/1200: Weighted fbeta score: 0.6492 (from cache 9980d7bb4880bd42a374615790cffdab). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 144/1200: Weighted fbeta score: 0.6487 (from cache d7041e30ea3aa954bd50e730b13e7a94). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 145/1200: Weighted fbeta score: 0.6525 (from cache ff6d5b0be2adc23a350361edba670808). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 146/1200: Weighted fbeta score: 0.6540 (from cache f75ae138a05e25db8a1c238a4ae3bebc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 147/1200: Weighted fbeta score: 0.6538 (from cache 16b5a28fb17b263c129bb898d9ab7b0c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 148/1200: Weighted fbeta score: 0.6438 (from cache 497cac26289ef7cbc90209ec98b9380a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 149/1200: Weighted fbeta score: 0.6507 (from cache adbf6fbe4ad1a0572bef70b595d20a1b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 150/1200: Weighted fbeta score: 0.6451 (from cache eb0abb259ae1aad8fa535c2904b82bcd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 151/1200: Weighted fbeta score: 0.6403 (from cache c81fafbe60ea83ef7bad855e96bad340). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 152/1200: Weighted fbeta score: 0.6451 (from cache f784ddb3fdc98b6370589c6f0ee19ae6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 153/1200: Weighted fbeta score: 0.6450 (from cache 92a31be09a25bb0da33408f8e730b4df). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 154/1200: Weighted fbeta score: 0.6539 (from cache e09efbf280d7447928b658a99099b224). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 155/1200: Weighted fbeta score: 0.6564 (from cache 6f0597a5d5b4158425edcc093c8dd26b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 156/1200: Weighted fbeta score: 0.6569 (from cache 126d56222ca9e03320c03d0d2754dab6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 157/1200: Weighted fbeta score: 0.6508 (from cache aebb1e26c9f6c7072db70d784dc66c47). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 158/1200: Weighted fbeta score: 0.6533 (from cache 48834d76f4ab92e57f937c8dd7a0d86c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 159/1200: Weighted fbeta score: 0.6464 (from cache 607eb5a69a6dd3a4848711459b77c13f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 160/1200: Weighted fbeta score: 0.6430 (from cache def18a6735dfce332b950ae43e2da561). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 161/1200: Weighted fbeta score: 0.6468 (from cache 29e65666b24a1195aa09ee180fbc830f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 162/1200: Weighted fbeta score: 0.6430 (from cache 8abab41a305d621b7299add4a58348b0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 163/1200: Weighted fbeta score: 0.6425 (from cache 0fd0ab66ad21319bf487d6daae9ca1bc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 164/1200: Weighted fbeta score: 0.6421 (from cache efaa7a60187deafb367cbc990da6168c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 165/1200: Weighted fbeta score: 0.6466 (from cache cc0a38f5b7b2119186a58050ae42fd16). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 166/1200: Weighted fbeta score: 0.6471 (from cache 244f04f8460811ec62d692fb0deee3f8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 167/1200: Weighted fbeta score: 0.6511 (from cache e1bf4ead53bbdd8bb3613fdea54fa11c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 168/1200: Weighted fbeta score: 0.6519 (from cache 01d00397db73b8c9218461e486251a1d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 169/1200: Weighted fbeta score: 0.6494 (from cache 14fed26b8b44a1799c5f46d9b3900813). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 170/1200: Weighted fbeta score: 0.6539 (from cache fc56be76e4b936b8ef12d060f2cf726a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 171/1200: Weighted fbeta score: 0.6525 (from cache 8563a46cd45e91896b49a0cc4cc970b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 172/1200: Weighted fbeta score: 0.6502 (from cache 5e64a6365c7f54de9cb8eb7dfae6fef4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 173/1200: Weighted fbeta score: 0.6468 (from cache f5e4ac2cca1f62b2b4da2a7cdd7172a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 174/1200: Weighted fbeta score: 0.6464 (from cache a96cd1a031089988d0a78edefb759154). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 175/1200: Weighted fbeta score: 0.6414 (from cache 1aae3080ac3cdbef124626278e8eb1f0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 176/1200: Weighted fbeta score: 0.6407 (from cache 369c0889c9ce69baf8120e37ede7466f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 177/1200: Weighted fbeta score: 0.6436 (from cache 9d14e001d294fab4f7ab23a596c0463b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 178/1200: Weighted fbeta score: 0.6424 (from cache 0e380bd1ccd5b346d1aabccc1463ddea). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 179/1200: Weighted fbeta score: 0.6456 (from cache a155b6d88d79645cfd32b2d1ae295aca). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 180/1200: Weighted fbeta score: 0.6488 (from cache 776b42093e7efe03e55976e604fa93c8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 181/1200: Weighted fbeta score: 0.6404 (from cache afffc4710f43d0e03ea42c5cc2d0b62c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 182/1200: Weighted fbeta score: 0.6403 (from cache c61ec9ce02ef2bd39ecd119d25cc25d2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 183/1200: Weighted fbeta score: 0.6428 (from cache 10dc95a956c89c0a14e7bd5890c564ce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 184/1200: Weighted fbeta score: 0.6471 (from cache cc4737870fa69e99ad0d7db754c3d152). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 185/1200: Weighted fbeta score: 0.6448 (from cache bbec91eab2a5ef30f159eb980f6e3267). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 186/1200: Weighted fbeta score: 0.6439 (from cache 62ac31c5ac199449f87739d199724c38). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 187/1200: Weighted fbeta score: 0.6483 (from cache 76ee5e2ea69f76c871c207add7fad069). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 188/1200: Weighted fbeta score: 0.6551 (from cache 2dc6e5fc7c69c2c380f56a61a7b6d6b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 189/1200: Weighted fbeta score: 0.6531 (from cache ad31849f5e19d6d85073ae8fdd7b2f64). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 190/1200: Weighted fbeta score: 0.6395 (from cache c6b43bc1654f17699d89feeb250ee3a3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 191/1200: Weighted fbeta score: 0.6459 (from cache ecfab22c3665e358107e035b98eab29a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 192/1200: Weighted fbeta score: 0.6490 (from cache be40f02ca9c1581bbaa1331a13a8a65a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 193/1200: Weighted fbeta score: 0.6344 (from cache fa0358c8a7b7ef02667c9993ab232e16). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 194/1200: Weighted fbeta score: 0.6415 (from cache 3cccd78ddee44e934e963e9fb5d358a8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 195/1200: Weighted fbeta score: 0.6461 (from cache 6b14a16882784d93c270a8fb67432f8c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 196/1200: Weighted fbeta score: 0.6388 (from cache 26bc28998ce979fe6802202e7e00e322). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 197/1200: Weighted fbeta score: 0.6412 (from cache 3e9b64f6bd8ef8e8f45a61d8e5fc1afc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 198/1200: Weighted fbeta score: 0.6432 (from cache 7791bf2197be27acfeb2aa07a8cf074d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 199/1200: Weighted fbeta score: 0.6431 (from cache 1c3a35410991328838d2afe6b843f0ab). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 200/1200: Weighted fbeta score: 0.6477 (from cache c9e2100b71b7ce36f201cb01fb81e6d7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 201/1200: Weighted fbeta score: 0.6509 (from cache c5ba7b96342511bc06f679c836ee1b1d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 202/1200: Weighted fbeta score: 0.6453 (from cache c842f249e753651bdff7542d84f34d43). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 203/1200: Weighted fbeta score: 0.6474 (from cache 0a43561d04858234bcfb1cf6d4519ab0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 204/1200: Weighted fbeta score: 0.6456 (from cache 52a7467c58e7ce3cf886645f58bfae58). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 205/1200: Weighted fbeta score: 0.6381 (from cache f1e4c46aa7424a1929ecf9e52221bdb8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 206/1200: Weighted fbeta score: 0.6454 (from cache 39b9146af229ca5c3e6b1b66d2efae0d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 207/1200: Weighted fbeta score: 0.6422 (from cache bf3736a9319ba0dda07b851d2e478011). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 208/1200: Weighted fbeta score: 0.6494 (from cache 929f097ef6921a72e29b0924ea45ac9a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 209/1200: Weighted fbeta score: 0.6480 (from cache aa34d9554b67cac9cf83028bb0708e27). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 210/1200: Weighted fbeta score: 0.6541 (from cache f4e4c2806752a5c684bc70d76663f606). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 211/1200: Weighted fbeta score: 0.6475 (from cache dc6ed637678fb8ce2db6814a080bd4fc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 212/1200: Weighted fbeta score: 0.6472 (from cache 5b5a9be22b02c1c94cad3115476bdfa4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 213/1200: Weighted fbeta score: 0.6521 (from cache dd1f58bd64dc9af996e539f6d80935d0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 214/1200: Weighted fbeta score: 0.6430 (from cache 7efc9f0034b276fd59d822504999fa54). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 215/1200: Weighted fbeta score: 0.6479 (from cache f281ac468915ec60daa5880af652fc48). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 216/1200: Weighted fbeta score: 0.6455 (from cache c62cd182628a9c65adece27be0b47855). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 217/1200: Weighted fbeta score: 0.6517 (from cache ca3941803452110b486ed63f30d57631). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 218/1200: Weighted fbeta score: 0.6480 (from cache c1a0caf23ab1223b4643e3ae2b689781). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 219/1200: Weighted fbeta score: 0.6502 (from cache e9681d219c4e39d9b40a5388684e3e00). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 220/1200: Weighted fbeta score: 0.6480 (from cache aa1161b257ce89337f7cc4019d0a78e3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 221/1200: Weighted fbeta score: 0.6466 (from cache 00a6a56990ef11e671feea519712b989). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 222/1200: Weighted fbeta score: 0.6492 (from cache 1bb3679d14bb9b27b7a5ee18b4047fa1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 223/1200: Weighted fbeta score: 0.6451 (from cache 33e3def4756ace57a72db0565f1aba2c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 224/1200: Weighted fbeta score: 0.6501 (from cache 141cd11d8aeda6ac5dd8dbbb03d9ce0a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 225/1200: Weighted fbeta score: 0.6479 (from cache c3744218a14334c91b72227d6e7f303f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 226/1200: Weighted fbeta score: 0.6363 (from cache cbf9f3483feec409623795436b975a37). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 227/1200: Weighted fbeta score: 0.6426 (from cache 5ee82bfb3c9267ddbc4debfb603f0e7e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 228/1200: Weighted fbeta score: 0.6463 (from cache eb3cff6dce0f6b328f1340dcda725489). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 229/1200: Weighted fbeta score: 0.6500 (from cache aec17d879746a53d5aadd9fb9171753f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 230/1200: Weighted fbeta score: 0.6409 (from cache 4f3afb320e7d79c482e40bef2655e33c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 231/1200: Weighted fbeta score: 0.6377 (from cache 390d3bc53b249830782e9f9444340b24). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 232/1200: Weighted fbeta score: 0.6492 (from cache bda17a2f2931749815b05902c187c6b6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 233/1200: Weighted fbeta score: 0.6430 (from cache 42e3e84d358e6d0412bc0df786f44fb1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 234/1200: Weighted fbeta score: 0.6446 (from cache 3653fa17d5aa59fb53c833e59f283843). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 235/1200: Weighted fbeta score: 0.6454 (from cache 516e7d0fa39f7193b7c53f6196fd491c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 236/1200: Weighted fbeta score: 0.6446 (from cache ac47d9cda006074da4f97a96212c8e24). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 237/1200: Weighted fbeta score: 0.6466 (from cache 0467c8b315d98db27b677e383460fd46). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 238/1200: Weighted fbeta score: 0.6465 (from cache 7e41f82d940d7c2787addc270ff547e8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 239/1200: Weighted fbeta score: 0.6510 (from cache 45040378c27a78ce0050a7bd946d4edc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 240/1200: Weighted fbeta score: 0.6544 (from cache a5e8f1e6c137d5b33804d0fbdc4fecb9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 241/1200: Weighted fbeta score: 0.6541 (from cache 312dd1774d50b8555696691b7754f039). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 242/1200: Weighted fbeta score: 0.6547 (from cache 04368735763d6e90b5da31f354c99948). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 243/1200: Weighted fbeta score: 0.6588 (from cache b0c4482534fc58b346ec83a3536c6923). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 244/1200: Weighted fbeta score: 0.6512 (from cache 36cfbad15be6feb69dc3ac8605981b7c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 245/1200: Weighted fbeta score: 0.6525 (from cache b70bece79eb48a67cc3adb88e4e61329). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 246/1200: Weighted fbeta score: 0.6532 (from cache 51eb3e8400212497c08fa1b3f9a0cbd1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 247/1200: Weighted fbeta score: 0.6524 (from cache 3d19ab107d866e81875e58701009c764). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 248/1200: Weighted fbeta score: 0.6546 (from cache 8f74421e1713d0db96630eeee37ea03d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 249/1200: Weighted fbeta score: 0.6513 (from cache be12623ba556192218a248adbab50cf9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 250/1200: Weighted fbeta score: 0.6586 (from cache c030c988cee24e81226a624d30d15843). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 251/1200: Weighted fbeta score: 0.6609 (from cache a34ba51d6ef5efc73430763438366492). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 252/1200: Weighted fbeta score: 0.6633 (from cache e6942c460c7ede8906d6daae512e76b8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 253/1200: Weighted fbeta score: 0.6542 (from cache 9fa1e4977cb0547e679eb0f113abe1dc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 254/1200: Weighted fbeta score: 0.6538 (from cache 173e9bb0ab18d9d91686fda06fc82cf1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 255/1200: Weighted fbeta score: 0.6533 (from cache ae58a26a3b49098c67c027d240337e45). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 256/1200: Weighted fbeta score: 0.6540 (from cache 98ceabed91735248457671b655e7977f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 257/1200: Weighted fbeta score: 0.6564 (from cache bb173fe30e59f4905d5f900874217c62). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 258/1200: Weighted fbeta score: 0.6559 (from cache 6d1e1cf7b629801c35b62be2ec8acc4d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 259/1200: Weighted fbeta score: 0.6543 (from cache 6202e7a99a6325e12f87bd3047295cbe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 260/1200: Weighted fbeta score: 0.6556 (from cache b7d8f4ad3f34504eac51aa69d76f718f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 261/1200: Weighted fbeta score: 0.6555 (from cache 0ae5846cbb68b56ad6381bcdd23049fd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 262/1200: Weighted fbeta score: 0.6583 (from cache 11ebab65ea0493052613251004ad9701). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 263/1200: Weighted fbeta score: 0.6554 (from cache fe81f5ee870a5ea6a93fd54a14efd306). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 264/1200: Weighted fbeta score: 0.6549 (from cache bf1934531892293327f51b8c3a2fa50c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 265/1200: Weighted fbeta score: 0.6560 (from cache 9a75b44c70973c327717d1fe2c16d865). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 266/1200: Weighted fbeta score: 0.6575 (from cache 39ba5becedf36d6dec989a9725d526ab). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 267/1200: Weighted fbeta score: 0.6563 (from cache aa2046e791ba00d470ad8ce066fc244a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 268/1200: Weighted fbeta score: 0.6497 (from cache b6f922125d711cb0d52d639c25fe6c3e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 269/1200: Weighted fbeta score: 0.6544 (from cache 3a21b7eb1091189fbb9196a0832e0e8f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 270/1200: Weighted fbeta score: 0.6522 (from cache 950709a6590b35a0bd8f8266a30dbd91). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 271/1200: Weighted fbeta score: 0.6563 (from cache d67def326be6ebfcff6b8568a10e25dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 272/1200: Weighted fbeta score: 0.6573 (from cache 9959d9965db79c9cd4e48d848531cbf8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 273/1200: Weighted fbeta score: 0.6513 (from cache 421940daf5365236613c7a164d96cb0f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 274/1200: Weighted fbeta score: 0.6554 (from cache d25f22212b9283e31e2954da953338d5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 275/1200: Weighted fbeta score: 0.6565 (from cache 3d2e2031e87d93501d570273c058b386). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 276/1200: Weighted fbeta score: 0.6570 (from cache 65bf46a9ca3a24af19de4c459181f652). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 277/1200: Weighted fbeta score: 0.6450 (from cache b9edf65ed5621625d8d63ead298ebdc0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 278/1200: Weighted fbeta score: 0.6579 (from cache 72cc27acbabef875a7d298a1ce77c1df). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 279/1200: Weighted fbeta score: 0.6603 (from cache d0280a8644084dd72bb4a69704210899). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 280/1200: Weighted fbeta score: 0.6564 (from cache 24cd217498141cce24f7dc8654841837). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 281/1200: Weighted fbeta score: 0.6550 (from cache 33113e4bc9b291b7a69092b779b132f3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 282/1200: Weighted fbeta score: 0.6550 (from cache 3bfb130277cab859215564fa481540b2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 283/1200: Weighted fbeta score: 0.6556 (from cache 86b75545b50e285f0741da051c5d9c38). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 284/1200: Weighted fbeta score: 0.6563 (from cache 2f648e491b411af6f687dc8d0d092b9f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 285/1200: Weighted fbeta score: 0.6556 (from cache d37e70df6c517973f8fcbb0e8f69b25f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 286/1200: Weighted fbeta score: 0.6526 (from cache a448b5aa7021f5e5eda080600924282b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 287/1200: Weighted fbeta score: 0.6570 (from cache a586fd1239479ab3ea7f47584ea08d78). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 288/1200: Weighted fbeta score: 0.6592 (from cache 860c23fe3de08add9e0c2e0486702cd3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 289/1200: Weighted fbeta score: 0.6490 (from cache ceec10acf062cf0c8cbe4af4422b56b4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 290/1200: Weighted fbeta score: 0.6561 (from cache 6dd0d714441503c05aef9eef84e071c0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 291/1200: Weighted fbeta score: 0.6533 (from cache a4e3577f3fd783318e1ca955d2635585). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 292/1200: Weighted fbeta score: 0.6513 (from cache b7703499c0ca7405d258d05572422935). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 293/1200: Weighted fbeta score: 0.6560 (from cache ebfaa9e10a6a0c44467c24347973e32a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 294/1200: Weighted fbeta score: 0.6550 (from cache ea23e929783266c88f1c579b34633707). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 295/1200: Weighted fbeta score: 0.6569 (from cache 984105eadb60fbc62d20dc29737583fd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 296/1200: Weighted fbeta score: 0.6578 (from cache 678a68b365ff7c936ebc36d0d2e73138). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 297/1200: Weighted fbeta score: 0.6526 (from cache 97c4bc7ad098c707e5550512a8911ffe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 298/1200: Weighted fbeta score: 0.6602 (from cache da8c3efced90e436f93c24f5297e23b3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 299/1200: Weighted fbeta score: 0.6590 (from cache 9ea4d13ac11072c64d7f9e18752bc418). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 300/1200: Weighted fbeta score: 0.6527 (from cache e3749ab97767cb213043d1fb748f5e27). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 301/1200: Weighted fbeta score: 0.6421 (from cache d5043d715da705d1b705a7fbb3e2eaaa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 302/1200: Weighted fbeta score: 0.6519 (from cache 83685e25c337a0084db026c877814174). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 303/1200: Weighted fbeta score: 0.6454 (from cache d1f087eb8263a493b82f818bbba19455). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 304/1200: Weighted fbeta score: 0.6524 (from cache f852208eaf3d4d257ee7a5501e71dfc6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 305/1200: Weighted fbeta score: 0.6567 (from cache dea7c2fa5a7fce261ba71e7f2e51ba12). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 306/1200: Weighted fbeta score: 0.6546 (from cache 1879e52e23930d7cc9d3100b71e4476b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 307/1200: Weighted fbeta score: 0.6477 (from cache 9e0248f9306e28101718ecc897f7bb72). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 308/1200: Weighted fbeta score: 0.6529 (from cache 916ce81feb44283ef08f1ab2e70f94fc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 309/1200: Weighted fbeta score: 0.6536 (from cache 9588b56e3cc27c20cf5e90978331aaf4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 310/1200: Weighted fbeta score: 0.6478 (from cache 03d0af59c0593ff94556e463ea664923). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 311/1200: Weighted fbeta score: 0.6499 (from cache 8bec497da676cdfa1871395e48d304ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 312/1200: Weighted fbeta score: 0.6507 (from cache c40f33c02022dabb55fa201126a77c90). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 313/1200: Weighted fbeta score: 0.6550 (from cache e0d85cc3ab0a98072e3e62d761f7dddc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 314/1200: Weighted fbeta score: 0.6544 (from cache 10daa565265a2dc60bb3c06ce61526fd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 315/1200: Weighted fbeta score: 0.6508 (from cache 3d40a591cb73bda4a0599627fe1c8f2b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 316/1200: Weighted fbeta score: 0.6574 (from cache 9e5b68231be4fa30046fd7a9a82ddcff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 317/1200: Weighted fbeta score: 0.6614 (from cache 2d1920909e758fcd201ba0dfa4a9fb9b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 318/1200: Weighted fbeta score: 0.6620 (from cache 11c695815c95a5e3f6166c2b830cd86b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 319/1200: Weighted fbeta score: 0.6482 (from cache 4d59d43093b69a463f8c655356e6d7e6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 320/1200: Weighted fbeta score: 0.6532 (from cache 4df239867720dd99c07ee747b33e60d5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 321/1200: Weighted fbeta score: 0.6503 (from cache 10874c883d86dad34b56c60894c2f3aa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 322/1200: Weighted fbeta score: 0.6525 (from cache 0a5ba7e6b79193f179dd9d6906af61da). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 323/1200: Weighted fbeta score: 0.6565 (from cache 67b6d32afbe3462666d8c0edf58c7ad2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 324/1200: Weighted fbeta score: 0.6576 (from cache 2e8841db3bb0aff030557ea81588d6d0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 325/1200: Weighted fbeta score: 0.6486 (from cache 169158a69e4874fbf087a15c3bd7a47d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 326/1200: Weighted fbeta score: 0.6554 (from cache ec7694257f877f18f4d0a1fee7bd1061). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 327/1200: Weighted fbeta score: 0.6553 (from cache 7132883253963b6bf1ed871e59666a74). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 328/1200: Weighted fbeta score: 0.6512 (from cache a70fb55e24c4bb98b68beb49069c66bc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 329/1200: Weighted fbeta score: 0.6489 (from cache 234cdbe350714786cc8a82cb2abce51f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 330/1200: Weighted fbeta score: 0.6516 (from cache ff4fc99a597fac0312763daa651088ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 331/1200: Weighted fbeta score: 0.6492 (from cache e5384bb0f4fd65daa8df573102b51479). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 332/1200: Weighted fbeta score: 0.6529 (from cache a9850922059ccb19e4e733a912cc4655). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 333/1200: Weighted fbeta score: 0.6530 (from cache 98af095a43b6f7d69fbb4df846fe1a6c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 334/1200: Weighted fbeta score: 0.6506 (from cache 2e0357ccc42045511e03823e1fd83872). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 335/1200: Weighted fbeta score: 0.6522 (from cache 41ff5f711d99603943fec453272cd9d1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 336/1200: Weighted fbeta score: 0.6517 (from cache 5b8fb293efd9fa135eda760813600b67). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 337/1200: Weighted fbeta score: 0.6545 (from cache 18410a95d88b326c567b8ae26d5c3c86). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 338/1200: Weighted fbeta score: 0.6535 (from cache ebfbf7ccfa31b9ddf738f58fd772a03c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 339/1200: Weighted fbeta score: 0.6529 (from cache a233fcb051be29f6788f5d97d080b6b6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 340/1200: Weighted fbeta score: 0.6531 (from cache 2567d015cd9986ad2de8a5e767840283). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 341/1200: Weighted fbeta score: 0.6547 (from cache 8f7c014d11955f6fda7c6f0ce7abe07c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 342/1200: Weighted fbeta score: 0.6507 (from cache e3afbc81d0d5d9a489d85199fd7858f9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 343/1200: Weighted fbeta score: 0.6518 (from cache f217f54ab49c78a1ca860e8ab476c94b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 344/1200: Weighted fbeta score: 0.6476 (from cache 2a99377512d67fb2eefddade20f5fbae). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 345/1200: Weighted fbeta score: 0.6470 (from cache 376286220b52c881caaa53771e615fd6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 346/1200: Weighted fbeta score: 0.6473 (from cache 073ad82a5e67854244936bf49fc60d3e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 347/1200: Weighted fbeta score: 0.6514 (from cache 60af273137293189e31fa2cd2078ae63). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 348/1200: Weighted fbeta score: 0.6509 (from cache 876141a15e7866c3682b3e86ebf158b4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 349/1200: Weighted fbeta score: 0.6536 (from cache 0405a248f8c79f5090ee0ccc65858cf3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 350/1200: Weighted fbeta score: 0.6494 (from cache eb8883cb1d7ff753ef84ea815361000d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 351/1200: Weighted fbeta score: 0.6494 (from cache 05dc134b827c038bb72bd31f0e839f26). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 352/1200: Weighted fbeta score: 0.6480 (from cache d44eafc62ffb58de35ab30717395a4d6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 353/1200: Weighted fbeta score: 0.6553 (from cache ec325d6ecc2e65da430a5d1de0a6d9de). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 354/1200: Weighted fbeta score: 0.6533 (from cache f7a4640638af2cae9408185ca99551c5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 355/1200: Weighted fbeta score: 0.6522 (from cache 0b647eeaa8dbb7cfbee6a6880c1227ae). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 356/1200: Weighted fbeta score: 0.6520 (from cache 0490abaf4588d7c22875dd74d67b2dd2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 357/1200: Weighted fbeta score: 0.6497 (from cache 6e8f1b3e18b2ff532cfb22329fe34ad5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 358/1200: Weighted fbeta score: 0.6376 (from cache a04781a56ea895c88a91b9e1f10f1c8c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 359/1200: Weighted fbeta score: 0.6460 (from cache 16957cba442c5b69d9cf46dba61abfe7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 360/1200: Weighted fbeta score: 0.6468 (from cache ba6ef982af904e8ef27e3df34949c80b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 361/1200: Weighted fbeta score: 0.6522 (from cache 08e4618f3fa5e661fb72c1c102749259). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 362/1200: Weighted fbeta score: 0.6483 (from cache fe45abe2a86bfa2df6e070906f3f9124). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 363/1200: Weighted fbeta score: 0.6499 (from cache 0e1c17851c5af7512ef14d1fc06a674e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 364/1200: Weighted fbeta score: 0.6487 (from cache 5a040338118835b021f79c7994f17bc5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 365/1200: Weighted fbeta score: 0.6485 (from cache 88682aafd9d67c692e4903f7097a9aa7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 366/1200: Weighted fbeta score: 0.6527 (from cache 242d6d7b6bafbfedb49fbca3b6a7d56f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 367/1200: Weighted fbeta score: 0.6496 (from cache f5ead3d55710d715ef4d173115945aa7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 368/1200: Weighted fbeta score: 0.6464 (from cache 261064c7c07aa05db0846d2ef8614c3f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 369/1200: Weighted fbeta score: 0.6483 (from cache 54bc3be296e5b880c630914e67d09c8c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 370/1200: Weighted fbeta score: 0.6468 (from cache f7de6927347be48f0574876a8da37975). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 371/1200: Weighted fbeta score: 0.6483 (from cache 7f317ca5f158d106b0511ba6e7170756). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 372/1200: Weighted fbeta score: 0.6492 (from cache 67756ad509b0edc6b02f7ec27245a05e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 373/1200: Weighted fbeta score: 0.6495 (from cache eaa11450e4058cbbba426bf608f4e212). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 374/1200: Weighted fbeta score: 0.6449 (from cache f28d305819ebf17483a1df08e8bee268). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 375/1200: Weighted fbeta score: 0.6482 (from cache 332e2605d98d672ce2e6322fdf9e3aa6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 376/1200: Weighted fbeta score: 0.6499 (from cache 3c95ae12b895e97725cf7ca754b311da). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 377/1200: Weighted fbeta score: 0.6442 (from cache fa3455c5bf8c875c90265c525eaeb893). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 378/1200: Weighted fbeta score: 0.6436 (from cache fc17832332dd61298f3ac9f96dc81d05). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 379/1200: Weighted fbeta score: 0.6425 (from cache b598431237c1b0f3a97d00733bbd6dad). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 380/1200: Weighted fbeta score: 0.6440 (from cache 0533dcc95f0e7832cf254087174cfa55). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 381/1200: Weighted fbeta score: 0.6422 (from cache e44d1808329c3acfcef3fcabd33c6360). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 382/1200: Weighted fbeta score: 0.6509 (from cache 0cd6556231a6990d52192cf56900be47). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 383/1200: Weighted fbeta score: 0.6481 (from cache 7bc851a4f6c14dc434a6af2cb49ab724). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 384/1200: Weighted fbeta score: 0.6501 (from cache 4cc326ba3477482ed1583ef81a9c2c80). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 385/1200: Weighted fbeta score: 0.6476 (from cache 1908c38a740836fd22de42a8d7ecb716). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 386/1200: Weighted fbeta score: 0.6503 (from cache 4681ba2132cfb1a8bab20100b773d7ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 387/1200: Weighted fbeta score: 0.6450 (from cache 6acf49f23eafd673640152f8135b39bf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 388/1200: Weighted fbeta score: 0.6552 (from cache 033db2d1e0ff7901e71bd1d20fa1af72). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 389/1200: Weighted fbeta score: 0.6469 (from cache 4c0e582b60928a52dace34e6468f8640). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 390/1200: Weighted fbeta score: 0.6540 (from cache 31a38f98ae21bbea4ff888f1c57b9a52). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 391/1200: Weighted fbeta score: 0.6440 (from cache 13a1ad715b444f967287b036352da67e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 392/1200: Weighted fbeta score: 0.6517 (from cache 427f3df90c8e92d5cc52577c068dfacf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 393/1200: Weighted fbeta score: 0.6462 (from cache 6ffc1efbd565fc1252587596639ab590). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 394/1200: Weighted fbeta score: 0.6463 (from cache 3b0558648b3583fca4592f5b84c89fc1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 395/1200: Weighted fbeta score: 0.6450 (from cache 16b9db4539d063dc59039c5435aab43f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 396/1200: Weighted fbeta score: 0.6449 (from cache e274f0e0333d394b8aadeefd8d0e57ff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 397/1200: Weighted fbeta score: 0.6500 (from cache a1d32a2c9e52c4d1eceae3d4a540d856). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 398/1200: Weighted fbeta score: 0.6504 (from cache ac834823e011b2069ece5ef3b2d2a90c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 399/1200: Weighted fbeta score: 0.6526 (from cache b8301f8816aa4814e4dff2cf41b3d283). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 400/1200: Weighted fbeta score: 0.6545 (from cache ee6cae7671f8b1b406b414749db35315). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 401/1200: Weighted fbeta score: 0.6566 (from cache eec6eb593f724d72e9d7207bec3b0a49). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 402/1200: Weighted fbeta score: 0.6515 (from cache 028e4a7ae4317b1c9d7371bacbb00aeb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 403/1200: Weighted fbeta score: 0.6423 (from cache 68e15ed5e9ca753b4335e105da842edc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 404/1200: Weighted fbeta score: 0.6474 (from cache 9d84e94aaeb1729f77add6bb86f88e81). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 405/1200: Weighted fbeta score: 0.6539 (from cache 5d33d27b1fd3f8ee768dce812f9bdf12). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 406/1200: Weighted fbeta score: 0.6507 (from cache 5153a7155dd7f8de6b7f32dfc377a0a2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 407/1200: Weighted fbeta score: 0.6463 (from cache 9da757d3b17b5229bede8ecb160176e0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 408/1200: Weighted fbeta score: 0.6481 (from cache 805ed01b2818e1eb6f0f58ca2f2e5f51). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 409/1200: Weighted fbeta score: 0.6491 (from cache 2423bceea5600b43eeaaaf0828531144). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 410/1200: Weighted fbeta score: 0.6489 (from cache 4d9108757d7bc068e7339107facadc2e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 411/1200: Weighted fbeta score: 0.6518 (from cache 6c9dcd86422a1f66ef0f42ff4930f17b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 412/1200: Weighted fbeta score: 0.6430 (from cache 34101fc1b0b3b148220aff26edc0fa15). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 413/1200: Weighted fbeta score: 0.6497 (from cache aaf9b16f6fe6588ad49ff27db618217f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 414/1200: Weighted fbeta score: 0.6513 (from cache 8bee8c74945e051c5dac0df6eb044501). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 415/1200: Weighted fbeta score: 0.6457 (from cache 84c8e067d4b6c6927bb733526074c000). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 416/1200: Weighted fbeta score: 0.6502 (from cache 3633dd9cc40cca1bec5817ae4e967e36). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 417/1200: Weighted fbeta score: 0.6465 (from cache 577354f4ce5ebb1cf521745d6f61e883). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 418/1200: Weighted fbeta score: 0.6500 (from cache 03ac4ca197b046a5a05ab3133159e00b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 419/1200: Weighted fbeta score: 0.6519 (from cache 0a50848a2634acd06a8d6a88a251b3c3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 420/1200: Weighted fbeta score: 0.6491 (from cache 4956f1782575dda16f4edf9d1dca0d62). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 421/1200: Weighted fbeta score: 0.6509 (from cache aa05dc604a99603a21f634fee03b40d9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 422/1200: Weighted fbeta score: 0.6485 (from cache ab26ef68358bea93c04a896e075b3010). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 423/1200: Weighted fbeta score: 0.6464 (from cache 903b1902d834479c177f71ef70ec3a36). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 424/1200: Weighted fbeta score: 0.6412 (from cache 498ac16cee239fba43a157f9c5fc3643). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 425/1200: Weighted fbeta score: 0.6389 (from cache 067ef4c774739caad1bfcfbd72caf274). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 426/1200: Weighted fbeta score: 0.6396 (from cache 3f27aa1f0f70921b1564bc56a8e9fb67). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 427/1200: Weighted fbeta score: 0.6453 (from cache 2d337fbca6ca37cb70c871b20b20499a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 428/1200: Weighted fbeta score: 0.6439 (from cache feee1e80065935fab566495b3aa5cecc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 429/1200: Weighted fbeta score: 0.6495 (from cache 225b70503e0c2f2db7994cd0a1ab7186). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 430/1200: Weighted fbeta score: 0.6391 (from cache 1a04119e5d6a0a5de5e8ac95eb1974b2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 431/1200: Weighted fbeta score: 0.6423 (from cache 4e9f6708c129b338b3785343d452b832). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 432/1200: Weighted fbeta score: 0.6458 (from cache 1929e49fc3e5f964e381c937d713c15d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 433/1200: Weighted fbeta score: 0.6352 (from cache 98170c640495925ac0f716af6153255c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 434/1200: Weighted fbeta score: 0.6414 (from cache 4fae5a7b4c80f2d570e6d0ce83669b5d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 435/1200: Weighted fbeta score: 0.6417 (from cache cdd9ab69283a496c619495a82db98647). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 436/1200: Weighted fbeta score: 0.6404 (from cache f59311d18833118a1810a3ed81d2a88b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 437/1200: Weighted fbeta score: 0.6392 (from cache c17caaee48f7247d98f37fbc66aee7d9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 438/1200: Weighted fbeta score: 0.6428 (from cache c987636dc7154a4f8218745627b1c426). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 439/1200: Weighted fbeta score: 0.6470 (from cache ca8e0c6b287e5738175b49dcdf188cc7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 440/1200: Weighted fbeta score: 0.6461 (from cache 6629ca3fc0f4ea7263a5cbd17fdaed2b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 441/1200: Weighted fbeta score: 0.6448 (from cache 351c739a68b92120522be635779c4d1c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 442/1200: Weighted fbeta score: 0.6475 (from cache b7e4e17752b862864f22a578c6459b9f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 443/1200: Weighted fbeta score: 0.6469 (from cache 77b85ebb0230ce353a22fd6b26e14907). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 444/1200: Weighted fbeta score: 0.6473 (from cache f4463dd92c9abe0b77e999226089ff63). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 445/1200: Weighted fbeta score: 0.6461 (from cache 0bfd29d7db53a8a362c15cf695467328). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 446/1200: Weighted fbeta score: 0.6470 (from cache 3502e7dcc91cdd33cf6e669b5082acb9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 447/1200: Weighted fbeta score: 0.6493 (from cache 15f59e8440c08562e1c604cacc74471c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 448/1200: Weighted fbeta score: 0.6418 (from cache 8e9eea3a7553b92eed02975f8e264b37). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 449/1200: Weighted fbeta score: 0.6410 (from cache 74b3ec003c2f6b1a5d9d42d5c1d78fa7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 450/1200: Weighted fbeta score: 0.6406 (from cache 6ed018b5719110672395cb443fb0047e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 451/1200: Weighted fbeta score: 0.6521 (from cache f31198e1446c9c2a555ca336df25f7dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 452/1200: Weighted fbeta score: 0.6528 (from cache 826271732018e04090990008d74e3a3b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 453/1200: Weighted fbeta score: 0.6488 (from cache 147f29cfca0a1ada73918895327e1d14). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 454/1200: Weighted fbeta score: 0.6455 (from cache cd5b65cd4bfcb79500bbfd98fc1c5826). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 455/1200: Weighted fbeta score: 0.6465 (from cache f178e58546b1913fb2ac69f109d3e95f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 456/1200: Weighted fbeta score: 0.6499 (from cache 417601dfa63fe7f33dc4a5c8fd97309e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 457/1200: Weighted fbeta score: 0.6475 (from cache d292a121fc9cf2ad46d8a062e0aaaee0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 458/1200: Weighted fbeta score: 0.6456 (from cache 390e7f306789802ab0e3019a1cba03ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 459/1200: Weighted fbeta score: 0.6440 (from cache 29521543040f55cb4894bebeb7be326b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 460/1200: Weighted fbeta score: 0.6469 (from cache 57d6625771ebfb9015ba151c44ff98b3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 461/1200: Weighted fbeta score: 0.6486 (from cache 0d420f4304f656e2c0a0843509329718). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 462/1200: Weighted fbeta score: 0.6488 (from cache f056e106d181e3eb61db106c38473907). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 463/1200: Weighted fbeta score: 0.6561 (from cache 68b6e2e3bc79d408a8405ea462b07501). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 464/1200: Weighted fbeta score: 0.6573 (from cache ec3bd70290940daf08e79ea68a4e1c43). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 465/1200: Weighted fbeta score: 0.6575 (from cache 4a51f56850f6e1f3a83cb1198c846ea0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 466/1200: Weighted fbeta score: 0.6393 (from cache 775ff7b5a2f3d469f7870eed75829598). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 467/1200: Weighted fbeta score: 0.6422 (from cache d4eb98a11dbeb130ff6b5ec5e7148489). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 468/1200: Weighted fbeta score: 0.6431 (from cache b40733646aa3b4c85e4ce05fc3ce4059). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 469/1200: Weighted fbeta score: 0.6431 (from cache b4cfa93fcfb27aab1109d3fd59a2fc7e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 470/1200: Weighted fbeta score: 0.6416 (from cache b9dc756feba88cd03710e9e1d087d127). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 471/1200: Weighted fbeta score: 0.6465 (from cache 0121e1abbe5502b78cab96437786d94f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 472/1200: Weighted fbeta score: 0.6461 (from cache a54d1a80318f8f8e11a95ad790f32401). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 473/1200: Weighted fbeta score: 0.6467 (from cache c48156e9564e6a4dedd65df5884a5b13). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 474/1200: Weighted fbeta score: 0.6481 (from cache 8cf42bda5e9b1e0b6fbcd68a970098e3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 475/1200: Weighted fbeta score: 0.6480 (from cache 6dce856a9cb36b4d1b38ff8e583f266f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 476/1200: Weighted fbeta score: 0.6479 (from cache af2f985cda77f8d10719e5a64c52154b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 477/1200: Weighted fbeta score: 0.6491 (from cache a465f92a583b72ee36f41c7833e04ea0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 478/1200: Weighted fbeta score: 0.6421 (from cache 29ea2927960d76130220653dd6fc1228). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 479/1200: Weighted fbeta score: 0.6491 (from cache 03b4241db66abeb09843dd0414bbd3e4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 480/1200: Weighted fbeta score: 0.6479 (from cache e66dab41f1bcbc2e9b56b15d367b1389). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 481/1200: Weighted fbeta score: 0.6500 (from cache 26807f3d2da57929704275141b5482ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 482/1200: Weighted fbeta score: 0.6507 (from cache 0f0e3f223217733eef7884ddee51869e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 483/1200: Weighted fbeta score: 0.6536 (from cache f4de63b3d1ca934544745eca20a27031). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 484/1200: Weighted fbeta score: 0.6560 (from cache 5ccdb4b9d72d4dafc4d8446e00d31f85). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 485/1200: Weighted fbeta score: 0.6541 (from cache db491f15881d1504b6818a61c016b090). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 486/1200: Weighted fbeta score: 0.6530 (from cache d9b3cdd85223821f8ab496feb052d037). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 487/1200: Weighted fbeta score: 0.6567 (from cache 9a793af39fc64445e90a96c26c3464c0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 488/1200: Weighted fbeta score: 0.6595 (from cache b5cd8f8850c060cf9189fe6216432ed8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 489/1200: Weighted fbeta score: 0.6572 (from cache 7d836d0dafd478c06201c07e16162ea8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 490/1200: Weighted fbeta score: 0.6597 (from cache 0846534c1860c6576fe88bca1b61b280). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 491/1200: Weighted fbeta score: 0.6591 (from cache 522c088c4ee1bd92725ba15f425a9677). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 492/1200: Weighted fbeta score: 0.6540 (from cache 0fd059ca97dc62a2fba66b06267df309). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 493/1200: Weighted fbeta score: 0.6538 (from cache 62cf5fc75b39e259bccda6fd8727273b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 494/1200: Weighted fbeta score: 0.6605 (from cache 5d623a85d72b4b630e0e4a7f54080c5e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 495/1200: Weighted fbeta score: 0.6571 (from cache e3867bac87e6404ffb6335efa0f25958). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 496/1200: Weighted fbeta score: 0.6489 (from cache 3e4a47d2ed6a6857c6b1619a93c456a5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 497/1200: Weighted fbeta score: 0.6522 (from cache 68227a85861d5b43ff3e06ce575051ac). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 498/1200: Weighted fbeta score: 0.6591 (from cache 0378a358039c683a0db4546925b2705e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 499/1200: Weighted fbeta score: 0.6551 (from cache 0eb3fdec311a326bb7a2a25d30198ce3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 500/1200: Weighted fbeta score: 0.6503 (from cache 9cf1215d0afc745c72936a53488d51fa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 501/1200: Weighted fbeta score: 0.6551 (from cache b39243b8cac6a74f063d02cb649a5758). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 502/1200: Weighted fbeta score: 0.6564 (from cache 5d9bc2d13d883e143dafeed94ae7fb93). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 503/1200: Weighted fbeta score: 0.6562 (from cache 7065676e1b2c9bc73f1fbd1526e796be). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 504/1200: Weighted fbeta score: 0.6546 (from cache 077db0355fe65b9a6d1862edf7c17fb1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 505/1200: Weighted fbeta score: 0.6537 (from cache c40d55d7dc56c24b87aa0d9063ab29ac). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 506/1200: Weighted fbeta score: 0.6523 (from cache 36dac72f3c398592c9d92ac7f0bf47fe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 507/1200: Weighted fbeta score: 0.6559 (from cache 6501d3a79da45914f20c50edfa744a4c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 508/1200: Weighted fbeta score: 0.6523 (from cache 2c9fe1fd858b3329e057cb6ea7df7236). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 509/1200: Weighted fbeta score: 0.6578 (from cache 7eea4d9ad6dceb1109a76818b104eddb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 510/1200: Weighted fbeta score: 0.6579 (from cache f0df0d5b4b83cca53833dc47f20c5031). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 511/1200: Weighted fbeta score: 0.6537 (from cache f4708f24153d50f610d0d855df71b9fa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 512/1200: Weighted fbeta score: 0.6563 (from cache e48de688d618f189d17d02973f0c629b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 513/1200: Weighted fbeta score: 0.6521 (from cache 5f9d10052d5f04167163f2e481d64d5b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 514/1200: Weighted fbeta score: 0.6536 (from cache 74e71de27e29ea63974f664f0530d074). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 515/1200: Weighted fbeta score: 0.6537 (from cache 95838f7427d691a465e0e62edaee18a3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 516/1200: Weighted fbeta score: 0.6512 (from cache af5e3bee045ab3c28910fed84817f107). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 517/1200: Weighted fbeta score: 0.6480 (from cache 1206c5844bb24a210fa6949b7b6b70a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 518/1200: Weighted fbeta score: 0.6535 (from cache a7eec945f25c3fb18b1af1ae5270da44). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 519/1200: Weighted fbeta score: 0.6562 (from cache 4a9e297990f3e8c527be0a6a7b0fae6a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 520/1200: Weighted fbeta score: 0.6489 (from cache 42952bf76e8302d2d94c922bd4c779c2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 521/1200: Weighted fbeta score: 0.6455 (from cache 1752c3939a15bae33e150c4c23fbc1fb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 522/1200: Weighted fbeta score: 0.6491 (from cache 94870126405c59d7fc8d664a3fe2fcae). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 523/1200: Weighted fbeta score: 0.6607 (from cache 83a726c5a75e237cffe7167c5fe84a79). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 524/1200: Weighted fbeta score: 0.6578 (from cache bda75f5b955c3b1ad046c5dbfaaf4d25). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 525/1200: Weighted fbeta score: 0.6547 (from cache 1edb5f2864798552dc5e688867baaa3d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 526/1200: Weighted fbeta score: 0.6545 (from cache 76f0f0ede5b7826d7a7cbe580dd978ce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 527/1200: Weighted fbeta score: 0.6560 (from cache a6c3c1e986cff8ce3584fdd21c8c52df). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 528/1200: Weighted fbeta score: 0.6544 (from cache f3e1e33e200623b5485c9590eaf14e8d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 529/1200: Weighted fbeta score: 0.6508 (from cache eb3b2fe694b4b2ead4ef6b959274fab7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 530/1200: Weighted fbeta score: 0.6575 (from cache 8ac32745ee6a4583b5e21737fd069a9e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 531/1200: Weighted fbeta score: 0.6514 (from cache e47e07b650122d1ed85ecfd1447301ee). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 532/1200: Weighted fbeta score: 0.6533 (from cache feaad278dc58ce2c1bf875155387527e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 533/1200: Weighted fbeta score: 0.6548 (from cache 37c380f475d663c9a7b2be4443d56c34). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 534/1200: Weighted fbeta score: 0.6534 (from cache 15145d24b018c0dfa95b599e75120d4f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 535/1200: Weighted fbeta score: 0.6526 (from cache 091b064de24e93c214f9a123d07f5f8c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 536/1200: Weighted fbeta score: 0.6567 (from cache ceb1cc69e2619e78c7651f61c92479e0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 537/1200: Weighted fbeta score: 0.6556 (from cache 221fe2da6c1b67b220ebd14653ba0a25). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 538/1200: Weighted fbeta score: 0.6495 (from cache 39b7382446c4bfbbcba722d630deabaa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 539/1200: Weighted fbeta score: 0.6503 (from cache d26d83577ab72b5fc9ff0d24c5318614). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 540/1200: Weighted fbeta score: 0.6520 (from cache d769b5cf2e2efa43c771e58f88133ea8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 541/1200: Weighted fbeta score: 0.6486 (from cache 5b49692e6b010aaf62a60c08a1543178). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 542/1200: Weighted fbeta score: 0.6526 (from cache 55cdebd9c1ef73e094a6f428dd89c3b2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 543/1200: Weighted fbeta score: 0.6477 (from cache 89d7913c5e4ed3ae8fb2611e678573cd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 544/1200: Weighted fbeta score: 0.6509 (from cache 1fc48b448551e5b87038a46a39ec32b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 545/1200: Weighted fbeta score: 0.6517 (from cache c014c7dc14e1fe9fd4293d5f1c5d1e8f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 546/1200: Weighted fbeta score: 0.6508 (from cache ff03f0d06be3e4f95bd13dbb6667718b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 547/1200: Weighted fbeta score: 0.6512 (from cache eb8fac67f50d231b1ec98717f0a228fa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 548/1200: Weighted fbeta score: 0.6473 (from cache 61bc5d999be5058912a952bff3870d4f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 549/1200: Weighted fbeta score: 0.6503 (from cache c712ce44026aae48b3baf7406cb630c2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 550/1200: Weighted fbeta score: 0.6544 (from cache e95f5c0edc92f1b1c1f4bc96c037036e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 551/1200: Weighted fbeta score: 0.6578 (from cache 1c332d285a3858271413e37cfeef2aad). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 552/1200: Weighted fbeta score: 0.6586 (from cache 2f672451b5ae6232df7f5e33b5735f0d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 553/1200: Weighted fbeta score: 0.6435 (from cache 2eaf7d86515f0d41e93c3bb0eb60f60e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 554/1200: Weighted fbeta score: 0.6434 (from cache 45126ae92822ee168017fd869d387524). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 555/1200: Weighted fbeta score: 0.6447 (from cache 45914697673462e212dee3b2e41c8cf5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 556/1200: Weighted fbeta score: 0.6526 (from cache 53a81aeafdf74b66a4951d517cf3c233). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 557/1200: Weighted fbeta score: 0.6539 (from cache 989fb142de8181d90f40e72d4a870c83). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 558/1200: Weighted fbeta score: 0.6568 (from cache 596947223dc7022f6539865f9a87b378). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 559/1200: Weighted fbeta score: 0.6489 (from cache 00194b9d173236fa3e38f528e0dcce53). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 560/1200: Weighted fbeta score: 0.6513 (from cache 0fd7216539e3ac531afd7a9b5e848ac2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 561/1200: Weighted fbeta score: 0.6508 (from cache 620eb2baf424ebdec6ab385ccbede7c9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 562/1200: Weighted fbeta score: 0.6555 (from cache 36978b93dfddcd2bbe720d24a6a1ec7c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 563/1200: Weighted fbeta score: 0.6542 (from cache 1e8b12bd584b5cc0cab4f755d114abd0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 564/1200: Weighted fbeta score: 0.6520 (from cache 767fced67a7fab192a16aec30e5fd430). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 565/1200: Weighted fbeta score: 0.6543 (from cache 34e6c5dad5e3f0b7d9f9aa6dcadaea56). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 566/1200: Weighted fbeta score: 0.6491 (from cache 4b230346a6678f0b965db980a76a627e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 567/1200: Weighted fbeta score: 0.6506 (from cache 4b383b364a860768a5c39a935f4bf7a8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 568/1200: Weighted fbeta score: 0.6443 (from cache e256ec34f5ea0f734fc0021edb03aac4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 569/1200: Weighted fbeta score: 0.6458 (from cache 0a4e6a8916c485deb2244058396428dc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 570/1200: Weighted fbeta score: 0.6455 (from cache 7a64af79c5fa6ee51a70798f6fbd0227). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 571/1200: Weighted fbeta score: 0.6460 (from cache 92ce351da444ce3600fa8fcb5a0163b6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 572/1200: Weighted fbeta score: 0.6447 (from cache 48b228227c827fd292184ba9ff0488c6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 573/1200: Weighted fbeta score: 0.6493 (from cache a0c956c97c3e7701aa6321dfb564cf5f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 574/1200: Weighted fbeta score: 0.6475 (from cache e607c26da34b29bb97091090530fceac). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 575/1200: Weighted fbeta score: 0.6517 (from cache bf6df2cc9926758fe0bcb6d897b52365). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 576/1200: Weighted fbeta score: 0.6561 (from cache 1ea538d7376eebe26f212eeab097e5e1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 577/1200: Weighted fbeta score: 0.6476 (from cache 360674aea13a982946d22c42766802a3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 578/1200: Weighted fbeta score: 0.6488 (from cache fce10c70eb3f497568bf0234b1691f2d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 579/1200: Weighted fbeta score: 0.6488 (from cache e80f80360b93ee3c45904a5312b85c65). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 580/1200: Weighted fbeta score: 0.6462 (from cache 20c78f03c1d1e49ef5c93fa923126699). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 581/1200: Weighted fbeta score: 0.6468 (from cache 77fb4ebc1b4c1818ddea2cfb5d2923f2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 582/1200: Weighted fbeta score: 0.6492 (from cache fc0f77afebcdf2e5bc55e2e77cc4f988). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 583/1200: Weighted fbeta score: 0.6487 (from cache 01b908c9f577cdd61f601332e8791f49). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 584/1200: Weighted fbeta score: 0.6499 (from cache 528b18ca8038cebe31ee10bfae00cc8b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 585/1200: Weighted fbeta score: 0.6510 (from cache 8bec74401637146b359ea4b407437be9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 586/1200: Weighted fbeta score: 0.6496 (from cache aa72951b0f21ed429068b22004f66b7b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 587/1200: Weighted fbeta score: 0.6527 (from cache 06d6760ebc7aa76295955e60c10ce401). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 588/1200: Weighted fbeta score: 0.6551 (from cache eadb7268158e9b455f74bd832888ea6d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 589/1200: Weighted fbeta score: 0.6495 (from cache 59bbbd0035dde680b3e910c3b5059c10). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 590/1200: Weighted fbeta score: 0.6486 (from cache a9a24678d979dd05953a2fe4df8a5ba7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 591/1200: Weighted fbeta score: 0.6403 (from cache 8dd4f6163c6a9609b8ba8652e4408ce7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 592/1200: Weighted fbeta score: 0.6531 (from cache 52902b778b2d4a875e6cd4f2b8cdb757). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 593/1200: Weighted fbeta score: 0.6454 (from cache 5ba93df6a28076a24c89017cadd8e981). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 594/1200: Weighted fbeta score: 0.6449 (from cache f1f72a102b2dc845f9a660e85f1724d4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 595/1200: Weighted fbeta score: 0.6559 (from cache aa5093e9a4e4e8eb9a08f154a34cb4e2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 596/1200: Weighted fbeta score: 0.6547 (from cache da391b52543d13b9874bb67efd24c702). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 597/1200: Weighted fbeta score: 0.6541 (from cache 2fcb17514e3ee2526137f314e351cc34). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 598/1200: Weighted fbeta score: 0.6556 (from cache 03702fd1021376ccc7413240b69f5ff7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 599/1200: Weighted fbeta score: 0.6599 (from cache 9d614ee76af7f6c183d176a47ef09a80). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 600/1200: Weighted fbeta score: 0.6612 (from cache 75e5a335686619d2bec42e8b19979dfb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 601/1200: Weighted fbeta score: 0.6466 (from cache d1714d84c7103159d2627fa5f692130b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 602/1200: Weighted fbeta score: 0.6518 (from cache d04b2436805dd62077bddd880c9b15d4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 603/1200: Weighted fbeta score: 0.6522 (from cache 03bb502040c7f28b5ae6621f85e32e99). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 604/1200: Weighted fbeta score: 0.6410 (from cache bfe70de47de1fc4f6cd58d2c76aa757b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 605/1200: Weighted fbeta score: 0.6449 (from cache a680b4d3e44d0c940211d9ad8cd85552). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 606/1200: Weighted fbeta score: 0.6476 (from cache 05773389abb7449c29dc1b98bc241e51). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 607/1200: Weighted fbeta score: 0.6497 (from cache b3a995f19d52bb22d0d76f841505cc85). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 608/1200: Weighted fbeta score: 0.6529 (from cache 3b54cd4dbb39bf15ecdc7323dcfbf1c9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 609/1200: Weighted fbeta score: 0.6534 (from cache cb49119e59222d0e341d9a57d788ef1a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 610/1200: Weighted fbeta score: 0.6416 (from cache f25412911ad03fb8f8b73ef67d095cdc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 611/1200: Weighted fbeta score: 0.6436 (from cache e756b768c63bc4c57b206d9b66a043a1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 612/1200: Weighted fbeta score: 0.6423 (from cache efceb5682f3bc3f9fd1133207ae9f29f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 613/1200: Weighted fbeta score: 0.6452 (from cache 12059ec2f0760bb8cbb9c0160e12d4c2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 614/1200: Weighted fbeta score: 0.6481 (from cache ca66c5eaa9dcb49d33333ed7e7f758f2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 615/1200: Weighted fbeta score: 0.6470 (from cache aed5fe4a29d8af95d17280995c674e6b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 616/1200: Weighted fbeta score: 0.6485 (from cache 77cb52e63743c87af03c08b5b85a0a16). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 617/1200: Weighted fbeta score: 0.6481 (from cache 06c2171a4141bd44b6ce291cbe4524c1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 618/1200: Weighted fbeta score: 0.6499 (from cache c651a1372e324e270b80c2b40328795c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 619/1200: Weighted fbeta score: 0.6402 (from cache bd092d2271a84e6e0c990f61d02f5b8d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 620/1200: Weighted fbeta score: 0.6438 (from cache 81b14623df91e68f9809936069687220). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 621/1200: Weighted fbeta score: 0.6436 (from cache b694add56bafe5adb8baa3692d31256a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 622/1200: Weighted fbeta score: 0.6486 (from cache f91e9d27225677c2974ff426042a4172). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 623/1200: Weighted fbeta score: 0.6517 (from cache cfc291e6abba23f5c1c4984efe67e2cc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 624/1200: Weighted fbeta score: 0.6449 (from cache 7cd875848134caab6c63b1ffa976990b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 625/1200: Weighted fbeta score: 0.6496 (from cache 3c4e3f26e57c5e76561a0161ebe13c95). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 626/1200: Weighted fbeta score: 0.6509 (from cache c764994c31c5bea5e7dd8fed2c3e4a77). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 627/1200: Weighted fbeta score: 0.6465 (from cache ee3228426aa871bf86453fc2fb108101). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 628/1200: Weighted fbeta score: 0.6460 (from cache 1dab87b4a28f7571ac8505c0b70c4b9d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 629/1200: Weighted fbeta score: 0.6459 (from cache 2b4a7e90d583cbe59640f4429b3d9c29). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 630/1200: Weighted fbeta score: 0.6533 (from cache f78956ec481067a1ea1b1d10a4812a42). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 631/1200: Weighted fbeta score: 0.6474 (from cache 35c8e07bccf44ed1d2be6ef91d0b7a8b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 632/1200: Weighted fbeta score: 0.6526 (from cache 70996e628356b3af902e49a457d86eec). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 633/1200: Weighted fbeta score: 0.6534 (from cache a4f4f6e2021b1e112a4759959dc96ee9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 634/1200: Weighted fbeta score: 0.6510 (from cache 584cc499385ca631a88c2c2f116edfd1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 635/1200: Weighted fbeta score: 0.6523 (from cache 0ae11b9af03039a647d6934fe0da99c9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 636/1200: Weighted fbeta score: 0.6544 (from cache 70cd5481d09206c44660e36de7306204). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 637/1200: Weighted fbeta score: 0.6420 (from cache 5f63fbd148dc6f7b5e228e6c74f8a61d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 638/1200: Weighted fbeta score: 0.6426 (from cache 285c4e470028b55ba58d666a49961fad). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 639/1200: Weighted fbeta score: 0.6474 (from cache 000526f5a1accc4603a44bc7518d5d14). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 640/1200: Weighted fbeta score: 0.6464 (from cache db8d17e668bbdda1c236215bb3520499). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 641/1200: Weighted fbeta score: 0.6515 (from cache 8fa18c5266461351cf373bc0b6a816ed). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 642/1200: Weighted fbeta score: 0.6481 (from cache 22c212b7f816d3645c3081727abfb325). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 643/1200: Weighted fbeta score: 0.6482 (from cache a70dcfdc15d4ddd935fcef49c8d8ef8c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 644/1200: Weighted fbeta score: 0.6493 (from cache 9d61610c85436e68f4b9eeddb6a968ef). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 645/1200: Weighted fbeta score: 0.6501 (from cache d773bb82fbb20148cf637e0b560ef130). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 646/1200: Weighted fbeta score: 0.6445 (from cache 151a7581f08926ddc10de61f4e53eb23). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 647/1200: Weighted fbeta score: 0.6504 (from cache d743a981335547ee5b71903a7e35c474). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 648/1200: Weighted fbeta score: 0.6499 (from cache d4b6a01b029c0376305ab1817a10c5f4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 649/1200: Weighted fbeta score: 0.6503 (from cache 2b3922776b241b8c088ac4e63a8ba447). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 650/1200: Weighted fbeta score: 0.6463 (from cache b0315c93bbfb5831cb54a28565a5054f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 651/1200: Weighted fbeta score: 0.6473 (from cache 41d2f98310a56904d589bd839a80280a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 652/1200: Weighted fbeta score: 0.6479 (from cache f6c36d33dff697053a985aa1a8283af5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 653/1200: Weighted fbeta score: 0.6540 (from cache 6642d25c421ed6902ec49930ae9dc29e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 654/1200: Weighted fbeta score: 0.6519 (from cache bee265666fe28c093dc7fec9c81517ff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 655/1200: Weighted fbeta score: 0.6500 (from cache 4448f18ae9909085bde20fe5c8775691). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 656/1200: Weighted fbeta score: 0.6485 (from cache 21eaa4eaea80a514d9a53293f18bd46e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 657/1200: Weighted fbeta score: 0.6485 (from cache 5cf2fe5114dd11e5ddd17aa0eeac8744). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 658/1200: Weighted fbeta score: 0.6447 (from cache 55f49b538a134a5083759648bc68a850). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 659/1200: Weighted fbeta score: 0.6507 (from cache 55a8a5becf223d2aa7a04a79c89a849b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 660/1200: Weighted fbeta score: 0.6522 (from cache 7d067ab64caebe50b18f2035f9cc512c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 661/1200: Weighted fbeta score: 0.6486 (from cache 4c4ee8640dc859f248b47741c338601b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 662/1200: Weighted fbeta score: 0.6482 (from cache 6063e1b5914231d900ce6ae79b62915e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 663/1200: Weighted fbeta score: 0.6486 (from cache fcc48b9873e5672339891fdf96a88fdd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 664/1200: Weighted fbeta score: 0.6428 (from cache eec915813e0c1a55ebc2c993f00e8fc2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 665/1200: Weighted fbeta score: 0.6523 (from cache 8d78372cc642f19da25e7a0fefeacb45). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 666/1200: Weighted fbeta score: 0.6490 (from cache f7e5422232e75002bb6e09a28f052099). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 667/1200: Weighted fbeta score: 0.6439 (from cache aad7c870cae7e5f44e5f5a7863d6cfd8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 668/1200: Weighted fbeta score: 0.6444 (from cache fcce5a7e5e89ee5f0c9785e79d56d7a7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 669/1200: Weighted fbeta score: 0.6457 (from cache a66eeddd5618e74701a9e26d30b7f446). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 670/1200: Weighted fbeta score: 0.6372 (from cache 6effd858558d7a1351bfc6a3ff8365c4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 671/1200: Weighted fbeta score: 0.6397 (from cache 9262cff78da635afe0589c8f5c22e6f0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 672/1200: Weighted fbeta score: 0.6383 (from cache f4a2031719e259ffa41ae3300983bcc9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 673/1200: Weighted fbeta score: 0.6485 (from cache 933483eb8e0eb9a38ad56a5a3bef4ea8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 674/1200: Weighted fbeta score: 0.6445 (from cache f71b3888b5424f81bc86a7af2815f6e3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 675/1200: Weighted fbeta score: 0.6422 (from cache e1609499f239dbccdfeb5e76bd73b6af). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 676/1200: Weighted fbeta score: 0.6426 (from cache 61cb5a309d709557fc6493f5454a085b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 677/1200: Weighted fbeta score: 0.6452 (from cache e2022c2222f27441eb630aaf39fc959a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 678/1200: Weighted fbeta score: 0.6419 (from cache 35d377604753f0c10d9202da33e51b36). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 679/1200: Weighted fbeta score: 0.6509 (from cache 260755e6ab8ef92c824d4259fcbb0709). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 680/1200: Weighted fbeta score: 0.6480 (from cache e48e93966e070514baff3d72b87f5c96). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 681/1200: Weighted fbeta score: 0.6502 (from cache 52c3c71c079e624181bc96a369a64e48). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 682/1200: Weighted fbeta score: 0.6466 (from cache f417f897f456488c9cc6ffd70646c16d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 683/1200: Weighted fbeta score: 0.6501 (from cache f279d4396a9d1a39ed20f7f355c49725). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 684/1200: Weighted fbeta score: 0.6498 (from cache 9ceaa77d47034a066acf7a483511daf3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 685/1200: Weighted fbeta score: 0.6471 (from cache 14cd3cce3f866a418543248e3103bd4f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 686/1200: Weighted fbeta score: 0.6473 (from cache 48e46de635efd44d0df3bd6b1a74ce81). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 687/1200: Weighted fbeta score: 0.6480 (from cache 9b7e5a0a5e4c1496dc34a9041b537f91). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 688/1200: Weighted fbeta score: 0.6506 (from cache a0238c69f28c9da9d0f750a956281738). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 689/1200: Weighted fbeta score: 0.6513 (from cache cc224a2864d1789809d2de08e1ca448a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 690/1200: Weighted fbeta score: 0.6471 (from cache 1041ebe1867323fd03ebe6fd9505048b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 691/1200: Weighted fbeta score: 0.6471 (from cache 48adc9dd97a636da8abc0edd581e1f82). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 692/1200: Weighted fbeta score: 0.6481 (from cache cdc2f17cf3bf6c5770ed132a2014099c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 693/1200: Weighted fbeta score: 0.6501 (from cache 19ae21f545b3be19108d4320ea75ab93). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 694/1200: Weighted fbeta score: 0.6422 (from cache 4c44862e461d8f1b7274d21ed85c85c9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 695/1200: Weighted fbeta score: 0.6419 (from cache f52a73630d7aaf41b743b504d17bd8d1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 696/1200: Weighted fbeta score: 0.6419 (from cache 513f86d62bd0a0d97d2a30b206d73e8b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 697/1200: Weighted fbeta score: 0.6448 (from cache 42ff2a8327da3e28e959875f3190f842). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 698/1200: Weighted fbeta score: 0.6423 (from cache 6a00cb3ba032e7b3a9473ec2933002fe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 699/1200: Weighted fbeta score: 0.6477 (from cache 723b1c547ffb0b279ec82c7812d9e901). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 700/1200: Weighted fbeta score: 0.6416 (from cache f77ba0e21f70f267e1c5c6238b31c8ac). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 701/1200: Weighted fbeta score: 0.6407 (from cache 07de21abe1d2ec9c45758ae4008bf055). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 702/1200: Weighted fbeta score: 0.6375 (from cache 185345b5bc59fd83d0a1785abfbc9c58). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 703/1200: Weighted fbeta score: 0.6460 (from cache b461addecce0845ab9f2092b91a49748). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 704/1200: Weighted fbeta score: 0.6426 (from cache 8a2408fc3dd0f4aab0e6b333acd887ff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 705/1200: Weighted fbeta score: 0.6440 (from cache c3c924dba2b6c68932cd37a68254684e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 706/1200: Weighted fbeta score: 0.6483 (from cache cc6aa1ade0a97c70bb25be50344d1e81). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 707/1200: Weighted fbeta score: 0.6493 (from cache abe72667cc8dea46cf454d9df3e18071). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 708/1200: Weighted fbeta score: 0.6519 (from cache 7bd86e9bf5f17073446138f45a6b034c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 709/1200: Weighted fbeta score: 0.6453 (from cache 4d03f3b98f69748a0312b06deba3fe2d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 710/1200: Weighted fbeta score: 0.6488 (from cache 918c184e79476d7c38b6f04525a052d4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 711/1200: Weighted fbeta score: 0.6507 (from cache 1053f345ee581b88050704482c301f5c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 712/1200: Weighted fbeta score: 0.6393 (from cache 4add8c37058b7fecc41d3ff43e478dbd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 713/1200: Weighted fbeta score: 0.6351 (from cache de01e39529e1e0546c98f879d4e44df2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 714/1200: Weighted fbeta score: 0.6383 (from cache 38e2fffc0452fd4c9c3872c5f011098d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 715/1200: Weighted fbeta score: 0.6491 (from cache 9743329a35d9c7969f7148709b52d0df). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 716/1200: Weighted fbeta score: 0.6444 (from cache 08d14403ebe4534d7d29ac3f26e67d46). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 717/1200: Weighted fbeta score: 0.6471 (from cache 7e64acf27ac8a8248da987e62ffa1809). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 718/1200: Weighted fbeta score: 0.6429 (from cache 60143565dc66731c606be946ed47c7e7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 719/1200: Weighted fbeta score: 0.6417 (from cache da811674b54e19f71833c6b0a2434251). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 720/1200: Weighted fbeta score: 0.6429 (from cache 40862bff085d847edcdd9069eb42e35a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 721/1200: Weighted fbeta score: 0.6461 (from cache e9f7f1c29f6f56505664587a5e5ce8f1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 722/1200: Weighted fbeta score: 0.6539 (from cache 822edce16274155d3c7311fd6b8adda1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 723/1200: Weighted fbeta score: 0.6550 (from cache 6613413b57520d85a160115c8087a695). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 724/1200: Weighted fbeta score: 0.6464 (from cache 318dc3e2132b685656047d9142ae4653). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 725/1200: Weighted fbeta score: 0.6573 (from cache aeced30317ad099b2b883a4b523ae904). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 726/1200: Weighted fbeta score: 0.6539 (from cache 6e8f627cdc3b1f62c96f069047465829). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 727/1200: Weighted fbeta score: 0.6556 (from cache e513482669cb599373277599ab357350). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 728/1200: Weighted fbeta score: 0.6571 (from cache 81460c397560f154cc18bee08fc12cb1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 729/1200: Weighted fbeta score: 0.6536 (from cache 372588eb07032a855a0bc58325112a54). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 730/1200: Weighted fbeta score: 0.6545 (from cache bb5a311a75f9bd853c0aab0fad811b40). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 731/1200: Weighted fbeta score: 0.6563 (from cache c680849dcc39da83885ad72f1f0de411). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 732/1200: Weighted fbeta score: 0.6568 (from cache bc55686d2f00333f78b224fb3b32edf6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 733/1200: Weighted fbeta score: 0.6530 (from cache 78c64c0e8411a3dcb4d004c108fd4f45). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 734/1200: Weighted fbeta score: 0.6611 (from cache d833ade27ac32258becf08e1da83b7c7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 735/1200: Weighted fbeta score: 0.6574 (from cache b84778bd90778ee6fcc8c997e8b18a6f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 736/1200: Weighted fbeta score: 0.6541 (from cache 18d793bb23059e4d4190e577ab725d49). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 737/1200: Weighted fbeta score: 0.6542 (from cache 8bb59c862342906d4512170c609dfbbc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 738/1200: Weighted fbeta score: 0.6518 (from cache 25534e6d28ec3e2c6de175acfd54208e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 739/1200: Weighted fbeta score: 0.6520 (from cache a291c7bacaa861cb192bd486320f3035). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 740/1200: Weighted fbeta score: 0.6556 (from cache cf18a194909469f9d1243829c5d93ebc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 741/1200: Weighted fbeta score: 0.6557 (from cache d0af18a324b38fef095f7aaeeea93cc2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 742/1200: Weighted fbeta score: 0.6502 (from cache b9b6c4432cdb7dac9b76ce2422593b6f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 743/1200: Weighted fbeta score: 0.6545 (from cache 6f46fd63cda1c5902e6cceaf2443d5b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 744/1200: Weighted fbeta score: 0.6530 (from cache da558e3e1c93ce67e11d8e3a71799dbd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 745/1200: Weighted fbeta score: 0.6463 (from cache 7effa7b7099288154654d6284d38dc4c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 746/1200: Weighted fbeta score: 0.6521 (from cache 7fb7ddc2278cd2bd7b7262451717dad0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 747/1200: Weighted fbeta score: 0.6519 (from cache a273be63a2c48a0cec4cff6b730cf6b1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 748/1200: Weighted fbeta score: 0.6524 (from cache 0e92f11642e10b9f52c36714c7277414). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 749/1200: Weighted fbeta score: 0.6537 (from cache 0b22f58038b90bb4255efaffe1ee8654). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 750/1200: Weighted fbeta score: 0.6559 (from cache ff3cb02c35eea7e1820769ed4965418c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 751/1200: Weighted fbeta score: 0.6489 (from cache 542482ce02ae29f5150e584f3a285473). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 752/1200: Weighted fbeta score: 0.6521 (from cache 0db54d275854982fbfa1f4ce2f817be2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 753/1200: Weighted fbeta score: 0.6490 (from cache 5f528f38bb50897e8195f8cabcb83b08). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 754/1200: Weighted fbeta score: 0.6537 (from cache 8b36a213a08439106cb3f9a9540b9f2a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 755/1200: Weighted fbeta score: 0.6568 (from cache 0c83a4ced277a907bf3fcffc66b4b5a8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 756/1200: Weighted fbeta score: 0.6536 (from cache 81eeea611c458df2b135b72fb00d86f1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 757/1200: Weighted fbeta score: 0.6558 (from cache 9389de4feb818a80d35dbffe2e1c4fce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 758/1200: Weighted fbeta score: 0.6567 (from cache f213a503de2d62a6ce8727e2d3bc7116). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 759/1200: Weighted fbeta score: 0.6603 (from cache ee533c6d6460e49a03fe72eb45300627). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 760/1200: Weighted fbeta score: 0.6500 (from cache 26fb5d817f6aeb12b56c8e3c25f3396b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 761/1200: Weighted fbeta score: 0.6553 (from cache 1973abde4ba1f0cfa41678a0312de1a5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 762/1200: Weighted fbeta score: 0.6531 (from cache 0ed1c4678a66659d1b6dd134292f820c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 763/1200: Weighted fbeta score: 0.6506 (from cache 519644c49cbb3ac1835aacbbc700797a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 764/1200: Weighted fbeta score: 0.6503 (from cache a91da894568c24a04fceb201ae62e9a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 765/1200: Weighted fbeta score: 0.6500 (from cache 9f0571215e57d7a74b4890adee629fd1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 766/1200: Weighted fbeta score: 0.6530 (from cache ff4404da623a15eeed078d187533a887). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 767/1200: Weighted fbeta score: 0.6568 (from cache dc56bd63d52c7d502a0bd66e8615d9ec). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 768/1200: Weighted fbeta score: 0.6543 (from cache 06eff6e45a52be9bc410e39e07989a0b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 769/1200: Weighted fbeta score: 0.6476 (from cache 71ce0a327c57324b59ce63bb6f9fde7b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 770/1200: Weighted fbeta score: 0.6510 (from cache f7ca9a07df37e5c8808d5bf792102686). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 771/1200: Weighted fbeta score: 0.6539 (from cache a4c5675902c9ee4340ee5526d3df61d2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 772/1200: Weighted fbeta score: 0.6516 (from cache 5ab2604ddc73fa7ab72b01268b871afb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 773/1200: Weighted fbeta score: 0.6517 (from cache 0794daf62a7dd7640d6753bd30fe30fd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 774/1200: Weighted fbeta score: 0.6559 (from cache f23ed48b6f8b1cc76d683b6528e2a3cb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 775/1200: Weighted fbeta score: 0.6535 (from cache 91f2c8834e700843bdce0ddbd9f4183a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 776/1200: Weighted fbeta score: 0.6556 (from cache 8b5a9d8cfdee8b67ef3185a53f778002). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 777/1200: Weighted fbeta score: 0.6521 (from cache a5c23a6820f8dd79315e2ca50a979fed). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 778/1200: Weighted fbeta score: 0.6576 (from cache 1236c750510be9fdf251ee4437533819). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 779/1200: Weighted fbeta score: 0.6572 (from cache 1b51a713a71c146c883a8031532341f4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 780/1200: Weighted fbeta score: 0.6539 (from cache 55039a2f0887c6156860b10bf3d23ed4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 781/1200: Weighted fbeta score: 0.6516 (from cache 9cd26baa001fb9faab7687d04a1839e8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 782/1200: Weighted fbeta score: 0.6461 (from cache 2106ec7db5d92d789c662257d603a72e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 783/1200: Weighted fbeta score: 0.6484 (from cache 656d8d06822d67e7e83a608137d445bf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 784/1200: Weighted fbeta score: 0.6494 (from cache e7fdb53be6bd60d868deb122753435c4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 785/1200: Weighted fbeta score: 0.6447 (from cache 71279eeca308ccd0cf875ccd66ab692f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 786/1200: Weighted fbeta score: 0.6442 (from cache ff7822362ab0252e49795fe16da7a3b9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 787/1200: Weighted fbeta score: 0.6529 (from cache 613da2e27361f3a3488ef154c275cbb8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 788/1200: Weighted fbeta score: 0.6558 (from cache 45ffe4e1503033eb5dd492cda6416390). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 789/1200: Weighted fbeta score: 0.6548 (from cache b0512ce2982bf7a8acb2f132a0702928). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 790/1200: Weighted fbeta score: 0.6465 (from cache ecc14eefe50e82807fea1d7a8a5fdaad). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 791/1200: Weighted fbeta score: 0.6440 (from cache e411c27ad510304964d59ed9df4ad64c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 792/1200: Weighted fbeta score: 0.6440 (from cache 66f8c54e7c03449e31a50f74ff682d0b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 793/1200: Weighted fbeta score: 0.6486 (from cache f4535b43ab91a3d0bd7bab277875475e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 794/1200: Weighted fbeta score: 0.6482 (from cache 0bdcef363d32b95136797c43b0ec889f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 795/1200: Weighted fbeta score: 0.6540 (from cache 1571ac5ab3a9824ec4365274c1a2dac7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 796/1200: Weighted fbeta score: 0.6573 (from cache f85f1b4ede16fffb2b0b929cb2da3427). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 797/1200: Weighted fbeta score: 0.6540 (from cache d1c42bf1b75e7dcb6bd3497191b9ba54). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 798/1200: Weighted fbeta score: 0.6536 (from cache 37f6a1d4e27a51d9a43f0f44da3e2274). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 799/1200: Weighted fbeta score: 0.6473 (from cache 73aede2a93a0f672a2c4624979a35908). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 800/1200: Weighted fbeta score: 0.6518 (from cache 8192585c7fef3b6afd9b74288e4276dd). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 801/1200: Weighted fbeta score: 0.6513 (from cache e2ea739cb7743913c2d81d8ed7093fea). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 802/1200: Weighted fbeta score: 0.6411 (from cache 0a47e2078c7356784a6b428fef7bfa2e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 803/1200: Weighted fbeta score: 0.6441 (from cache 32d84cf7bb544947b0e051f0b3f09d44). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 804/1200: Weighted fbeta score: 0.6462 (from cache b4216965b554c869724c92cb52d3374a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 805/1200: Weighted fbeta score: 0.6521 (from cache efec8d1ea6dd9287e362281712433770). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 806/1200: Weighted fbeta score: 0.6499 (from cache 489338835850b0381f053773ed88cb79). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 807/1200: Weighted fbeta score: 0.6508 (from cache 9812e875edf12ba75e0e1e53902f7832). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 808/1200: Weighted fbeta score: 0.6587 (from cache 18f26738f3fcb64caf3a325d8c2633aa). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 809/1200: Weighted fbeta score: 0.6535 (from cache 62790f78ef01861d1f8eff90ef4380c8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 810/1200: Weighted fbeta score: 0.6512 (from cache b942a0147908c3c061b679b0d8da8652). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 811/1200: Weighted fbeta score: 0.6526 (from cache b91cebaa3e2593166147f072f5b48eb6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 812/1200: Weighted fbeta score: 0.6527 (from cache 107457e0c76d104b6b86da0232377be3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 813/1200: Weighted fbeta score: 0.6483 (from cache 11dd3db04d238dd41b8c426de671e2f2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 814/1200: Weighted fbeta score: 0.6423 (from cache 3edcfae478e53d8df214b9c2539caea7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 815/1200: Weighted fbeta score: 0.6473 (from cache 20421a030b6ee170fdc73760f1143774). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 816/1200: Weighted fbeta score: 0.6487 (from cache fb8bea533a2bb8a564abb47dc02520ff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 817/1200: Weighted fbeta score: 0.6586 (from cache e88d5f47b0a43a37967e956eb1053452). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 818/1200: Weighted fbeta score: 0.6528 (from cache 2fe13e6d2e01ed9feb820e2e43b0e225). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 819/1200: Weighted fbeta score: 0.6527 (from cache 441524ac193cd2ecbb482bdbaa1c308e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 820/1200: Weighted fbeta score: 0.6535 (from cache 943c04b40e03e3ace643507e1e01dd68). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 821/1200: Weighted fbeta score: 0.6520 (from cache cb1cea28bf54a12cab8f5b9b8319143b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 822/1200: Weighted fbeta score: 0.6486 (from cache 8ae594e183a1fdd05602ee61c4f5d2a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 823/1200: Weighted fbeta score: 0.6521 (from cache 8cc897cedd6c207a1a9c7c5956f0fe55). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 824/1200: Weighted fbeta score: 0.6485 (from cache 79d330f86951e8a3a59c6563f7cf01c9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 825/1200: Weighted fbeta score: 0.6487 (from cache 16ba3cd2c9855b968085e2cdc59d4f03). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 826/1200: Weighted fbeta score: 0.6427 (from cache 7edbcc09a1010ae0e83c8c26f0c3d943). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 827/1200: Weighted fbeta score: 0.6484 (from cache 6242f52f25652526c376d70c9d1da679). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 828/1200: Weighted fbeta score: 0.6485 (from cache e23cc0c1e181b94f9229db24328ce425). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 829/1200: Weighted fbeta score: 0.6493 (from cache 6c9769be27abbffdebef33d2a737b02c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 830/1200: Weighted fbeta score: 0.6525 (from cache 818d8151c7078e473b941f95745b1ae3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 831/1200: Weighted fbeta score: 0.6493 (from cache ec07d698ee5854743690ba0ad2d4ee4b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 832/1200: Weighted fbeta score: 0.6550 (from cache c646485180e22a82fe40475940be09d2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 833/1200: Weighted fbeta score: 0.6572 (from cache 551f4df93713a8e80c1c56f59daa8dae). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 834/1200: Weighted fbeta score: 0.6557 (from cache c44515c111545fb6d24eebce88fd626c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 835/1200: Weighted fbeta score: 0.6587 (from cache ba98fad89d745ffce5266189c2b71c03). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 836/1200: Weighted fbeta score: 0.6555 (from cache 4afc9ee0e60c4b9dcc60f83da5484b4a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 837/1200: Weighted fbeta score: 0.6574 (from cache cba580410fa817b3230c2bf1cae7e11e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 838/1200: Weighted fbeta score: 0.6490 (from cache b8027309842d66a10d23d01f76402a8d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 839/1200: Weighted fbeta score: 0.6500 (from cache 870495308fec43d825694492d39ce762). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 840/1200: Weighted fbeta score: 0.6554 (from cache b48aef70396bbc967aa26330b8b9804b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 841/1200: Weighted fbeta score: 0.6468 (from cache ec0c71c70489972e7faa030f3231b88e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 842/1200: Weighted fbeta score: 0.6478 (from cache 6e766b7b31c72f046204623aa74e1657). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 843/1200: Weighted fbeta score: 0.6453 (from cache d56d7561f18f15dae3a84b2423b9682a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 844/1200: Weighted fbeta score: 0.6415 (from cache f1f9f60efc08297752e299f63c887022). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 845/1200: Weighted fbeta score: 0.6397 (from cache 80436903ca1a3b4025cccb883a7b1a32). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 846/1200: Weighted fbeta score: 0.6451 (from cache 03abf796753dd8dbf72a50fb981944f1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 847/1200: Weighted fbeta score: 0.6561 (from cache 6dde4a42edb8bbf2dc60b013f222fd1d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 848/1200: Weighted fbeta score: 0.6549 (from cache 8447a4f9c1cfea6fac414822a6b51c5c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 849/1200: Weighted fbeta score: 0.6557 (from cache d6f51ecf3315894e1c7f898de20a91b8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 850/1200: Weighted fbeta score: 0.6482 (from cache e57a415194ece08711f19b224673bf04). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 851/1200: Weighted fbeta score: 0.6442 (from cache d1e8d21e5206a351d31b3b7892b2ca31). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 852/1200: Weighted fbeta score: 0.6436 (from cache 5376a643febedab86b5a5d6cadec821b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 853/1200: Weighted fbeta score: 0.6424 (from cache 1f65c43d37de8607eeb7ddc714f4ebbc). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 854/1200: Weighted fbeta score: 0.6478 (from cache a8de26348bffbd37506874235da5f2e8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 855/1200: Weighted fbeta score: 0.6483 (from cache 1622b3e79aed6398193b397644c15460). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 856/1200: Weighted fbeta score: 0.6439 (from cache 0274812a3aa7e10b80585a22e1ec858f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 857/1200: Weighted fbeta score: 0.6415 (from cache b12bf6a5f94f174b390b55f94d3158b0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 858/1200: Weighted fbeta score: 0.6428 (from cache 98cbdc00ec2d2113c0b2b53503d1fcf8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 859/1200: Weighted fbeta score: 0.6458 (from cache c742a275babf1a14f2312c82c160b2be). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 860/1200: Weighted fbeta score: 0.6438 (from cache 0d77ee74c95b5fd49ad7e4f3b5639ad2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 861/1200: Weighted fbeta score: 0.6456 (from cache 79d65fb529fe46f471ff973c7dce37b2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 862/1200: Weighted fbeta score: 0.6491 (from cache 5379885c21dcdce163d667e44641b2bb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 863/1200: Weighted fbeta score: 0.6501 (from cache 77ca8e501d1fa0b33541d668e799fa2b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 864/1200: Weighted fbeta score: 0.6481 (from cache a2d6f6ea66186585488a8a4af7398fa3). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 865/1200: Weighted fbeta score: 0.6484 (from cache 7700a26d8ced1774ce460d475efcea2e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 866/1200: Weighted fbeta score: 0.6531 (from cache 4b11b62d10ee38b5e7b87b76a354b60b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 867/1200: Weighted fbeta score: 0.6554 (from cache 6344d2b1bbcf48a17eecb41540335a22). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 868/1200: Weighted fbeta score: 0.6507 (from cache 91fc198f7366354f90cfb36acaf51066). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 869/1200: Weighted fbeta score: 0.6549 (from cache 891412b3c2cd3173cb14be031a25f59a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 870/1200: Weighted fbeta score: 0.6500 (from cache 346ca8a8140964549b80aab57d8a80c8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 871/1200: Weighted fbeta score: 0.6505 (from cache 9a0bfab4ddc950eeafbcc755054be68e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 872/1200: Weighted fbeta score: 0.6507 (from cache beb9227bd6bbf91c8ac625d0b8dcb52e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 873/1200: Weighted fbeta score: 0.6499 (from cache 715fe43537cd73cc220ac9731acdf623). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 874/1200: Weighted fbeta score: 0.6444 (from cache 55376c878e29fdeb4ab7c0e31a7b4a11). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 875/1200: Weighted fbeta score: 0.6514 (from cache dac52f9c9d928d366a9f30e3cde51865). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 876/1200: Weighted fbeta score: 0.6515 (from cache 6e6b985774b9612c67b4938e161d11c4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 877/1200: Weighted fbeta score: 0.6577 (from cache 4a64d121dffd09b4311cdf3db973091d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 878/1200: Weighted fbeta score: 0.6545 (from cache d81b274998ac9d013b4ec63d263b1c2d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 879/1200: Weighted fbeta score: 0.6500 (from cache cabbcddf235fb33ad9db3f3b71df11f5). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 880/1200: Weighted fbeta score: 0.6450 (from cache 9462a0bfa848d7de0b500e247301b498). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 881/1200: Weighted fbeta score: 0.6487 (from cache 15b7bd01d352c7ad1814c550b807c940). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 882/1200: Weighted fbeta score: 0.6483 (from cache 03df1c3b529d5a77d488b600511bf5b6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 883/1200: Weighted fbeta score: 0.6491 (from cache 8c0a58fda51a42ae79fb4fc09edb8803). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 884/1200: Weighted fbeta score: 0.6533 (from cache 90ed3eea8ae776d1ff6fb351f9324d9d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 885/1200: Weighted fbeta score: 0.6533 (from cache 9c5f572da20a7f8b28445ab13ba59718). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 886/1200: Weighted fbeta score: 0.6494 (from cache cf05a7722967dec332300d2548e35ffe). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 887/1200: Weighted fbeta score: 0.6459 (from cache 6a8f132cc447b0fb2de5db433ae91ab6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 888/1200: Weighted fbeta score: 0.6462 (from cache 506972d21e12ed71a5876851ac42fcb6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 889/1200: Weighted fbeta score: 0.6434 (from cache 3462cec59345e3225aafbebf548ace59). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 890/1200: Weighted fbeta score: 0.6497 (from cache 8ca5dad85c5f7c5c4db5c10eb75ab7c1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 891/1200: Weighted fbeta score: 0.6442 (from cache 66e02359328fe76586fd5e126488363d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 892/1200: Weighted fbeta score: 0.6450 (from cache bb1bbcc4ee9eae988d35bc3c3a1a37a9). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 893/1200: Weighted fbeta score: 0.6458 (from cache 5bd8cdccd47a3f93928bfc7597b46a56). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 894/1200: Weighted fbeta score: 0.6427 (from cache 0272b516a508037c280cedea789a234f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 895/1200: Weighted fbeta score: 0.6486 (from cache 96faade9f6611c2fb80240bda80369f8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 896/1200: Weighted fbeta score: 0.6461 (from cache 2094f8584821cfd68a82ce365184dcb4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 897/1200: Weighted fbeta score: 0.6481 (from cache 249d442a01d92a0bbc23f12199972106). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 898/1200: Weighted fbeta score: 0.6525 (from cache e2dde29027df6a38c1638c10134f1234). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 899/1200: Weighted fbeta score: 0.6526 (from cache 04bf927921876a7197e0afb975a5a8c8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 900/1200: Weighted fbeta score: 0.6546 (from cache 420bde098eec4b4f19523beb8f25cb45). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 901/1200: Weighted fbeta score: 0.6448 (from cache 8feb2fb485e0b519dc6ac45ca7aa861f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 902/1200: Weighted fbeta score: 0.6465 (from cache ae3281619af31f5ab86a79f435a9315b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 903/1200: Weighted fbeta score: 0.6500 (from cache 1914da74ac5f433b1c404a9c5312428f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 904/1200: Weighted fbeta score: 0.6455 (from cache 9c0f6a254041c7fd2a5d159ecf517e99). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 905/1200: Weighted fbeta score: 0.6528 (from cache 8f184b651a5bfa8d915639ab912ec6f0). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 906/1200: Weighted fbeta score: 0.6515 (from cache 2b2a040ce82bb97b950c1a86d1579a3c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 907/1200: Weighted fbeta score: 0.6463 (from cache 77e4d9afc272d18363604651c8a8358a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 908/1200: Weighted fbeta score: 0.6484 (from cache f56bb9e1de5364626273bc71d8d815ce). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 909/1200: Weighted fbeta score: 0.6480 (from cache fd45fe2e66bad3d471581ed28748f258). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 910/1200: Weighted fbeta score: 0.6468 (from cache 0bd54572ca1faddbbabcc89c2513fb79). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 911/1200: Weighted fbeta score: 0.6422 (from cache 6ae38754d44eb544552cecc73518c54d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 912/1200: Weighted fbeta score: 0.6422 (from cache 227019fbc7a2e2b2abff108057e012c2). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 913/1200: Weighted fbeta score: 0.6489 (from cache 4e18f4d058c98110b880669069abf561). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 914/1200: Weighted fbeta score: 0.6509 (from cache bec6214e742d28458f690d9ded22c597). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 915/1200: Weighted fbeta score: 0.6485 (from cache 7cff4f160ad532fe45005e6d85837826). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 916/1200: Weighted fbeta score: 0.6340 (from cache 5cdfb3c50a944b5245236d65fc911c96). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 917/1200: Weighted fbeta score: 0.6410 (from cache b0c902c22cb146646ddaa8b0b52418ff). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 918/1200: Weighted fbeta score: 0.6423 (from cache 88e8c78a76910c828cf2e64d17ac9883). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 919/1200: Weighted fbeta score: 0.6415 (from cache 7be11d930770400c5a8ebe50f66761ef). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 920/1200: Weighted fbeta score: 0.6393 (from cache 7f4720dda0979b701ba4cb1146482f93). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 921/1200: Weighted fbeta score: 0.6399 (from cache f9847f696528490e4c846bdb3d669b98). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 922/1200: Weighted fbeta score: 0.6510 (from cache 0ab20d54f73d72178cb5cc30b870dc90). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 923/1200: Weighted fbeta score: 0.6482 (from cache 51d57e7e9637c71e59b850b7fbc99d93). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 924/1200: Weighted fbeta score: 0.6482 (from cache cc8a2f9dacf22018f2ffe94533e3840d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 925/1200: Weighted fbeta score: 0.6437 (from cache 50d1387dff9698be116d9ed727a1bec4). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 926/1200: Weighted fbeta score: 0.6487 (from cache e95cad985a3a2ed9066206dc903e0d71). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 927/1200: Weighted fbeta score: 0.6434 (from cache fc49d39b365d4d1ffe37a9bd98db5438). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 928/1200: Weighted fbeta score: 0.6450 (from cache 1c1005615c3dd9e8b85dc41d14e8c713). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 929/1200: Weighted fbeta score: 0.6492 (from cache 190f5bcecdccc949befe886322674651). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 930/1200: Weighted fbeta score: 0.6499 (from cache 5cf0c09ae0501d3fde2ab38389bbc408). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 931/1200: Weighted fbeta score: 0.6502 (from cache 0a1e59ebdd14c98b835e8929e599db39). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 932/1200: Weighted fbeta score: 0.6461 (from cache 8d396001f4fa697d10597b3c364f6f2a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 933/1200: Weighted fbeta score: 0.6469 (from cache eed3ba61d3b2ae7528b6ccd64290bc43). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 934/1200: Weighted fbeta score: 0.6490 (from cache c1929d8254919768879510b17dcec7a8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 935/1200: Weighted fbeta score: 0.6455 (from cache ff69905c3588353e31dda5fd7967399f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 936/1200: Weighted fbeta score: 0.6455 (from cache 4da77443e2ff275f04db73d5e6b8a9eb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 937/1200: Weighted fbeta score: 0.6503 (from cache 5ccf89271edcb5ecbe0eaa3d7817163f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 938/1200: Weighted fbeta score: 0.6414 (from cache a74595487432df53719017d47b2e63bb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 939/1200: Weighted fbeta score: 0.6414 (from cache 1d81055da3679b46861dd3deae6d4e62). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 940/1200: Weighted fbeta score: 0.6400 (from cache 23575fb279c85d9d4716c595b28fe8ca). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 941/1200: Weighted fbeta score: 0.6428 (from cache defe0eb339dc1e38e580cba94eb7465f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 942/1200: Weighted fbeta score: 0.6439 (from cache 0ba0ad5f01e20edb6dbd06bf5a913adf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 943/1200: Weighted fbeta score: 0.6475 (from cache 81a6bee579304dcf617570ab2112a142). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 944/1200: Weighted fbeta score: 0.6484 (from cache 6e651b408c58a41f3c58e766ed97517f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 945/1200: Weighted fbeta score: 0.6486 (from cache b8723ce292fd75f5357cecc646e78833). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 946/1200: Weighted fbeta score: 0.6442 (from cache be88170a6e00e61f1e18e2480e139435). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 947/1200: Weighted fbeta score: 0.6446 (from cache 6157a6692c4e21cabde12c9fed29767a). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 948/1200: Weighted fbeta score: 0.6446 (from cache 35396401defe7768a937b4183ca02fe8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 949/1200: Weighted fbeta score: 0.6472 (from cache bfc39c11d3d50363d36be542e9d62451). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 950/1200: Weighted fbeta score: 0.6465 (from cache 7f5310bf9a9958f541ea9f9d9fefa246). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 951/1200: Weighted fbeta score: 0.6434 (from cache 89ebd96138db09cfa2eccde1904e2236). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 952/1200: Weighted fbeta score: 0.6501 (from cache 74ece5e4895f7adfd28bc632cf6879e1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 953/1200: Weighted fbeta score: 0.6500 (from cache 9854f26111d0ce603e6e49132b366df8). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 954/1200: Weighted fbeta score: 0.6462 (from cache 2508f41f671000c73ec7030e939e202e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 955/1200: Weighted fbeta score: 0.6459 (from cache 3139a05fde50695facba8d22946c9e6f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 956/1200: Weighted fbeta score: 0.6471 (from cache 93de27464ddeea64ceb02dccb2aafd74). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 957/1200: Weighted fbeta score: 0.6448 (from cache 67f2f045648de2be48e04f1cad9af66b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 958/1200: Weighted fbeta score: 0.6469 (from cache ffe717a2662c2b5a74636fdc85b66a04). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 959/1200: Weighted fbeta score: 0.6486 (from cache 819e96d2c4d0b81deb6de2bba70ed5d7). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 960/1200: Weighted fbeta score: 0.6486 (from cache 239d1a28516ae48daffe1eb5eb03dd88). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 961/1200: Weighted fbeta score: 0.6438 (from cache 5f01c868a7f7a40760887c4014e9d40c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 962/1200: Weighted fbeta score: 0.6533 (from cache 9e32bcf14da2cc9e680d2f5220fcebbf). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 963/1200: Weighted fbeta score: 0.6585 (from cache 908433e61e16aee025047174d1cb913b). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 964/1200: Weighted fbeta score: 0.6497 (from cache 0db9068b3d613c3142b6cab5f1bf5ea1). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 965/1200: Weighted fbeta score: 0.6540 (from cache 517820966bf692f1650a2175bed3e90e). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 966/1200: Weighted fbeta score: 0.6567 (from cache f114beab66a0156058eef66f3e7e6b8d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 967/1200: Weighted fbeta score: 0.6527 (from cache 39a9edebbb9275d1f772996b36cfa0be). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 968/1200: Weighted fbeta score: 0.6614 (from cache 41c2cba63c29830b4d4866095d1a5728). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 969/1200: Weighted fbeta score: 0.6576 (from cache 2dd043eac2fe3cb4a6760471496c6f21). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 970/1200: Weighted fbeta score: 0.6551 (from cache 31e836fd30b86572c24cd564c02ee5f6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 971/1200: Weighted fbeta score: 0.6583 (from cache 467b753f0bc85569b8febf3fa5d3ba77). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 972/1200: Weighted fbeta score: 0.6552 (from cache 2a03e26b3c35175d6e647a062831a97c). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 973/1200: Weighted fbeta score: 0.6471 (from cache 179f73c7b4acbf95c362529491503b23). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 974/1200: Weighted fbeta score: 0.6555 (from cache 3362486e460953866acdce919b34a6eb). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 975/1200: Weighted fbeta score: 0.6520 (from cache cb6a2dee2a27e8a0de7a521754583d0d). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 976/1200: Weighted fbeta score: 0.6564 (from cache 971a622023955336e26ff755c9681f72). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 977/1200: Weighted fbeta score: 0.6520 (from cache beaa833f002cded0664fd628cc166494). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 978/1200: Weighted fbeta score: 0.6530 (from cache f9d4d3920f22bc92667a4e982189ed7f). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 979/1200: Weighted fbeta score: 0.6551 (from cache a9c1786685f15321ab45aaf04d77a5a6). Best score so far: 0.6635\n",
      "Evaluating model 2, combination 980/1200: Weighted fbeta score: 0.6654 (from cache 4d3494b890c7ab93b1e7e78490edfa3f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 981/1200: Weighted fbeta score: 0.6591 (from cache b14095dba6fbcf951887554e7f93a38b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 982/1200: Weighted fbeta score: 0.6518 (from cache 69c593995dee683c0e0a6ff684fa7f10). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 983/1200: Weighted fbeta score: 0.6561 (from cache 5f713564e0eeddb1be318269bdfa794b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 984/1200: Weighted fbeta score: 0.6553 (from cache 2f9edbf293e17cb27583a3eb70a8b005). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 985/1200: Weighted fbeta score: 0.6564 (from cache 5559c302eddd9ea392dd12179133da95). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 986/1200: Weighted fbeta score: 0.6618 (from cache 08f9310b144e63406b6ef900b2032249). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 987/1200: Weighted fbeta score: 0.6624 (from cache 9cfef8694a23f7232be5499dc74f1b52). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 988/1200: Weighted fbeta score: 0.6480 (from cache b3e10e1c7d5e1a917f01af980a66db6b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 989/1200: Weighted fbeta score: 0.6595 (from cache 4f886da04e16fea9960aed1ef88ee8a4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 990/1200: Weighted fbeta score: 0.6540 (from cache 4a9fcfa261055c33d130a2fe88c3ca1c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 991/1200: Weighted fbeta score: 0.6576 (from cache 088717f84864eaa685f87cc939b4d17c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 992/1200: Weighted fbeta score: 0.6510 (from cache e240b5ba8517d8d4ecd1c0f67428dcd2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 993/1200: Weighted fbeta score: 0.6498 (from cache ed099399e32f0365b999d7365de8dfb5). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 994/1200: Weighted fbeta score: 0.6508 (from cache 8c16777ed1f3de55db0511a6380c007e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 995/1200: Weighted fbeta score: 0.6518 (from cache 62fba4e41129f2f8a23eddff3510d73d). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 996/1200: Weighted fbeta score: 0.6528 (from cache 180aa1d5812c5fd9ef0a12f6cd58421a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 997/1200: Weighted fbeta score: 0.6595 (from cache 1d04f364cf4eba3eea148811e25bd943). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 998/1200: Weighted fbeta score: 0.6565 (from cache 382e01325ce245a83ad58aaab147dc67). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 999/1200: Weighted fbeta score: 0.6532 (from cache f3b0af4928306eb164829c529c9de701). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1000/1200: Weighted fbeta score: 0.6484 (from cache d78b5206e7a5cce17031041d68eea398). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1001/1200: Weighted fbeta score: 0.6556 (from cache 9508ef7d8292c185426e6a54be403927). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1002/1200: Weighted fbeta score: 0.6581 (from cache 5177d99e72af5b912a9061d3f4cde3a6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1003/1200: Weighted fbeta score: 0.6584 (from cache 5e8450046024453c8bcbddcafc300d52). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1004/1200: Weighted fbeta score: 0.6526 (from cache ed2133c05294b7b17c551a156243fb3c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1005/1200: Weighted fbeta score: 0.6536 (from cache 569f7ad0c8d48b8d25610ba9a3656527). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1006/1200: Weighted fbeta score: 0.6517 (from cache 770a53d2104100c4aeb967499282fcf9). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1007/1200: Weighted fbeta score: 0.6520 (from cache 768c18e2ff2ca2852b47066f9a0d1529). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1008/1200: Weighted fbeta score: 0.6552 (from cache e82cab3622a49d8f2282205c301df866). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1009/1200: Weighted fbeta score: 0.6488 (from cache ad6feb81be62ff7c9fc9fa078615e333). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1010/1200: Weighted fbeta score: 0.6589 (from cache 90bcbe634de0c98a3e374729b810136a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1011/1200: Weighted fbeta score: 0.6546 (from cache 9aa531f5df68dbd7e1f9676c1d0c4c1b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1012/1200: Weighted fbeta score: 0.6477 (from cache 713df45b638abfeb5462abf91028e7a1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1013/1200: Weighted fbeta score: 0.6555 (from cache 0a9983f3c36f7abd45a76b436815d966). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1014/1200: Weighted fbeta score: 0.6516 (from cache 6e46c59e7e2cf2f191ab713a2240593b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1015/1200: Weighted fbeta score: 0.6539 (from cache e301575d62b1a5ef3095748c1697b6e8). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1016/1200: Weighted fbeta score: 0.6583 (from cache 2e17d7a66b77553eb049a0bba8b18ed0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1017/1200: Weighted fbeta score: 0.6546 (from cache 49b5d70e45c6ce745cf3d4449c9acede). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1018/1200: Weighted fbeta score: 0.6544 (from cache 179640f46d9fed56b4fedc9827f230ab). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1019/1200: Weighted fbeta score: 0.6494 (from cache 7738813275a6d42ced23911574e575f1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1020/1200: Weighted fbeta score: 0.6527 (from cache 77374c2c93e010784eed091cd68c4a17). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1021/1200: Weighted fbeta score: 0.6451 (from cache ed89a01b17a1d4477d18e5f6490c6890). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1022/1200: Weighted fbeta score: 0.6527 (from cache 547ce7db66997fb1a23c97974b89ea6d). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1023/1200: Weighted fbeta score: 0.6472 (from cache 110bc7b2a589123c8f963bc710562c7b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1024/1200: Weighted fbeta score: 0.6457 (from cache 00c7e610cf400790130f9ead49ef84cc). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1025/1200: Weighted fbeta score: 0.6444 (from cache 9ad77427262e2966435478f353dccc75). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1026/1200: Weighted fbeta score: 0.6481 (from cache 8701450ec9e59fc1e6573b45f25b33df). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1027/1200: Weighted fbeta score: 0.6447 (from cache 21e5b4cd6e670acab3ce344c98c4387b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1028/1200: Weighted fbeta score: 0.6500 (from cache 45c5db15bcad7fe4f698f84ded096edd). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1029/1200: Weighted fbeta score: 0.6508 (from cache 0ee18d9467142323ce93aa6c9a404ff6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1030/1200: Weighted fbeta score: 0.6446 (from cache f994eace7130d597a9faf7527ed779ea). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1031/1200: Weighted fbeta score: 0.6504 (from cache 18a4176c20adc65c6b4641d1e2e8b47e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1032/1200: Weighted fbeta score: 0.6492 (from cache 1c33c882898189fe308c1c573024f9f6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1033/1200: Weighted fbeta score: 0.6446 (from cache 8ad446697a4c20da7a0400082ac32e13). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1034/1200: Weighted fbeta score: 0.6527 (from cache 1e9fe60a37860b73236c98abdd0fd246). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1035/1200: Weighted fbeta score: 0.6521 (from cache e4132f93baad6ec0e48c42ddf57f7ab4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1036/1200: Weighted fbeta score: 0.6509 (from cache 601dd0fd070c3e0fd0aabd30a1f00723). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1037/1200: Weighted fbeta score: 0.6548 (from cache 0968f676839129610b0d48c1a23c7a2a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1038/1200: Weighted fbeta score: 0.6524 (from cache f940b3d831f3e8e7f41b2f66ee8fa40c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1039/1200: Weighted fbeta score: 0.6459 (from cache b122428b70f6f49aa3ae1080f848a330). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1040/1200: Weighted fbeta score: 0.6486 (from cache a08721ee9224ba0cf6c9b30350e4433e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1041/1200: Weighted fbeta score: 0.6484 (from cache 92531d587193587972deb0477f853a1e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1042/1200: Weighted fbeta score: 0.6487 (from cache 5f94f0dc8c1ad2bbb66e7e1b1a560503). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1043/1200: Weighted fbeta score: 0.6523 (from cache db746ed16336cf5122af7d02a57f399f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1044/1200: Weighted fbeta score: 0.6517 (from cache 6c5b1a82d494885fd8c165743be0a05c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1045/1200: Weighted fbeta score: 0.6519 (from cache 2046fe423db8a4fbeb819a969de087ee). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1046/1200: Weighted fbeta score: 0.6506 (from cache ed938f10c40ac4c0e481d5bcc935d7ae). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1047/1200: Weighted fbeta score: 0.6507 (from cache 1a7bee8faa8146a0d844e7e8d2f28f22). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1048/1200: Weighted fbeta score: 0.6570 (from cache dceb6b7beee62df48b1888eb18d3394a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1049/1200: Weighted fbeta score: 0.6543 (from cache 0b6a51232c953330b15fc4e99653c518). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1050/1200: Weighted fbeta score: 0.6497 (from cache c6dab3c041496340f2ffa1a3f03ff098). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1051/1200: Weighted fbeta score: 0.6573 (from cache e12e8dd2b21f15da4ee5f30e0def3912). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1052/1200: Weighted fbeta score: 0.6537 (from cache 5d1540cad3b3417fd1e49666343a4ed3). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1053/1200: Weighted fbeta score: 0.6499 (from cache 3e7e81497df6d8bcd0adc29740efb75f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1054/1200: Weighted fbeta score: 0.6493 (from cache 43f953f2c3dd392f846294575b189507). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1055/1200: Weighted fbeta score: 0.6471 (from cache 2fd4094dd225e4df3323e277ae6f6b25). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1056/1200: Weighted fbeta score: 0.6463 (from cache bb1a36a58712e2de76383f910a31966f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1057/1200: Weighted fbeta score: 0.6538 (from cache c4c871569ae286707ab287965c6ff860). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1058/1200: Weighted fbeta score: 0.6546 (from cache 925a33bf2e05d466df928460aff15835). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1059/1200: Weighted fbeta score: 0.6516 (from cache be8260a02e71892bb6f0ca25bcc9710c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1060/1200: Weighted fbeta score: 0.6615 (from cache 9ba5f318e94a290e80ba16075f907276). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1061/1200: Weighted fbeta score: 0.6537 (from cache 0f99647236b125eec16a70dd1d7b5ec2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1062/1200: Weighted fbeta score: 0.6541 (from cache 6b5b8a86936de8dbe17a476d5e84c6d2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1063/1200: Weighted fbeta score: 0.6473 (from cache c3a096eea49acdf6983292ac05636c28). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1064/1200: Weighted fbeta score: 0.6485 (from cache c68f03e19a568a2a64409f0350b28482). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1065/1200: Weighted fbeta score: 0.6509 (from cache e9b7a62d6f1eb87e7b155b8fff9b24f6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1066/1200: Weighted fbeta score: 0.6412 (from cache a55644e6da6c5d9aaf359b5e4629f8df). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1067/1200: Weighted fbeta score: 0.6394 (from cache df31e03392093d95ab4d60ac48fc7c48). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1068/1200: Weighted fbeta score: 0.6415 (from cache 7d635e00a38c0551bad19935d2b49e4b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1069/1200: Weighted fbeta score: 0.6469 (from cache 10d256fc9f33a8a54615aa035e11686f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1070/1200: Weighted fbeta score: 0.6498 (from cache a3e882fcc24a5bc4430acd502f8be69a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1071/1200: Weighted fbeta score: 0.6481 (from cache e598c2654e65707a385eaa1ee78e79f0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1072/1200: Weighted fbeta score: 0.6527 (from cache e13b76a7f32313c0fcd8846040e85dcf). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1073/1200: Weighted fbeta score: 0.6522 (from cache a8714c09044fd3a961961b7cfed59d5e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1074/1200: Weighted fbeta score: 0.6560 (from cache 2baff3e086501ad0ea80545816d148cc). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1075/1200: Weighted fbeta score: 0.6482 (from cache f5295ae88ea493c79228d195e2790e17). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1076/1200: Weighted fbeta score: 0.6493 (from cache b57d8f554eb3a9d8c9ce1c5de7a926dd). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1077/1200: Weighted fbeta score: 0.6519 (from cache 807e1f9b03474aa6b68ab96e52ad9790). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1078/1200: Weighted fbeta score: 0.6484 (from cache edb9284662280e67612ecdaffe56c010). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1079/1200: Weighted fbeta score: 0.6456 (from cache 40dd9a742282f58f87fd986bbfa8e6f5). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1080/1200: Weighted fbeta score: 0.6469 (from cache ca3251b1edc8fe0ccf6a735099f8977c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1081/1200: Weighted fbeta score: 0.6434 (from cache 37f66d637cdb8fbf8858be6871217cd8). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1082/1200: Weighted fbeta score: 0.6451 (from cache d96b07ba3e5d610daba126f89b99f5c6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1083/1200: Weighted fbeta score: 0.6456 (from cache 14f72553bb5c7aedf9dfa0565174b19f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1084/1200: Weighted fbeta score: 0.6464 (from cache 0e41699390abd5b43dc001450be7e82f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1085/1200: Weighted fbeta score: 0.6483 (from cache 5c680407c82407e6bf06702e84981bcb). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1086/1200: Weighted fbeta score: 0.6451 (from cache a9d69d221ccbca7775f94a8d2a3f27f6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1087/1200: Weighted fbeta score: 0.6462 (from cache e88b004a0aec6a63a8abcc5bdd3fd146). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1088/1200: Weighted fbeta score: 0.6476 (from cache 140229a8438288b8baf854b26d788934). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1089/1200: Weighted fbeta score: 0.6482 (from cache 4d5783c162f382992a0d71274f3afc9d). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1090/1200: Weighted fbeta score: 0.6441 (from cache 26ec1df5a5143009b3916e4516f43205). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1091/1200: Weighted fbeta score: 0.6467 (from cache 64a946fffdf77b61d13d3eac56760f27). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1092/1200: Weighted fbeta score: 0.6465 (from cache 07089d28dee137e75ba091a95548ec86). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1093/1200: Weighted fbeta score: 0.6518 (from cache 53f15ae6ad42faa05c925c33fd3fc760). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1094/1200: Weighted fbeta score: 0.6539 (from cache 39be4d9d962fc7789d2a8c3c6e9e9f04). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1095/1200: Weighted fbeta score: 0.6550 (from cache e2e7ef8b5071acd3ef5a6dd4ab70a51a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1096/1200: Weighted fbeta score: 0.6478 (from cache 081c7ad4be9aafe8c343f51ca91c9c24). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1097/1200: Weighted fbeta score: 0.6500 (from cache ccf0039b1e2e932a7ea7a0c7bc9ce939). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1098/1200: Weighted fbeta score: 0.6446 (from cache 5a44fb3e1b1fd6f9050a0d8fcc972686). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1099/1200: Weighted fbeta score: 0.6490 (from cache 2b8f59ea3ff4dc3f29aa3529e1371180). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1100/1200: Weighted fbeta score: 0.6523 (from cache 74696d34bd08e4d6cc59fe045accdb00). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1101/1200: Weighted fbeta score: 0.6497 (from cache e32dd5c18bab9eda463c0dfe9d06f3c1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1102/1200: Weighted fbeta score: 0.6449 (from cache 6720a10eea300082b50ec22b038c7713). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1103/1200: Weighted fbeta score: 0.6456 (from cache 35d9d81c0fec18bc1b67d1d4ee6f13eb). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1104/1200: Weighted fbeta score: 0.6449 (from cache ed57d8601048017f8ad0ac419cc3a785). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1105/1200: Weighted fbeta score: 0.6564 (from cache 3eddca63ea3eedb28d284513e3964e14). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1106/1200: Weighted fbeta score: 0.6518 (from cache 43370c2dd5d4a631cbc021335c1ca11b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1107/1200: Weighted fbeta score: 0.6500 (from cache 0c4c4b5995f885dd4f99f9a19c529896). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1108/1200: Weighted fbeta score: 0.6438 (from cache 9abad09cfe1c545f650a3a8a0898a245). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1109/1200: Weighted fbeta score: 0.6442 (from cache 497b1589bff814cf5a135b1f8e785cc1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1110/1200: Weighted fbeta score: 0.6435 (from cache 67a004579268765999b4ff49b138d064). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1111/1200: Weighted fbeta score: 0.6484 (from cache 343749a7ef331a3739346103081895b1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1112/1200: Weighted fbeta score: 0.6534 (from cache 1b15c737ca61855f28c19bb9f699e408). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1113/1200: Weighted fbeta score: 0.6501 (from cache 4166408528b93b8a23c36e6c9d3a9cd2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1114/1200: Weighted fbeta score: 0.6402 (from cache d11052dd695302accfea47af55e6491a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1115/1200: Weighted fbeta score: 0.6442 (from cache 0671af846fef07a3fef2863cd2f34a99). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1116/1200: Weighted fbeta score: 0.6452 (from cache da484ffdbba363ee2a6a8eedadb3ed31). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1117/1200: Weighted fbeta score: 0.6497 (from cache 001b4a88b253c07b3b2949122b8eaca0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1118/1200: Weighted fbeta score: 0.6473 (from cache 3b8ce5f7b1001c9d66ae8f2cb332757c). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1119/1200: Weighted fbeta score: 0.6453 (from cache 2dc7d104707652f8d8873d92fa96e88a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1120/1200: Weighted fbeta score: 0.6442 (from cache b59b77a71685f6fd5f766afc524d4538). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1121/1200: Weighted fbeta score: 0.6540 (from cache f1504f99b4bf02679fa1f6c1cb740019). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1122/1200: Weighted fbeta score: 0.6529 (from cache afd38d509a427e86b49e59079b014cf4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1123/1200: Weighted fbeta score: 0.6505 (from cache 9520dfdc332110c9defbbd14c300662f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1124/1200: Weighted fbeta score: 0.6444 (from cache 752c0ed48c03084c276b00c193f987e8). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1125/1200: Weighted fbeta score: 0.6479 (from cache 79ad5c3b772ca2183bc028d87f374f44). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1126/1200: Weighted fbeta score: 0.6430 (from cache fb58ad54ecbfdf753294bda902c6591f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1127/1200: Weighted fbeta score: 0.6457 (from cache f2b34db01ad6e294b98d700c2f3c3963). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1128/1200: Weighted fbeta score: 0.6468 (from cache 6de4ecb96c95429df578329c6fbbde57). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1129/1200: Weighted fbeta score: 0.6549 (from cache 8d8046c6aaefe7d615b26625713e37cb). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1130/1200: Weighted fbeta score: 0.6558 (from cache 79495575e614351176753780b4ba9260). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1131/1200: Weighted fbeta score: 0.6542 (from cache 3bb61a28a8585924df7fdd03b4f28584). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1132/1200: Weighted fbeta score: 0.6560 (from cache 6277a713e82176eb41880248707d8421). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1133/1200: Weighted fbeta score: 0.6472 (from cache b818d8640d3d82801b51aed8c1151e99). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1134/1200: Weighted fbeta score: 0.6530 (from cache 42ac5910dd882d9f6c2c5a69769eb023). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1135/1200: Weighted fbeta score: 0.6557 (from cache 8cf512a4c9cf9e6c68614903491cbb56). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1136/1200: Weighted fbeta score: 0.6542 (from cache 39513a27409c6c5e76b33ff8406c17b7). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1137/1200: Weighted fbeta score: 0.6514 (from cache 9c1c6d4ccd4dbec40c32f08ed295b5c2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1138/1200: Weighted fbeta score: 0.6494 (from cache 40f0168eed05e6379eaa44e2658c69a9). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1139/1200: Weighted fbeta score: 0.6475 (from cache 67e566817660e24b1ca04445af6cca63). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1140/1200: Weighted fbeta score: 0.6477 (from cache 75cdf057777ac14185b3acedb08afc15). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1141/1200: Weighted fbeta score: 0.6489 (from cache 93ba4116dd90249e46b4b160c070d0b6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1142/1200: Weighted fbeta score: 0.6466 (from cache 1797d1205dd377e6e796c46885d45a7a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1143/1200: Weighted fbeta score: 0.6490 (from cache da1431bf9473397ab5a42f8c5667ce39). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1144/1200: Weighted fbeta score: 0.6454 (from cache 98a392fb255f55c774d560c560ad7aad). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1145/1200: Weighted fbeta score: 0.6434 (from cache 78d9423ec62dabf1d0c4c0397083e857). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1146/1200: Weighted fbeta score: 0.6485 (from cache 1a52501f80fbafeb257efe41db760c0f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1147/1200: Weighted fbeta score: 0.6468 (from cache 84a783fa1047b787f8ad8977486bbb5a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1148/1200: Weighted fbeta score: 0.6478 (from cache 6d6ed3c5c766c43e781bec1684e5c8a8). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1149/1200: Weighted fbeta score: 0.6478 (from cache be0b366cbff9c3dda21f34f3c4f033f7). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1150/1200: Weighted fbeta score: 0.6518 (from cache 17c2f602d8d5f48e83dac7f2377ec44a). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1151/1200: Weighted fbeta score: 0.6543 (from cache e9248050109111eb432aed1c075d5d6e). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1152/1200: Weighted fbeta score: 0.6543 (from cache af14418981931c6722c9b02996d4e9ef). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1153/1200: Weighted fbeta score: 0.6524 (from cache b74e09da03f20c191fd974596bb4c3be). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1154/1200: Weighted fbeta score: 0.6550 (from cache 11aeafe60c64f197ac09b9e6e6a212e6). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1155/1200: Weighted fbeta score: 0.6498 (from cache 283d2d0d5eecb5e0c978c39c07c946e1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1156/1200: Weighted fbeta score: 0.6414 (from cache a09b5ed1830024e30725f2c8bf149e84). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1157/1200: Weighted fbeta score: 0.6470 (from cache ca3e0fbd99421ab00f75ab0f18d4f5bd). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1158/1200: Weighted fbeta score: 0.6487 (from cache d2aa45013c0204fea1b3319b90bf8e46). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1159/1200: Weighted fbeta score: 0.6498 (from cache a459b49186dc8d1d43c6a052879ccf67). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1160/1200: Weighted fbeta score: 0.6513 (from cache 71a3ca71d58f6d742682e57f7b3f1cf0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1161/1200: Weighted fbeta score: 0.6513 (from cache 0c4ca38b7ed3548c1d3dfad7536b1221). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1162/1200: Weighted fbeta score: 0.6468 (from cache a1d65b156a65133846b55028fb342888). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1163/1200: Weighted fbeta score: 0.6464 (from cache 99e411baee8e0fb81aa0e55b8de5c55f). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1164/1200: Weighted fbeta score: 0.6464 (from cache 79d68fba8e96dc6948802b5842718e53). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1165/1200: Weighted fbeta score: 0.6480 (from cache 51972769696ef6fedf12ad8e5098d285). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1166/1200: Weighted fbeta score: 0.6564 (from cache c0bc60b7d848cbe2899b1606d4fa9dce). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1167/1200: Weighted fbeta score: 0.6515 (from cache 96496f6b652b1497a9b450868ac9fafb). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1168/1200: Weighted fbeta score: 0.6579 (from cache fe29e755b210e706ffcb601a08fc4754). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1169/1200: Weighted fbeta score: 0.6549 (from cache f3b3488428bca979cf3d3f6b7b1da643). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1170/1200: Weighted fbeta score: 0.6563 (from cache 7c88eb0bcd3f78b11002e523b1a011e9). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1171/1200: Weighted fbeta score: 0.6429 (from cache fe14c638739605d46c52fe8a9a09e7ee). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1172/1200: Weighted fbeta score: 0.6489 (from cache 354667984a99b51397ea6f8eda1fd2a4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1173/1200: Weighted fbeta score: 0.6491 (from cache 166da0bfc0c4a78b935c5210cffbe31b). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1174/1200: Weighted fbeta score: 0.6398 (from cache cc6485d4bb0c978909705732a832cf10). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1175/1200: Weighted fbeta score: 0.6405 (from cache 9f60de24e9e1c33d3883cd8f2e7ce224). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1176/1200: Weighted fbeta score: 0.6405 (from cache b39fc14e470b4b3943563823f2bcb4c7). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1177/1200: Weighted fbeta score: 0.6453 (from cache d454e0ab8d7538bbf7229b6f2073a9c0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1178/1200: Weighted fbeta score: 0.6478 (from cache 7e4f07c60afed961b9a1edd9f10591a4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1179/1200: Weighted fbeta score: 0.6503 (from cache 0b21774bafdad4ab7f7f959d62bbd6b1). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1180/1200: Weighted fbeta score: 0.6374 (from cache 261500abd7f843135ed3711963707bb2). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1181/1200: Weighted fbeta score: 0.6487 (from cache b7bd94f05a05276af5de402ceccc40d9). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1182/1200: Weighted fbeta score: 0.6457 (from cache 308ead4a59a598f4f5d7cfddbd3abbfc). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1183/1200: Weighted fbeta score: 0.6435 (from cache e04f323bb5318734c7a6fc83be14a71d). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1184/1200: Weighted fbeta score: 0.6452 (from cache 27828d55256e5e846e7abb97d03cbc24). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1185/1200: Weighted fbeta score: 0.6446 (from cache cd4e179861c3e50863e9b80e600b14cf). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1186/1200: Weighted fbeta score: 0.6414 (from cache 600b00e160de83fa6924c8a2b1d8f9d4). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1187/1200: Weighted fbeta score: 0.6438 (from cache 020d392645a725d46c7c5f29440a8462). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1188/1200: Weighted fbeta score: 0.6438 (from cache 690fc4278d36dcc284eb56915f7e9176). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1189/1200: Weighted fbeta score: 0.6517 (from cache 79755a56f17cde580cde384067d1eada). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1190/1200: Weighted fbeta score: 0.6568 (from cache d0d5aeadb571eb0e05b63e61eed40265). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1191/1200: Weighted fbeta score: 0.6469 (from cache 2bac58a123ccd2cbfd9a1dfcd43ffa36). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1192/1200: Weighted fbeta score: 0.6421 (from cache 45a40c75f5e49234f177106c1bcb0996). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1193/1200: Weighted fbeta score: 0.6407 (from cache 7ec53dfbbb7f0afe102d1bca02629a34). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1194/1200: Weighted fbeta score: 0.6453 (from cache b9c7dc4b1836f7200ae35aec4e988cbd). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1195/1200: Weighted fbeta score: 0.6450 (from cache 5069f85bfa1376b79661804b4c0ee079). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1196/1200: Weighted fbeta score: 0.6434 (from cache 55ec0011b5d831bb18f5af5729ba1dda). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1197/1200: Weighted fbeta score: 0.6433 (from cache 768b5d67af80d6004a19e61ba66dd465). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1198/1200: Weighted fbeta score: 0.6484 (from cache 9fab403d3e66e9d0eb9ffae42e70d105). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1199/1200: Weighted fbeta score: 0.6530 (from cache 937312b7767b208496c181c8a3eb54d0). Best score so far: 0.6654\n",
      "Evaluating model 2, combination 1200/1200: Weighted fbeta score: 0.6530 (from cache 2449e908584d53696204ecdaaaed20f1). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 1/288: Weighted fbeta score: 0.6528 (from cache 6df6e06e038ab63c50cb739a61ca1c1c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 2/288: Weighted fbeta score: 0.0000 (from cache 1c3602760e5cb2a7ad464194d1860d4c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 3/288: Weighted fbeta score: 0.6509 (from cache 16899ef329c57b83ac83bfb06e20e09d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 4/288: Weighted fbeta score: 0.0000 (from cache 80dd194fd528321800f1be523a9abc2c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 5/288: Weighted fbeta score: 0.6443 (from cache 896bd2f38804d18a6c1de685ce8fb76c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 6/288: Weighted fbeta score: 0.0000 (from cache 0a792382c1e68044b938a0321e02f445). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 7/288: Weighted fbeta score: 0.6274 (from cache a1ca76d84873b43f824c67b97ac6ddb3). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 8/288: Weighted fbeta score: 0.0000 (from cache 551a875ef4d71d4eba5ea26ef2774929). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 9/288: Weighted fbeta score: 0.6477 (from cache c909d160d246d4ec5208e52cb73c2cb9). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 10/288: Weighted fbeta score: 0.0000 (from cache 4ae78905143a9138135cb9bce0c2f59a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 11/288: Weighted fbeta score: 0.6485 (from cache 3ba2ee2c39f67f3af9645c8aafe62c97). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 12/288: Weighted fbeta score: 0.0000 (from cache 9191b6559998372ef47df9ee3ab5c993). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 13/288: Weighted fbeta score: 0.6443 (from cache 0786a882d68773c177a7a18ffce9ea2a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 14/288: Weighted fbeta score: 0.0000 (from cache 633cbf2b7d708c1427fd1deb8d4290fa). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 15/288: Weighted fbeta score: 0.6274 (from cache bdb6bb2ad955ee78da4a0fccba7070d2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 16/288: Weighted fbeta score: 0.0000 (from cache 432ac4a5f1df1ab31d61408d97e42ec8). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 17/288: Weighted fbeta score: 0.6597 (from cache 5daa21fcac6e6fef6e51dd93e4c98df2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 18/288: Weighted fbeta score: 0.0000 (from cache d15456e61af3848f8059bb9d03077b38). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 19/288: Weighted fbeta score: 0.6497 (from cache 6332ba0b215c9d5b894265eb0c3a2b74). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 20/288: Weighted fbeta score: 0.0000 (from cache f5660394ec51fe3a966f14dd339bbf7d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 21/288: Weighted fbeta score: 0.6471 (from cache 264ab67cf132125a9c06c15c4b1230ff). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 22/288: Weighted fbeta score: 0.0000 (from cache a04e00428445941597df14165e9f4e24). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 23/288: Weighted fbeta score: 0.6274 (from cache 5306b4804a6a1ab56c07e464e01d3762). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 24/288: Weighted fbeta score: 0.0000 (from cache 5cb99bef05ba120a6c6c79931f04ac6e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 25/288: Weighted fbeta score: 0.6467 (from cache fcc93bab38c2bb3178dae632d29394ad). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 26/288: Weighted fbeta score: 0.0000 (from cache bbb78ab80b3ad1f6d964df25be0e71fe). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 27/288: Weighted fbeta score: 0.6398 (from cache 24552749cef999ff731b70030f61a71b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 28/288: Weighted fbeta score: 0.0000 (from cache 3b3521976736b187789a17ffd94327fe). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 29/288: Weighted fbeta score: 0.6375 (from cache 6abc66602de61507b8229a368f6da6f2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 30/288: Weighted fbeta score: 0.0000 (from cache 126f2dc191b37796606c427c0dc4fbb5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 31/288: Weighted fbeta score: 0.6274 (from cache b6c8e81e837b8a86a8af2d4426fb1492). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 32/288: Weighted fbeta score: 0.0000 (from cache b957bb22ed5e0105dfef25cbd2cb291a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 33/288: Weighted fbeta score: 0.3672 (from cache b68d97356eb0ab8882c93e45d6a9b59e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 34/288: Weighted fbeta score: 0.0000 (from cache 6fd9779baa6bbd1b827c47683fe5b7ba). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 35/288: Weighted fbeta score: 0.3675 (from cache fa0f827b27f5b56945b383addeba9a8f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 36/288: Weighted fbeta score: 0.0000 (from cache 746cdcced3a5d9b07249c911ac0e2b3e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 37/288: Weighted fbeta score: 0.3659 (from cache 193106dc2a184c0f208274c632ee3bc4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 38/288: Weighted fbeta score: 0.0000 (from cache f3c6d255bc01058ef65715d45beff4d5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 39/288: Weighted fbeta score: 0.3626 (from cache e92a77901386ce8687934b068770223b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 40/288: Weighted fbeta score: 0.0000 (from cache 9d51ee460f097b2a941abece22d6ac95). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 41/288: Weighted fbeta score: 0.3645 (from cache a540d194b902ec0d45abac359f7a6d22). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 42/288: Weighted fbeta score: 0.0000 (from cache 116b5a61421d755f34f7747dc9c04d36). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 43/288: Weighted fbeta score: 0.3653 (from cache 7ec51102f48750a7f41fcdf1515cc4ca). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 44/288: Weighted fbeta score: 0.0000 (from cache 174de451e996a7917d433333284b0ecc). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 45/288: Weighted fbeta score: 0.3659 (from cache 75b941d67cb389edcf4d1285a714590e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 46/288: Weighted fbeta score: 0.0000 (from cache 0d6ffa37371a7769d0e28a8725198464). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 47/288: Weighted fbeta score: 0.3626 (from cache 5ad31b4b8246318e0b343a089a7e01d8). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 48/288: Weighted fbeta score: 0.0000 (from cache 7df673c80e927ddd98dcfe7e3a7e1b62). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 49/288: Weighted fbeta score: 0.3744 (from cache e7e1ff6c7ac5a30f05695079cb162df9). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 50/288: Weighted fbeta score: 0.0000 (from cache 44c2a327f9a61cc4982ac0dd861d0053). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 51/288: Weighted fbeta score: 0.3766 (from cache cefa7737b579415d02988ae6f6979212). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 52/288: Weighted fbeta score: 0.0000 (from cache e292b2df10b77cb5a6866bf0f571f2ba). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 53/288: Weighted fbeta score: 0.3668 (from cache eb3c163d01968a55d0e444205d105fb6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 54/288: Weighted fbeta score: 0.0000 (from cache f69b73e8d911d6b0d005768e865ab3ec). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 55/288: Weighted fbeta score: 0.3626 (from cache cad59bc6af706d5ab424b13c37c9b13e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 56/288: Weighted fbeta score: 0.0000 (from cache 7a21dca39f52661cafe5bda5b2c7f061). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 57/288: Weighted fbeta score: 0.3713 (from cache d16f0bd9847c51b55e0c53815b32c5ec). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 58/288: Weighted fbeta score: 0.0000 (from cache 2e6481120213afd9fe8fe81a949ee77f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 59/288: Weighted fbeta score: 0.3725 (from cache 9a73002a0b5c2214d5cfc6b0c216375c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 60/288: Weighted fbeta score: 0.0000 (from cache 6ee8687f5e8b9e799469e867bc140c40). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 61/288: Weighted fbeta score: 0.3688 (from cache d15c35f615fc1aa9aa355a47f3f3832d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 62/288: Weighted fbeta score: 0.0000 (from cache ac58e890fab4f32da08a07f6fe59923e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 63/288: Weighted fbeta score: 0.3626 (from cache 56dcdefa1de1644cad3df08cba546256). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 64/288: Weighted fbeta score: 0.0000 (from cache 3ac77063c41b8aa7130838c1c3685b69). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 65/288: Weighted fbeta score: 0.6074 (from cache ab87cb7fe5af4406ef9999e308a182a6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 66/288: Weighted fbeta score: 0.0000 (from cache 74a2406d45b1d176d5b458c6b6fe2458). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 67/288: Weighted fbeta score: 0.6018 (from cache bdae2d8f9b4360468f0dfad698c76f61). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 68/288: Weighted fbeta score: 0.0000 (from cache 1810cd31f5c1a52358df5032c686b598). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 69/288: Weighted fbeta score: 0.6078 (from cache b2fe1e3e5acca4c347bff6102a06eeab). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 70/288: Weighted fbeta score: 0.0000 (from cache c59d140465abba35e6d5a2e5b9871c26). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 71/288: Weighted fbeta score: 0.5934 (from cache 99116fa6ed01f50252f08de9a2c86828). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 72/288: Weighted fbeta score: 0.0000 (from cache a88d46951ce0aa92548f60452910acb2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 73/288: Weighted fbeta score: 0.6113 (from cache a095c79e6898d53da5e2bfc84ada7836). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 74/288: Weighted fbeta score: 0.0000 (from cache 7b5f1d6ffc51e4b7d84bfc80ed15fcea). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 75/288: Weighted fbeta score: 0.6067 (from cache 2bf997c08e921ed8d8ac78e651e961a0). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 76/288: Weighted fbeta score: 0.0000 (from cache 9f21edcc59d095092dd40b4f0786adfa). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 77/288: Weighted fbeta score: 0.6078 (from cache 6505ce89186868827b30bc37bc279244). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 78/288: Weighted fbeta score: 0.0000 (from cache e56d48cb0902b45982e4643908fab76c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 79/288: Weighted fbeta score: 0.5934 (from cache 2bc670eb9d65db153824720a46ab3a54). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 80/288: Weighted fbeta score: 0.0000 (from cache 9d2efe20b722ffcd73afb3f00f5d5e1c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 81/288: Weighted fbeta score: 0.5996 (from cache 58053ac8c662efcf65ed289f381469b5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 82/288: Weighted fbeta score: 0.0000 (from cache e95649f27b72277519b3f7366d0a5ed7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 83/288: Weighted fbeta score: 0.6041 (from cache e62060c28e057393bfd02865ce8b9906). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 84/288: Weighted fbeta score: 0.0000 (from cache aa89184e220a6f94ce3278979a256a4a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 85/288: Weighted fbeta score: 0.6033 (from cache f54f6d6ed07147de20c717a52c221d3f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 86/288: Weighted fbeta score: 0.0000 (from cache 8237b19feae837287336816dbfbeb40a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 87/288: Weighted fbeta score: 0.5934 (from cache 2d742e250ba0ae55cab682d1b8fa6c1b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 88/288: Weighted fbeta score: 0.0000 (from cache 64b00df39f2b7b1c9992499762edebfa). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 89/288: Weighted fbeta score: 0.6039 (from cache fd64fa1aebb82635e1d2f82bf533b5f4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 90/288: Weighted fbeta score: 0.0000 (from cache fe7aff1333b76b8fc402e3f69fdd9b7d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 91/288: Weighted fbeta score: 0.6084 (from cache 0954f3b5ea61a79e6084ba0f2c01cf3a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 92/288: Weighted fbeta score: 0.0000 (from cache eae8db1886477b31d354418189d5c22e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 93/288: Weighted fbeta score: 0.6041 (from cache 4cfd938232150243a38c8a521b4b870d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 94/288: Weighted fbeta score: 0.0000 (from cache 4bb69d4ef9d986f98ec76a48029a6506). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 95/288: Weighted fbeta score: 0.5934 (from cache 08a830aa5312c152e6318aa097dc457d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 96/288: Weighted fbeta score: 0.0000 (from cache 88f9c4ee117e4d5f7202112bd8a1fc1c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 97/288: Weighted fbeta score: 0.6514 (from cache a72229617096f3bd10607285bd2639e7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 98/288: Weighted fbeta score: 0.0000 (from cache ba14891739f3664c87f4971d9ea37c35). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 99/288: Weighted fbeta score: 0.6511 (from cache 857eded1e055c2befa18d6b38b0e30a4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 100/288: Weighted fbeta score: 0.0000 (from cache aec03a90e5ff241a1b4b89463cbc1dec). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 101/288: Weighted fbeta score: 0.6450 (from cache 71a6303edd41585eea502fe4277daaad). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 102/288: Weighted fbeta score: 0.0000 (from cache bc17f5fa0b2a86bd96f652ad9e697d12). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 103/288: Weighted fbeta score: 0.6275 (from cache b17a37de6a0a25405eb1010836efa117). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 104/288: Weighted fbeta score: 0.0000 (from cache e30eb1ccda298d97cf72d630e076299f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 105/288: Weighted fbeta score: 0.6509 (from cache 43c6bba03921eceac5e3cab55e15f540). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 106/288: Weighted fbeta score: 0.0000 (from cache 3b496445f9e766b4cb47442c7fef87fe). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 107/288: Weighted fbeta score: 0.6502 (from cache eb9494e0a8e5f7138938fa1893631d84). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 108/288: Weighted fbeta score: 0.0000 (from cache 828acaf8fe07f676baa5b5bb0f2cddae). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 109/288: Weighted fbeta score: 0.6450 (from cache 09155ef378f97beabafbfe125bd9bdeb). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 110/288: Weighted fbeta score: 0.0000 (from cache 51672c6f9ef0bd7b27e4840d731ea281). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 111/288: Weighted fbeta score: 0.6275 (from cache db490c43c194f4d691baa6af05a4ae0c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 112/288: Weighted fbeta score: 0.0000 (from cache be7c14afb32692d800650e81611b790c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 113/288: Weighted fbeta score: 0.6587 (from cache bf285c2548c2920287dcb79024e5ae6a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 114/288: Weighted fbeta score: 0.0000 (from cache 55fe194ec7b9dea703058cbae7f60d1c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 115/288: Weighted fbeta score: 0.6448 (from cache 4be6ec95db4b07d7b11cb3ea86d4dbac). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 116/288: Weighted fbeta score: 0.0000 (from cache 301ef0007741bc823806d6ff37227350). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 117/288: Weighted fbeta score: 0.6467 (from cache 0b6f3d4eb61ec41ce5da865107813039). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 118/288: Weighted fbeta score: 0.0000 (from cache fa12b6473655fe802f18bc02022962e6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 119/288: Weighted fbeta score: 0.6275 (from cache 97f88cd6a7496a5669801fcaccea76b3). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 120/288: Weighted fbeta score: 0.0000 (from cache fb571284c5334e8f655e2d5bde52dcd5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 121/288: Weighted fbeta score: 0.6443 (from cache 347783dc1424a4e325c45830de51e68e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 122/288: Weighted fbeta score: 0.0000 (from cache 960f2caed61ea44abeef5c0d24b2438f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 123/288: Weighted fbeta score: 0.6397 (from cache 4f0e160538c739f0b9a132d1537584e5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 124/288: Weighted fbeta score: 0.0000 (from cache 462b846bef3c7f263d4121c7f852770f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 125/288: Weighted fbeta score: 0.6364 (from cache 8d9b23848d259edfe837157a8f310893). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 126/288: Weighted fbeta score: 0.0000 (from cache d28acff80a2a2b181562efc3bfff76f7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 127/288: Weighted fbeta score: 0.6275 (from cache e3914f7eda39f33ecb7e37570b602c50). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 128/288: Weighted fbeta score: 0.0000 (from cache d049bf0e5715c09b903476e35dc3aadc). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 129/288: Weighted fbeta score: 0.3742 (from cache fe3d6115a3d3c8a46b8f535094862eaf). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 130/288: Weighted fbeta score: 0.0000 (from cache 38016a6df83bb3ee3f5977a479def9f0). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 131/288: Weighted fbeta score: 0.3707 (from cache 7e9351954ae9a6eb1742e6ca807d2c80). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 132/288: Weighted fbeta score: 0.0000 (from cache 96d06a877622b373564b14f6cf2527a2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 133/288: Weighted fbeta score: 0.3762 (from cache 27d285205150ed48e9d2421b017773f7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 134/288: Weighted fbeta score: 0.0000 (from cache 387cf5e199705e05bb6bc818628a828c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 135/288: Weighted fbeta score: 0.3733 (from cache 27f65bfb5ad589261d4096735a51a24c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 136/288: Weighted fbeta score: 0.0000 (from cache d66e932cc5e86a8cf586d61f79ea45cd). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 137/288: Weighted fbeta score: 0.3791 (from cache 92c37af3a8c523379ebbdb20bee77528). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 138/288: Weighted fbeta score: 0.0000 (from cache 30a14eca3fc9552b2c4f3c6b95c8ad47). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 139/288: Weighted fbeta score: 0.3706 (from cache 879e0749f4eb897caf7a3c6660368ba9). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 140/288: Weighted fbeta score: 0.0000 (from cache 14912fe8d869e5ff3b5a9e81bd04d1b6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 141/288: Weighted fbeta score: 0.3762 (from cache 220c194e2151269fbf25986ce0d3d9fe). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 142/288: Weighted fbeta score: 0.0000 (from cache 1ce1475fecc74080e7a95f471984717c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 143/288: Weighted fbeta score: 0.3733 (from cache 14462c654bf999bc921d8d9f3ef9483c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 144/288: Weighted fbeta score: 0.0000 (from cache 2cf8706b62b45a2530a220bdc11906ec). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 145/288: Weighted fbeta score: 0.3787 (from cache fd5f6b9ff3e9fec08c1e14be2c75740e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 146/288: Weighted fbeta score: 0.0000 (from cache c49da6760db0a9480628856cbd6e0395). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 147/288: Weighted fbeta score: 0.3816 (from cache 7b8bbfec2533f786e72b1c9046dbdb06). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 148/288: Weighted fbeta score: 0.0000 (from cache 930574a3aa2bf8ccb1a1129d6062d566). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 149/288: Weighted fbeta score: 0.3749 (from cache 11e66c7515ac551bdcb706e822758d87). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 150/288: Weighted fbeta score: 0.0000 (from cache 3c3926bdddd47186858008fcf32ca878). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 151/288: Weighted fbeta score: 0.3733 (from cache 9379dd6e6044fb26e01358a47c318c50). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 152/288: Weighted fbeta score: 0.0000 (from cache 206077d9fc42510d8da7d6d4f972e068). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 153/288: Weighted fbeta score: 0.3792 (from cache a02494bb15d2e494fdf34dd306ff06af). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 154/288: Weighted fbeta score: 0.0000 (from cache 8d9cfbefbc2d0dcef328afaaf63c32a3). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 155/288: Weighted fbeta score: 0.3846 (from cache 55e8e18bec79f3ee0b6f324318adcf32). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 156/288: Weighted fbeta score: 0.0000 (from cache 1c47d70ffd89435a8aaff7d00a3bc0f7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 157/288: Weighted fbeta score: 0.3765 (from cache 48c398990d15293b1e5ca343f1997f6b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 158/288: Weighted fbeta score: 0.0000 (from cache 031d19570c63e3e4e673e2e7ba81a2c5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 159/288: Weighted fbeta score: 0.3733 (from cache ff1d17c12617bc50123c898e61487ed9). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 160/288: Weighted fbeta score: 0.0000 (from cache bf90c7bd123b5d3ae931620d74259ff8). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 161/288: Weighted fbeta score: 0.6111 (from cache 3a50ca590c0c1a5012e1e6127356d909). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 162/288: Weighted fbeta score: 0.0000 (from cache cc5c6274bdf56e1511e1dd2eb2383362). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 163/288: Weighted fbeta score: 0.5967 (from cache 39804a56f7acd571f9934f9dafe8116b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 164/288: Weighted fbeta score: 0.0000 (from cache 8b785c53b758c0ad1455995bfc82c09d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 165/288: Weighted fbeta score: 0.6055 (from cache 15a55f5d173490564dfdc3bd1d5f6427). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 166/288: Weighted fbeta score: 0.0000 (from cache 3ba9ccdc8bde2923859e7c12d71828dd). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 167/288: Weighted fbeta score: 0.5980 (from cache 9ca084aaccec76c7ae228373c52e562b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 168/288: Weighted fbeta score: 0.0000 (from cache 5a0ff001801cea6bbaaa5941d12c7b48). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 169/288: Weighted fbeta score: 0.6064 (from cache e3843344127566c0406ce2471523243f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 170/288: Weighted fbeta score: 0.0000 (from cache d61ce42503f1f51bbb6a17ebfd8f5430). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 171/288: Weighted fbeta score: 0.6086 (from cache a1ac174ce5b89b4c46200c864a27d5b6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 172/288: Weighted fbeta score: 0.0000 (from cache 270c56748f5cf232cac8a92282ac4eee). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 173/288: Weighted fbeta score: 0.6055 (from cache d2891b149f571bd3a822bef146d3a81c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 174/288: Weighted fbeta score: 0.0000 (from cache 1690ecefad6eba8dce269666bfaba261). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 175/288: Weighted fbeta score: 0.5980 (from cache da393f7c5ad0b7bf3fc8af2704f29c45). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 176/288: Weighted fbeta score: 0.0000 (from cache 7ee09cae4ba83860757db16a6fa51c22). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 177/288: Weighted fbeta score: 0.6027 (from cache 6647c31e9cb341d77b13c95fd0b7d47c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 178/288: Weighted fbeta score: 0.0000 (from cache 2895e1317f54a69688fc6e1fc20e83be). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 179/288: Weighted fbeta score: 0.6116 (from cache 145c0efb97e90c2a48aa9ebcabc980e1). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 180/288: Weighted fbeta score: 0.0000 (from cache e98a83386c78d63b3025ea0cc30ed94e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 181/288: Weighted fbeta score: 0.6032 (from cache 3817b25c8f542a0a9df31e3834b7a0a9). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 182/288: Weighted fbeta score: 0.0000 (from cache 8f1c751ab717e2e6d2113091606e0ea1). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 183/288: Weighted fbeta score: 0.5980 (from cache 9ce09172cf65a3dccff57636c64b6143). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 184/288: Weighted fbeta score: 0.0000 (from cache bbb581d76668661cebc3b593eb7cadf7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 185/288: Weighted fbeta score: 0.6091 (from cache aaf7661b6015c5a7fa36afe76d33cdcb). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 186/288: Weighted fbeta score: 0.0000 (from cache 8212a460e5aeaba8c5100f73d01df711). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 187/288: Weighted fbeta score: 0.6085 (from cache 4374e5a9baab54d549b2b647ae202687). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 188/288: Weighted fbeta score: 0.0000 (from cache 674d335a655f3ebd0f3f2187febc2465). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 189/288: Weighted fbeta score: 0.6058 (from cache d550eeb5b4e7f4fa3f3043937da6980f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 190/288: Weighted fbeta score: 0.0000 (from cache b71e309f164407d70e3ab577f4139c1d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 191/288: Weighted fbeta score: 0.5980 (from cache b408e13fef4495fc64249fdf33f4fdd4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 192/288: Weighted fbeta score: 0.0000 (from cache c04614161d49cbddb9d816573b3a8cda). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 193/288: Weighted fbeta score: 0.6528 (from cache 8053ee1cab6ecadc63333e3b2aaced09). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 194/288: Weighted fbeta score: 0.0000 (from cache e1573fe77996441492dbd5db3ccc7837). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 195/288: Weighted fbeta score: 0.6521 (from cache 2390f56767ccca44a2bbca9c24bc9095). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 196/288: Weighted fbeta score: 0.0000 (from cache dc4f2ba8c281c107d7a0fa9440a332f8). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 197/288: Weighted fbeta score: 0.6474 (from cache f0e1323032ebb101a613381dbc9a5721). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 198/288: Weighted fbeta score: 0.0000 (from cache a37b334193cec16502736340b4d69f7a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 199/288: Weighted fbeta score: 0.6268 (from cache a0e4dd05f0ec1b89f0281ac9f35f0758). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 200/288: Weighted fbeta score: 0.0000 (from cache ce30843c8389cf66a1b48ec807538122). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 201/288: Weighted fbeta score: 0.6523 (from cache e80ae0153c78eee40326a743d5530686). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 202/288: Weighted fbeta score: 0.0000 (from cache 5f56dd2a7dbeb74ada6f0ba9cd0dd0d4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 203/288: Weighted fbeta score: 0.6472 (from cache fd24d68a6eee81d7cc25668ebdbc2e70). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 204/288: Weighted fbeta score: 0.0000 (from cache 96940ab741de7014c5c9bd7d66094a62). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 205/288: Weighted fbeta score: 0.6474 (from cache 66c0b758fbaa753180c7a6644f0a7275). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 206/288: Weighted fbeta score: 0.0000 (from cache 690e1177d1cc0c7fbe2a7d105b75c5ad). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 207/288: Weighted fbeta score: 0.6268 (from cache d69339b82d2d5406ab09d1f407116da6). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 208/288: Weighted fbeta score: 0.0000 (from cache 3c90121c4dd0bd31cffa206081b96f38). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 209/288: Weighted fbeta score: 0.6559 (from cache 3a2e0c6a4ab98c9cbc065484398105f3). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 210/288: Weighted fbeta score: 0.0000 (from cache e3c609249a9a1f17d5b8e575dbabbf45). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 211/288: Weighted fbeta score: 0.6460 (from cache 96f8516aaa26f251dbdf923f6f469961). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 212/288: Weighted fbeta score: 0.0000 (from cache add6adb5793f2fc001d14275b005af29). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 213/288: Weighted fbeta score: 0.6443 (from cache 00db22c21207f3ad1742438ea5767360). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 214/288: Weighted fbeta score: 0.0000 (from cache b31d10a8ec0acd38788bfae0181a9abd). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 215/288: Weighted fbeta score: 0.6268 (from cache 9176c8458927af468349dcd86dcf1206). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 216/288: Weighted fbeta score: 0.0000 (from cache 97a5ac99a890bfb45a3e8ffe82d49272). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 217/288: Weighted fbeta score: 0.6490 (from cache 47e9290ed0d0496e484d30e351dd343d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 218/288: Weighted fbeta score: 0.0000 (from cache 7c0fac54e8f2583b42c0f12441daf6f3). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 219/288: Weighted fbeta score: 0.6418 (from cache 9fff581669afaa0584f3bd58567e64c2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 220/288: Weighted fbeta score: 0.0000 (from cache d17cedd46180035a369068ef4ed16330). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 221/288: Weighted fbeta score: 0.6395 (from cache 1fc00871f7b0398b9cf4571a26fe074c). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 222/288: Weighted fbeta score: 0.0000 (from cache 360b3e4ecde30c02953d908a6d2bd6cf). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 223/288: Weighted fbeta score: 0.6268 (from cache 79cbfa80eb27a62f60ddbdea2c383fcf). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 224/288: Weighted fbeta score: 0.0000 (from cache d7a2c5a7f95a075fe04e67c1f9d834df). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 225/288: Weighted fbeta score: 0.3736 (from cache dc022f2e4efa3d083eb3492f8364764b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 226/288: Weighted fbeta score: 0.0000 (from cache 87b93661e92d001554e2e738ef062990). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 227/288: Weighted fbeta score: 0.3689 (from cache 4f97df2bef8308d18baebb6165e54a99). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 228/288: Weighted fbeta score: 0.0000 (from cache 14123e062ec66ebf62563119694908b7). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 229/288: Weighted fbeta score: 0.3766 (from cache 06145001d50c7a5617a9c10af5360fad). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 230/288: Weighted fbeta score: 0.0000 (from cache 7ed8f26e94c351a6e22221d53a28274a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 231/288: Weighted fbeta score: 0.3722 (from cache b8459138a5709e2e45a4044b29879127). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 232/288: Weighted fbeta score: 0.0000 (from cache dc4acc65ef1c4f8d878b59ff57ab9d8e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 233/288: Weighted fbeta score: 0.3762 (from cache 4ac77f549a5d4a82acd2836c20069a5e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 234/288: Weighted fbeta score: 0.0000 (from cache c2445d673877a4fe775490b24aa14122). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 235/288: Weighted fbeta score: 0.3724 (from cache f554096b8270fd6717286cb9225349a2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 236/288: Weighted fbeta score: 0.0000 (from cache 01e97e426f7cbe572878cf8e227b0f18). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 237/288: Weighted fbeta score: 0.3766 (from cache b297112e75b083c8fdf1a458011ca9e5). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 238/288: Weighted fbeta score: 0.0000 (from cache 6c54879d5e637729bd7a47c3ad88aab2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 239/288: Weighted fbeta score: 0.3722 (from cache f4590f861cc149ddc1ff2a5576177932). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 240/288: Weighted fbeta score: 0.0000 (from cache d9d656a7e5a17667a297c0bc29ffda35). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 241/288: Weighted fbeta score: 0.3767 (from cache ad8aa92db0a861a9066744127728d480). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 242/288: Weighted fbeta score: 0.0000 (from cache 81c5e3b1e7baf9762642d34954fa533d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 243/288: Weighted fbeta score: 0.3769 (from cache 56be29c09ce6e3559e4c30422c221e0b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 244/288: Weighted fbeta score: 0.0000 (from cache fa470e080d80e79d7cdd71ba586a38af). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 245/288: Weighted fbeta score: 0.3736 (from cache 11be01d67f8f0912b102e0d3dd422110). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 246/288: Weighted fbeta score: 0.0000 (from cache 41966ecbb5c14b74eccbe3a4f22ef259). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 247/288: Weighted fbeta score: 0.3722 (from cache 877da5b7433de5cc9537931d8e6b70a8). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 248/288: Weighted fbeta score: 0.0000 (from cache 6d56858e14ffd31a9c7ba3753140e83d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 249/288: Weighted fbeta score: 0.3791 (from cache 7cf7ac5066e1fdeb5172bb991c855096). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 250/288: Weighted fbeta score: 0.0000 (from cache 79265ae45391edb23f6e2c7fd5d00900). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 251/288: Weighted fbeta score: 0.3770 (from cache c24449555a74baebbb7c75c74590c5bb). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 252/288: Weighted fbeta score: 0.0000 (from cache 863f0074d25a39b0e8b9797898335c85). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 253/288: Weighted fbeta score: 0.3736 (from cache a27b77e1bb5dd29c0460d4a5cad14974). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 254/288: Weighted fbeta score: 0.0000 (from cache 7af52e77f19b423ef01c9fb66ac81a89). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 255/288: Weighted fbeta score: 0.3722 (from cache 79da308a10fa5a951e002f4e569dfe21). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 256/288: Weighted fbeta score: 0.0000 (from cache 8bf15710f02c116139e6d55c67584e2d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 257/288: Weighted fbeta score: 0.6064 (from cache 792cf4a82e9db4a276c91618bc4e8665). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 258/288: Weighted fbeta score: 0.0000 (from cache 92a71fc38c9c5ec2f1fa7691f1fd6a3b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 259/288: Weighted fbeta score: 0.6016 (from cache 414b4231e084fe32376f5e264c4bd949). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 260/288: Weighted fbeta score: 0.0000 (from cache 1ff4a3e3936c20fe1d348afb50829704). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 261/288: Weighted fbeta score: 0.6025 (from cache 98545e6ddc5d48a547425618ce133bb4). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 262/288: Weighted fbeta score: 0.0000 (from cache 453e2932778f95c400e430ecd9908799). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 263/288: Weighted fbeta score: 0.5987 (from cache 508917b8df064d5f2d53bdca2ef8013b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 264/288: Weighted fbeta score: 0.0000 (from cache e6e0539744d1c0b85e7a923003d51cfa). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 265/288: Weighted fbeta score: 0.6050 (from cache 5471456f1400d6ddf999475d7401257d). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 266/288: Weighted fbeta score: 0.0000 (from cache bf6c065f8b0a5cf49ab4bfdd3e3ba503). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 267/288: Weighted fbeta score: 0.6054 (from cache e5627d49f607ed45cd7ffb4a67c13f8b). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 268/288: Weighted fbeta score: 0.0000 (from cache 13e874bd448f6724c61ea8f86708fc97). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 269/288: Weighted fbeta score: 0.6025 (from cache 374ea1b6edfb7d5366c728b634e26d32). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 270/288: Weighted fbeta score: 0.0000 (from cache 9ae2a4471fb547bbab0cfbadbc9af89a). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 271/288: Weighted fbeta score: 0.5987 (from cache 7568d7d3dd3b19e3d6ee972c4ce697e2). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 272/288: Weighted fbeta score: 0.0000 (from cache 4370b3467be6727bd19d769726090d35). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 273/288: Weighted fbeta score: 0.6054 (from cache 5e8b75863392b6193f7049a4d0f1d65f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 274/288: Weighted fbeta score: 0.0000 (from cache 7a39c1935e69116f534c72be06f02a96). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 275/288: Weighted fbeta score: 0.6083 (from cache 33500514f21fed6e77217075c0f5bf40). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 276/288: Weighted fbeta score: 0.0000 (from cache 197e28a3fdacdeae81a5013a2abb9053). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 277/288: Weighted fbeta score: 0.6049 (from cache 77e2be13b849c1fc766eed0f88b0295f). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 278/288: Weighted fbeta score: 0.0000 (from cache de0f609764030547492e891f5e4f062e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 279/288: Weighted fbeta score: 0.5987 (from cache 1b8b10b3e435394cddb532cbe54f4aaf). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 280/288: Weighted fbeta score: 0.0000 (from cache f8a638752f57eda44ed34708b5e10e52). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 281/288: Weighted fbeta score: 0.6062 (from cache 2e279e7ccc1846961bfe2514416e1102). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 282/288: Weighted fbeta score: 0.0000 (from cache 136418d4005622e32b6215ebd47ce5ef). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 283/288: Weighted fbeta score: 0.6086 (from cache 7d8efb2eb4f97255789fe5197eff937e). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 284/288: Weighted fbeta score: 0.0000 (from cache f6be6a898a3955023131a5a7c3d5db96). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 285/288: Weighted fbeta score: 0.6030 (from cache 5da559e3d0828c46fc696836632d0948). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 286/288: Weighted fbeta score: 0.0000 (from cache c416f031f372f7ab236b26cca16a8338). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 287/288: Weighted fbeta score: 0.5987 (from cache 4152990d4dc788a82a4169320e638fad). Best score so far: 0.6654\n",
      "Evaluating model 3, combination 288/288: Weighted fbeta score: 0.0000 (from cache ba3624018da564c307695d3e8416eefb). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 1/24: Weighted fbeta score: 0.3788 (from cache 8bb3ee6b3b8b63ad75120c1d660329ad). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 2/24: Weighted fbeta score: 0.3275 (from cache 7f894f0f12a52ff7393c86ca56ed301a). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 3/24: Weighted fbeta score: 0.4860 (from cache 577f33aecbdc24a55b10e0d604d9fcc8). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 4/24: Weighted fbeta score: 0.5534 (from cache 8d19f65f166ec4bcfc1809b867a13714). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 5/24: Weighted fbeta score: 0.5261 (from cache 523fe028533431fb2b08842030cd6764). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 6/24: Weighted fbeta score: 0.5985 (from cache 6e713537d136fffa182428c246c93ae4). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 7/24: Weighted fbeta score: 0.6164 (from cache d138bb7494dc6cc1a93da4d90003ab96). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 8/24: Weighted fbeta score: 0.5974 (from cache d0b2f0aff78dbf3742610bd511311c27). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 9/24: Weighted fbeta score: 0.6360 (from cache f79f4c0da5886e2a5a5df86b05cccc52). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 10/24: Weighted fbeta score: 0.6313 (from cache 73e11a397f7e266d51fc897606a0a3ee). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 11/24: Weighted fbeta score: 0.6433 (from cache bda4b265ea253a9a1597d924d5b34207). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 12/24: Weighted fbeta score: 0.6486 (from cache ee61ea13860b08966d0caa0766e6f772). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 13/24: Weighted fbeta score: 0.4928 (from cache 8ae623dcb89b49c66fbe39308acc1646). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 14/24: Weighted fbeta score: 0.4555 (from cache 86e95158c6999ec669aaa2ff47232935). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 15/24: Weighted fbeta score: 0.5496 (from cache fb4f762a8a3b866a3ed151b33bbd9d90). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 16/24: Weighted fbeta score: 0.5969 (from cache 33b4e1808bfcc9844c79ef998c1c2ad2). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 17/24: Weighted fbeta score: 0.5819 (from cache 0991980c9ce410ced3fbcb510c07a014). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 18/24: Weighted fbeta score: 0.6263 (from cache fd8d733ba972fb2742a370b3c73dc524). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 19/24: Weighted fbeta score: 0.6387 (from cache 8f3e5e45323e0935a0447cdeb12e32e3). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 20/24: Weighted fbeta score: 0.6317 (from cache ac979abc04c4818adfe6b6d80b167fcb). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 21/24: Weighted fbeta score: 0.6498 (from cache 80095c0654055366411453e73b286b6b). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 22/24: Weighted fbeta score: 0.6475 (from cache 83cf06cd374cd6b90c5812916b254a82). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 23/24: Weighted fbeta score: 0.6476 (from cache 58a959c58ebe23c04de4cbe951882ec5). Best score so far: 0.6654\n",
      "Evaluating model 4, combination 24/24: Weighted fbeta score: 0.6523 (from cache b826b12cf0a3858bc2a8962d4f7c1a07). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 1/20: Weighted fbeta score: 0.4952 (from cache 4a4acbc9706adc275ae2e614cce862de). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 2/20: Weighted fbeta score: 0.5526 (from cache 94b1f9cf0c92ca1c46c987f410f84b26). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 3/20: Weighted fbeta score: 0.0000 (from cache c559a769a46d34f9108e0b1c25d20ab5). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 4/20: Weighted fbeta score: 0.2164 (from cache 0dd9f3ccf789fa2e2cb46000c3f60994). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 5/20: Weighted fbeta score: 0.5788 (from cache d04087fb7d804459f17fd0d0369efc08). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 6/20: Weighted fbeta score: 0.5864 (from cache 182ea6bd87ae9d359135190962e545b0). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 7/20: Weighted fbeta score: 0.0695 (from cache 91bb23bcb1b98c4d06f221ce95e2386d). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 8/20: Weighted fbeta score: 0.5446 (from cache fdb99a0a4f8e13a66f0d5974dd0eef11). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 9/20: Weighted fbeta score: 0.6190 (from cache 4d36b29874935679593bb126cd481d9d). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 10/20: Weighted fbeta score: 0.6106 (from cache 932619e697303edf5aa223fdc016cbee). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 11/20: Weighted fbeta score: 0.5872 (from cache fef2f2ba9d4373139f7a9bc9f144651d). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 12/20: Weighted fbeta score: 0.5899 (from cache 47af4fb8bc4df88f0d0c077ece1a5b6d). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 13/20: Weighted fbeta score: 0.6064 (from cache 4671d49f237f100862e83a80d6a73007). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 14/20: Weighted fbeta score: 0.6061 (from cache ca0b27ef6cef5087fa3da4e734f7197b). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 15/20: Weighted fbeta score: 0.6234 (from cache 5bc7e1816e8cc9b5bf06f417d35ad62e). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 16/20: Weighted fbeta score: 0.6204 (from cache 9cbf67b05a736544a2a18fba4d17df4b). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 17/20: Weighted fbeta score: 0.5982 (from cache ba00d90ef966c4cc7dfe70ed485eb0d4). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 18/20: Weighted fbeta score: 0.5982 (from cache 19e35a33471c12aae554ce3d1317e514). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 19/20: Weighted fbeta score: 0.6138 (from cache bc22aad3c20ee65782936c663b0ec919). Best score so far: 0.6654\n",
      "Evaluating model 5, combination 20/20: Weighted fbeta score: 0.6132 (from cache 10e930906fcebd89cb90cbf363250cc2). Best score so far: 0.6654\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning and evaluating top 5 models: \")\n",
    "results_top5 = evaluate_parameter_grid(param_grid_top5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5bad129e-bf8b-440e-8a2b-9c9a0a910b0c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 tuned models: \n",
      "\u001b[35mRank 1/1676 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6654, \u001b[0mPrecision: 0.7116, Recall: 0.7020\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: XGBClassifier, \n",
      "\u001b[36mobjective\u001b[0m: binary:logistic, \u001b[36mbase_score\u001b[0m: None, \u001b[36mbooster\u001b[0m: gbtree, \u001b[36mcallbacks\u001b[0m: None, \u001b[36mcolsample_bylevel\u001b[0m: 1.0, \u001b[36mcolsample_bynode\u001b[0m: 1.0, \u001b[36mcolsample_bytree\u001b[0m: 1.0, \u001b[36mdevice\u001b[0m: None, \u001b[36mearly_stopping_rounds\u001b[0m: None, \u001b[36menable_categorical\u001b[0m: False, \u001b[36meval_metric\u001b[0m: None, \u001b[36mfeature_types\u001b[0m: None, \u001b[36mgamma\u001b[0m: 0, \u001b[36mgrow_policy\u001b[0m: None, \u001b[36mimportance_type\u001b[0m: None, \u001b[36minteraction_constraints\u001b[0m: None, \u001b[36mlearning_rate\u001b[0m: None, \u001b[36mmax_bin\u001b[0m: None, \u001b[36mmax_cat_threshold\u001b[0m: None, \u001b[36mmax_cat_to_onehot\u001b[0m: None, \u001b[36mmax_delta_step\u001b[0m: None, \u001b[36mmax_depth\u001b[0m: 8, \u001b[36mmax_leaves\u001b[0m: None, \u001b[36mmin_child_weight\u001b[0m: 5, \u001b[36mmissing\u001b[0m: nan, \u001b[36mmonotone_constraints\u001b[0m: None, \u001b[36mmulti_strategy\u001b[0m: None, \u001b[36mn_estimators\u001b[0m: 200, \u001b[36mn_jobs\u001b[0m: None, \u001b[36mnum_parallel_tree\u001b[0m: None, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mreg_alpha\u001b[0m: None, \u001b[36mreg_lambda\u001b[0m: None, \u001b[36msampling_method\u001b[0m: None, \u001b[36mscale_pos_weight\u001b[0m: 1, \u001b[36msubsample\u001b[0m: 1.0, \u001b[36mtree_method\u001b[0m: hist, \u001b[36mvalidate_parameters\u001b[0m: None, \u001b[36mverbosity\u001b[0m: None, \u001b[36malpha\u001b[0m: 1.6, \u001b[36meta\u001b[0m: 0.1, \u001b[36mlambda\u001b[0m: 0.5, \n",
      "\n",
      "\u001b[35mRank 2/1676 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6635, \u001b[0mPrecision: 0.7099, Recall: 0.7003\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: HistGradientBoostingClassifier, \n",
      "\u001b[36mcategorical_features\u001b[0m: warn, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mearly_stopping\u001b[0m: auto, \u001b[36minteraction_cst\u001b[0m: None, \u001b[36ml2_regularization\u001b[0m: 3, \u001b[36mlearning_rate\u001b[0m: 0.1, \u001b[36mloss\u001b[0m: log_loss, \u001b[36mmax_bins\u001b[0m: 128, \u001b[36mmax_depth\u001b[0m: None, \u001b[36mmax_features\u001b[0m: 1.0, \u001b[36mmax_iter\u001b[0m: 300, \u001b[36mmax_leaf_nodes\u001b[0m: 31, \u001b[36mmin_samples_leaf\u001b[0m: 20, \u001b[36mmonotonic_cst\u001b[0m: None, \u001b[36mn_iter_no_change\u001b[0m: 10, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mscoring\u001b[0m: None, \u001b[36mtol\u001b[0m: 1e-07, \u001b[36mvalidation_fraction\u001b[0m: 0.1, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n",
      "\u001b[35mRank 3/1676 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6633, \u001b[0mPrecision: 0.7097, Recall: 0.7001\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: HistGradientBoostingClassifier, \n",
      "\u001b[36mcategorical_features\u001b[0m: warn, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mearly_stopping\u001b[0m: auto, \u001b[36minteraction_cst\u001b[0m: None, \u001b[36ml2_regularization\u001b[0m: 3, \u001b[36mlearning_rate\u001b[0m: 0.1, \u001b[36mloss\u001b[0m: log_loss, \u001b[36mmax_bins\u001b[0m: 255, \u001b[36mmax_depth\u001b[0m: None, \u001b[36mmax_features\u001b[0m: 1.0, \u001b[36mmax_iter\u001b[0m: 300, \u001b[36mmax_leaf_nodes\u001b[0m: 31, \u001b[36mmin_samples_leaf\u001b[0m: 10, \u001b[36mmonotonic_cst\u001b[0m: None, \u001b[36mn_iter_no_change\u001b[0m: 10, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mscoring\u001b[0m: None, \u001b[36mtol\u001b[0m: 1e-07, \u001b[36mvalidation_fraction\u001b[0m: 0.1, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n",
      "\u001b[35mRank 4/1676 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6633, \u001b[0mPrecision: 0.7097, Recall: 0.7007\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: XGBClassifier, \n",
      "\u001b[36mobjective\u001b[0m: binary:logistic, \u001b[36mbase_score\u001b[0m: None, \u001b[36mbooster\u001b[0m: gbtree, \u001b[36mcallbacks\u001b[0m: None, \u001b[36mcolsample_bylevel\u001b[0m: 1.0, \u001b[36mcolsample_bynode\u001b[0m: 1.0, \u001b[36mcolsample_bytree\u001b[0m: 1.0, \u001b[36mdevice\u001b[0m: None, \u001b[36mearly_stopping_rounds\u001b[0m: None, \u001b[36menable_categorical\u001b[0m: False, \u001b[36meval_metric\u001b[0m: None, \u001b[36mfeature_types\u001b[0m: None, \u001b[36mgamma\u001b[0m: 0, \u001b[36mgrow_policy\u001b[0m: None, \u001b[36mimportance_type\u001b[0m: None, \u001b[36minteraction_constraints\u001b[0m: None, \u001b[36mlearning_rate\u001b[0m: None, \u001b[36mmax_bin\u001b[0m: None, \u001b[36mmax_cat_threshold\u001b[0m: None, \u001b[36mmax_cat_to_onehot\u001b[0m: None, \u001b[36mmax_delta_step\u001b[0m: None, \u001b[36mmax_depth\u001b[0m: 10, \u001b[36mmax_leaves\u001b[0m: None, \u001b[36mmin_child_weight\u001b[0m: 5, \u001b[36mmissing\u001b[0m: nan, \u001b[36mmonotone_constraints\u001b[0m: None, \u001b[36mmulti_strategy\u001b[0m: None, \u001b[36mn_estimators\u001b[0m: 300, \u001b[36mn_jobs\u001b[0m: None, \u001b[36mnum_parallel_tree\u001b[0m: None, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mreg_alpha\u001b[0m: None, \u001b[36mreg_lambda\u001b[0m: None, \u001b[36msampling_method\u001b[0m: None, \u001b[36mscale_pos_weight\u001b[0m: 1, \u001b[36msubsample\u001b[0m: 1.0, \u001b[36mtree_method\u001b[0m: hist, \u001b[36mvalidate_parameters\u001b[0m: None, \u001b[36mverbosity\u001b[0m: None, \u001b[36malpha\u001b[0m: 0.5, \u001b[36meta\u001b[0m: 0.1, \u001b[36mlambda\u001b[0m: 0, \n",
      "\n",
      "\u001b[35mRank 5/1676 - \u001b[0m\u001b[31mWeighted Fbeta: 0.6630, \u001b[0mPrecision: 0.7095, Recall: 0.7006\n",
      "\u001b[34mPipeline parameters: \n",
      "\u001b[0m\u001b[36mmodel\u001b[0m: HistGradientBoostingClassifier, \n",
      "\u001b[36mcategorical_features\u001b[0m: warn, \u001b[36mclass_weight\u001b[0m: None, \u001b[36mearly_stopping\u001b[0m: auto, \u001b[36minteraction_cst\u001b[0m: None, \u001b[36ml2_regularization\u001b[0m: 7, \u001b[36mlearning_rate\u001b[0m: 0.1, \u001b[36mloss\u001b[0m: log_loss, \u001b[36mmax_bins\u001b[0m: 255, \u001b[36mmax_depth\u001b[0m: 5, \u001b[36mmax_features\u001b[0m: 1.0, \u001b[36mmax_iter\u001b[0m: 300, \u001b[36mmax_leaf_nodes\u001b[0m: 31, \u001b[36mmin_samples_leaf\u001b[0m: 1, \u001b[36mmonotonic_cst\u001b[0m: None, \u001b[36mn_iter_no_change\u001b[0m: 10, \u001b[36mrandom_state\u001b[0m: 42, \u001b[36mscoring\u001b[0m: None, \u001b[36mtol\u001b[0m: 1e-07, \u001b[36mvalidation_fraction\u001b[0m: 0.1, \u001b[36mverbose\u001b[0m: 0, \u001b[36mwarm_start\u001b[0m: False, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 tuned models: \") \n",
    "top_results_top5 = display_top_models(results_top5, X_train.shape[1], top_k = 5, sort_by = 'weighted_fbeta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edf6c0-cf30-45d5-a6ad-56aec0832f80",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 15.2 Pick the top model from the tuned top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "69346526-7e92-4804-b05b-3a38289241a4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "best_model_final = top_results_top5[0]['parameters']['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d110c-d35d-437b-92ae-a1c5802021fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 16. Feature selection using best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521406a-906e-423c-adff-4f7722bb805f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Feature reduction will be our next step, employing a comprehensive approach with multiple feature selection techniques. We'll utilize four distinct methods to identify and select the most informative features:\n",
    "\n",
    "- Univariate Feature Selection (SelectKBest)\n",
    "- Percentile-based Selection\n",
    "- Recursive Feature Elimination (RFE)\n",
    "- Model-based Feature Selection\n",
    "\n",
    "Each of these techniques will leverage cross-validation prediction and our custom $F_{\\beta}$ score to systematically evaluate and select the most relevant features. Once we've completed the feature selection process, we'll benchmark the performance of the reduced feature sets against the best-performing model from our previous top 5 trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e2d3d9b-1dde-4000-86ab-76ff94ddeec1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "n_features = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2386ad7-a910-4258-9eaa-dc18359efa65",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 16.1 Feature seleciton using SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7415800a-548e-4dfa-ae42-0e596dfb77d7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "fbeta_kbest_75 = select_k_best(\n",
    "    best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, k=(2 * n_features) // 3\n",
    ")\n",
    "fbeta_kbest_50 = select_k_best(best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, k=n_features // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ce563-5b06-4d89-a13b-b821a0a9d071",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 16.2 Feature selection using SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8d4eb3c-ae3a-4ce0-99a1-f26c5759db83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "fbeta_percentile_75 = select_percentile(best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, percentile=75)\n",
    "fbeta_percentile_50 = select_percentile(best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, percentile=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32c53c-8468-4432-b6ca-c8fe40c7652a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 16.3 Feature selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ba63a10-86e6-4194-b93d-088fe6c49dc8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "fbeta_rfe_75 = recursive_feature_elimination(\n",
    "    best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, n_features_to_select=(2 * n_features) // 3\n",
    ")\n",
    "fbeta_rfe_50 = recursive_feature_elimination(\n",
    "    best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score, n_features_to_select=n_features // 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62d120-7dd4-40a6-8f74-31367f5f430a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 16.4 Feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ddca6719-6210-48e7-a97e-9ece67287d2c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "fbeta_from_model = select_from_model(best_model_final, X_train, y_train, X_test.columns, calculate_fbeta_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff04376-e0ac-4f22-ae4f-17fb4687ed69",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "### 16.5 Compare the scores with the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54201b90-030c-4436-8d2b-5220883e18a7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "fbeta_final_model = top_results_top5[0]['scores']['weighted_fbeta']\n",
    "\n",
    "selection_results = {\n",
    "    \"fbeta_final_model\":   float(fbeta_final_model),\n",
    "    \"fbeta_kbest_75\":      fbeta_kbest_75[\"score\"],\n",
    "    \"fbeta_kbest_50\":      fbeta_kbest_50[\"score\"],\n",
    "    \"fbeta_percentile_75\": fbeta_percentile_75[\"score\"],\n",
    "    \"fbeta_percentile_50\": fbeta_percentile_50[\"score\"],\n",
    "    \"fbeta_rfe_75\":        fbeta_rfe_75[\"score\"],\n",
    "    \"fbeta_rfe_50\":        fbeta_rfe_50[\"score\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "261af865-e316-41f8-82bf-b2d7ac70dd72",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View best score (from best_model_final) and the scores from the feature selection functions:\n",
      "fbeta_final_model    0.6654\n",
      "fbeta_kbest_75       0.6562\n",
      "fbeta_kbest_50       0.6468\n",
      "fbeta_percentile_75  0.6595\n",
      "fbeta_percentile_50  0.6468\n",
      "fbeta_rfe_75         0.6565\n",
      "fbeta_rfe_50         0.6604\n"
     ]
    }
   ],
   "source": [
    "print(\"View best score (from best_model_final) and the scores from the feature selection functions:\")\n",
    "for key, value in selection_results.items():\n",
    "    print(f\"{key:<20} {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e8ab6-e3c6-4bfd-901f-67ef0d6f0119",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "#### Did we find a better score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c3f3e12-57ec-43df-ad88-e723d908ef6d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Fbeta score so far is fbeta_final_model: 0.6654\n"
     ]
    }
   ],
   "source": [
    "# which fbeta score is the greatest?\n",
    "max_fbeta_key = max(selection_results, key=selection_results.get)\n",
    "print(f\"The best Fbeta score so far is {max_fbeta_key}: {selection_results[max_fbeta_key]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc527fb6-0617-4906-9e55-41b2af6a9c99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "We did not find a better score, therefore we will continue using `best_model_final`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d305f-e343-4857-9f03-b3d02a4ba5ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 17. Predict on test data using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3395d51a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:         0.6570\n",
      "Fbeta:      0.6766\n",
      "Precision:  0.6947\n",
      "Recall:     0.6232\n",
      "Accuracy:   0.7266\n"
     ]
    }
   ],
   "source": [
    "scores = predict_and_score(best_model_final, X_test, y_test, 0.5, X_test.columns)\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97571a57-9c97-4e7d-9c92-5503f52fa509",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 18. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "def921f2-67d4-4d9a-b953-52e5e9d7c106",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the predicted probabilities for the test set\n",
    "y_pred_prob = best_model_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "cplt.figure(figsize=(8, 6))\n",
    "cplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "cplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "cplt.txylabel('Receiver Operating Characteristic (ROC) Curve', 'False Positive Rate', 'True Positive Rate')\n",
    "cplt.legend(loc=\"lower right\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0adbf-9d96-4a1a-bf0f-43f1cae112a3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 18 Analyzing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59901497-a097-4bb8-ac77-4319855e675d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "The relatively low custom $F_{\\beta}$ score can be attributed to several factors observed in the notebook. First, the dataset contains substantial missing data, requiring imputation methods such as median values and group-specific imputations, which might not fully capture the underlying relationships in the data. Additionally, the features are derived from self-reported survey responses, which are inherently subjective and may include biases or inaccuracies. Another limitation arises from the significant number of columns removed during preprocessing to exclude \"future data,\" potentially discarding predictive features. Finally, the challenge of balancing high precision with recall, as prioritized by the custom $F_{\\beta}$ score, inherently limits the model’s ability to optimize for both simultaneously. These combined challenges likely constrained the model's performance in achieving a higher score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798c68e-9670-4b6b-9705-1b242f7ff38b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Another possible reason for the low custom $F_{\\beta}$ score is the nature of the participants in the original dating experiment. Most of them were young college students with an average age of 26 years, and it’s possible that they didn’t have a clear idea of what they were looking for in a partner or couldn’t fully justify their answers. Young people may also have an idealistic view of their future partner, which might not align with reality when they actually meet someone. Additionally, other analyses on Kaggle, which included \"future\" features (like answers after participants had met their partners), achieve better results. This suggests that until two people meet, it might be hard for them—especially young participants—to predict whether they’ll like someone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add18a5d-e6d4-4234-8d4c-78580555704f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "Finally, many participants joined the experiment \"just for fun,\" (feature _goal_) with only a small number being serious about finding a date. This raises questions about how reliable their answers were in reflecting genuine preferences or intentions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f738b-630a-4ffc-9df6-2c01a84bd5b7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 19. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c40fb-9d05-4425-9cbc-849d2e806881",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "This article developed a machine learning project to predict matches for a dating app, using a speed-dating dataset filled with demographic, psychological, and preference-based information. The data preprocessing process tackled key issues like missing data, redundant features, and inconsistent scaling to ensure the dataset was ready for modeling. Some standout innovations included creating partner-specific features, creating new features like differences and similarities, and designing a custom evaluation metric to strike the right balance between precision and recall—crucial for real-world matchmaking scenarios.\n",
    "\n",
    "The project highlights how AI can transform personalized experiences, especially in complex areas like dating. It underscores the importance of thoughtful metric selection and feature engineering in improving predictive performance. However, challenges remain, such as addressing biases in self-reported survey data and ensuring fair recommendations for users with diverse preferences. Future work could focus on incorporating real-time user feedback, leveraging deep learning to capture complex feature interactions, and addressing the ethical considerations of automated matchmaking. With these improvements, such models could set new standards for user-centered AI applications in interpersonal domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb9d90-495a-4687-9150-e65e46a3de16",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "## 20. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8ae01-7590-4933-bc46-75e7346b9b55",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "source": [
    "<div id=\"ref1\">\n",
    "    [1] Fisman, R., Iyengar, S. S., Kamenica, E., & Simonson, I. (2006). <a href=\"https://doi.org/10.1162/qjec.2006.121.2.673, [pdf](http://www.stat.columbia.edu/~gelman/stuff_for_blog/sheena.pdf\" Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment</a>. The Quarterly Journal of Economics, 121(2), 673-697. \n",
    "</div>\n",
    "\n",
    "<div id=\"ref2\">\n",
    "    [2] The original dataset and the key file: <a href=\"http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/\">http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/</a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "jpcodetoc-autonumbering": false,
  "jpcodetoc-showtags": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "scenes_data": {
   "active_scene": "Default Scene",
   "init_scene": "",
   "scenes": [
    "Default Scene"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
