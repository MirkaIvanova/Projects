//prettier-ignore
{
    "model__alpha":             [0, 0.5, 1, 1.5, 1.6], // [2] default=0, L1 regularization term on weights
    "model__base_score":        [null],                // default: null
    "model__booster":           ["gbtree"],            // Type of booster to use
    "model__colsample_bylevel": [1.0],                 // default=1
    "model__colsample_bynode":  [1.0],                 // default=1
    "model__colsample_bytree":  [1.0],                 // default=1
    "model__device":            [null],                // default: null
    "model__eta":               [ 0.1, 0.2, 0.25, 0.3], // [0.01, 0.05,] Learning rate (slower = more robust)
    "model__gamma":             [0], // default=0
    "model__lambda":            [0, 0.5, 1, 1.5, 2],       // default=1, L2 regularization term on weights
    "model__max_depth":         [5, 6, 8, 10],          // [3, 4, 10] default=6
    "model__min_child_weight":  [5],                    // default=1
    "model__n_estimators":      [100, 200, 300],             // Number of boosting rounds
    "model__objective":         ["binary:logistic"],    // default: binary:logistic
    "model__scale_pos_weight":  [1],                    // default=1, Balance for positive classes
    "model__subsample":         [1.0],                  // default: 1
    "model__tree_method":       ["hist"]                // Method for building trees


    // "model__n_estimators":      [100]  # Number of boosting rounds

}
